{"cells":[{"cell_type":"markdown","metadata":{"id":"yCkmNlaUurdG"},"source":["# Deep Q-Learning"]},{"cell_type":"markdown","metadata":{"id":"VfX4I_eyurdJ"},"source":["Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16953,"status":"ok","timestamp":1714073394157,"user":{"displayName":"Vaibhav Raheja","userId":"11920937693571090776"},"user_tz":300},"id":"rq5VpM-2urdK","outputId":"3ee494c6-dcf9-4d4a-a2bc-a0603bc8dd23"},"outputs":[],"source":["# !pip3 install gym pyvirtualdisplay\n","# !pip3 install ffmpeg xvfbwrapper PyOpenGL\n","# !sudo apt-get install -y xvfb python-opengl ffmpeg"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44092,"status":"ok","timestamp":1714073438246,"user":{"displayName":"Vaibhav Raheja","userId":"11920937693571090776"},"user_tz":300},"id":"Gynn3oRWurdL","outputId":"e67dfbb4-befe-4c64-d418-ee1914566b63"},"outputs":[],"source":["# !pip3 install --upgrade setuptools --user\n","# !pip3 install ez_setup\n","# !pip3 install gym[atari]\n","# !pip3 install gym[accept-rom-license]"]},{"cell_type":"markdown","metadata":{"id":"OnOcntb3urdL"},"source":["For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2963,"status":"ok","timestamp":1714073523701,"user":{"displayName":"Vaibhav Raheja","userId":"11920937693571090776"},"user_tz":300},"id":"-MfV12osurdM","outputId":"aa500d5d-91a4-4170-e20e-77a1764a9a01"},"outputs":[],"source":["%matplotlib inline\n","\n","import sys\n","import gym\n","import torch\n","import pylab\n","import random\n","import numpy as np\n","from collections import deque\n","from datetime import datetime\n","from copy import deepcopy\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from utils import find_max_lives, check_live, get_frame, get_init_state\n","from model import DQN, DQN_LSTM\n","from config import *\n","\n","import matplotlib.pyplot as plt\n","# %load_ext autoreload\n","# %autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"S9L49ArBurdM"},"source":["## Understanding the environment"]},{"cell_type":"markdown","metadata":{"id":"8DglP8jPurdM"},"source":["In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://gym.openai.com/envs.\n","\n","In breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":323,"status":"ok","timestamp":1714073527231,"user":{"displayName":"Vaibhav Raheja","userId":"11920937693571090776"},"user_tz":300},"id":"YOsGBcG2urdN","outputId":"2572cf23-d400-4a94-a620-c3d17a557aba"},"outputs":[],"source":["env = gym.make('BreakoutDeterministic-v4')\n","state = env.reset()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"elapsed":123,"status":"error","timestamp":1714073528542,"user":{"displayName":"Vaibhav Raheja","userId":"11920937693571090776"},"user_tz":300},"id":"M4vxU17xurdN","outputId":"41f0d93b-9ad7-4b6c-94d7-968ce1ccf7ec"},"outputs":[],"source":["number_lives = find_max_lives(env)\n","state_size = env.observation_space.shape\n","action_size = 3 #fire, left, and right"]},{"cell_type":"markdown","metadata":{"id":"X1L99cleurdN"},"source":["## Creating a DQN Agent"]},{"cell_type":"markdown","metadata":{"id":"jlq-X_hburdN"},"source":["Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n","\n","__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n","\n","__Frame__ : Number of frames processed in total.\n","\n","__Memory Size__ : The current size of the replay memory."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"eKNXNP4yurdN"},"outputs":[],"source":["double_dqn = True # set to True if using double DQN agent\n","\n","if double_dqn:\n","    from agent_double import Agent\n","else:\n","    from agent import Agent\n","\n","agent = Agent(action_size)\n","evaluation_reward = deque(maxlen=evaluation_reward_length)\n","frame = 0\n","memory_size = 0"]},{"cell_type":"markdown","metadata":{"id":"6HI5JYSJurdO"},"source":["### Main Training Loop"]},{"cell_type":"markdown","metadata":{"id":"FJyQkmauurdO"},"source":["In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\""]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Ow4hd3TrurdO","outputId":"ed51a4e1-afe2-4352-f915-09816747fcaf","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["e:\\Personal_Stuff\\UIUC\\Sem_2\\DL for CV (CS_444)\\Assignments\\assignment5\\agent_double.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  a = torch.tensor(a)\n"]},{"name":"stdout","output_type":"stream","text":["episode: 0   score: 0.0   memory length: 123   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 0.0\n","episode: 1   score: 4.0   memory length: 418   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 2.0\n","episode: 2   score: 3.0   memory length: 648   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 2.3333333333333335\n","episode: 3   score: 2.0   memory length: 845   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 2.25\n","episode: 4   score: 2.0   memory length: 1043   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 2.2\n","episode: 5   score: 3.0   memory length: 1291   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 2.3333333333333335\n","episode: 6   score: 1.0   memory length: 1461   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 2.142857142857143\n","episode: 7   score: 1.0   memory length: 1633   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 2.0\n","episode: 8   score: 3.0   memory length: 1880   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 2.111111111111111\n","episode: 9   score: 4.0   memory length: 2155   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 2.3\n","episode: 10   score: 0.0   memory length: 2278   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 2.090909090909091\n","episode: 11   score: 1.0   memory length: 2447   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 2.0\n","episode: 12   score: 4.0   memory length: 2743   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 2.1538461538461537\n","episode: 13   score: 0.0   memory length: 2866   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 2.0\n","episode: 14   score: 1.0   memory length: 3034   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.9333333333333333\n","episode: 15   score: 0.0   memory length: 3157   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.8125\n","episode: 16   score: 2.0   memory length: 3355   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.8235294117647058\n","episode: 17   score: 2.0   memory length: 3554   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.8333333333333333\n","episode: 18   score: 2.0   memory length: 3751   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.8421052631578947\n","episode: 19   score: 1.0   memory length: 3920   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.8\n","episode: 20   score: 0.0   memory length: 4042   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.7142857142857142\n","episode: 21   score: 1.0   memory length: 4193   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.6818181818181819\n","episode: 22   score: 2.0   memory length: 4376   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.6956521739130435\n","episode: 23   score: 1.0   memory length: 4527   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.6666666666666667\n","episode: 24   score: 1.0   memory length: 4678   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.64\n","episode: 25   score: 0.0   memory length: 4801   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5769230769230769\n","episode: 26   score: 2.0   memory length: 4999   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5925925925925926\n","episode: 27   score: 1.0   memory length: 5149   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.5714285714285714\n","episode: 28   score: 1.0   memory length: 5318   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5517241379310345\n","episode: 29   score: 4.0   memory length: 5593   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.6333333333333333\n","episode: 30   score: 3.0   memory length: 5861   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.6774193548387097\n","episode: 31   score: 0.0   memory length: 5984   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.625\n","episode: 32   score: 2.0   memory length: 6205   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.6363636363636365\n","episode: 33   score: 4.0   memory length: 6481   epsilon: 1.0    steps: 276    lr: 0.0001     evaluation reward: 1.7058823529411764\n","episode: 34   score: 5.0   memory length: 6786   epsilon: 1.0    steps: 305    lr: 0.0001     evaluation reward: 1.8\n","episode: 35   score: 4.0   memory length: 7078   epsilon: 1.0    steps: 292    lr: 0.0001     evaluation reward: 1.8611111111111112\n","episode: 36   score: 0.0   memory length: 7201   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.8108108108108107\n","episode: 37   score: 1.0   memory length: 7370   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.7894736842105263\n","episode: 38   score: 3.0   memory length: 7614   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.8205128205128205\n","episode: 39   score: 3.0   memory length: 7858   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.85\n","episode: 40   score: 2.0   memory length: 8040   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.853658536585366\n","episode: 41   score: 0.0   memory length: 8163   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.8095238095238095\n","episode: 42   score: 0.0   memory length: 8286   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7674418604651163\n","episode: 43   score: 2.0   memory length: 8501   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.7727272727272727\n","episode: 44   score: 0.0   memory length: 8623   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.7333333333333334\n","episode: 45   score: 1.0   memory length: 8792   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.7173913043478262\n","episode: 46   score: 2.0   memory length: 8992   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.7234042553191489\n","episode: 47   score: 1.0   memory length: 9160   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.7083333333333333\n","episode: 48   score: 0.0   memory length: 9283   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6734693877551021\n","episode: 49   score: 2.0   memory length: 9481   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.68\n","episode: 50   score: 1.0   memory length: 9649   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.6666666666666667\n","episode: 51   score: 2.0   memory length: 9849   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.6730769230769231\n","episode: 52   score: 1.0   memory length: 10000   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.6603773584905661\n","episode: 53   score: 1.0   memory length: 10168   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.6481481481481481\n","episode: 54   score: 2.0   memory length: 10387   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.6545454545454545\n","episode: 55   score: 1.0   memory length: 10556   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.6428571428571428\n","episode: 56   score: 1.0   memory length: 10707   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.631578947368421\n","episode: 57   score: 1.0   memory length: 10877   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.6206896551724137\n","episode: 58   score: 2.0   memory length: 11095   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.6271186440677967\n","episode: 59   score: 2.0   memory length: 11315   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.6333333333333333\n","episode: 60   score: 0.0   memory length: 11438   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6065573770491803\n","episode: 61   score: 4.0   memory length: 11721   epsilon: 1.0    steps: 283    lr: 0.0001     evaluation reward: 1.6451612903225807\n","episode: 62   score: 1.0   memory length: 11892   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.6349206349206349\n","episode: 63   score: 2.0   memory length: 12090   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.640625\n","episode: 64   score: 1.0   memory length: 12241   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.6307692307692307\n","episode: 65   score: 0.0   memory length: 12364   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.606060606060606\n","episode: 66   score: 1.0   memory length: 12533   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5970149253731343\n","episode: 67   score: 1.0   memory length: 12702   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.588235294117647\n","episode: 68   score: 0.0   memory length: 12825   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.565217391304348\n","episode: 69   score: 1.0   memory length: 12994   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5571428571428572\n","episode: 70   score: 2.0   memory length: 13212   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.5633802816901408\n","episode: 71   score: 0.0   memory length: 13335   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5416666666666667\n","episode: 72   score: 0.0   memory length: 13458   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5205479452054795\n","episode: 73   score: 0.0   memory length: 13581   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n","episode: 74   score: 1.0   memory length: 13749   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.4933333333333334\n","episode: 75   score: 0.0   memory length: 13872   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4736842105263157\n","episode: 76   score: 3.0   memory length: 14120   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.4935064935064934\n","episode: 77   score: 2.0   memory length: 14339   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.5\n","episode: 78   score: 2.0   memory length: 14537   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5063291139240507\n","episode: 79   score: 2.0   memory length: 14735   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5125\n","episode: 80   score: 1.0   memory length: 14903   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.5061728395061729\n","episode: 81   score: 1.0   memory length: 15053   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.5\n","episode: 82   score: 1.0   memory length: 15205   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4939759036144578\n","episode: 83   score: 1.0   memory length: 15375   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.4880952380952381\n","episode: 84   score: 0.0   memory length: 15497   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4705882352941178\n","episode: 85   score: 1.0   memory length: 15668   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.4651162790697674\n","episode: 86   score: 2.0   memory length: 15866   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.471264367816092\n","episode: 87   score: 2.0   memory length: 16048   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.4772727272727273\n","episode: 88   score: 0.0   memory length: 16171   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4606741573033708\n","episode: 89   score: 2.0   memory length: 16368   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.4666666666666666\n","episode: 90   score: 9.0   memory length: 16729   epsilon: 1.0    steps: 361    lr: 0.0001     evaluation reward: 1.5494505494505495\n","episode: 91   score: 0.0   memory length: 16852   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5326086956521738\n","episode: 92   score: 0.0   memory length: 16974   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5161290322580645\n","episode: 93   score: 3.0   memory length: 17220   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.5319148936170213\n","episode: 94   score: 1.0   memory length: 17389   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5263157894736843\n","episode: 95   score: 0.0   memory length: 17511   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5104166666666667\n","episode: 96   score: 2.0   memory length: 17732   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.5154639175257731\n","episode: 97   score: 1.0   memory length: 17901   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.510204081632653\n","episode: 98   score: 1.0   memory length: 18052   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.505050505050505\n","episode: 99   score: 1.0   memory length: 18221   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5\n","episode: 100   score: 3.0   memory length: 18467   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.53\n","episode: 101   score: 2.0   memory length: 18686   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.51\n","episode: 102   score: 2.0   memory length: 18901   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.5\n","episode: 103   score: 1.0   memory length: 19073   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.49\n","episode: 104   score: 0.0   memory length: 19196   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n","episode: 105   score: 4.0   memory length: 19492   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 1.48\n","episode: 106   score: 0.0   memory length: 19614   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.47\n","episode: 107   score: 0.0   memory length: 19737   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n","episode: 108   score: 0.0   memory length: 19859   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\n","episode: 109   score: 1.0   memory length: 20028   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.4\n","episode: 110   score: 1.0   memory length: 20178   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.41\n","episode: 111   score: 0.0   memory length: 20300   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4\n","episode: 112   score: 4.0   memory length: 20574   epsilon: 1.0    steps: 274    lr: 0.0001     evaluation reward: 1.4\n","episode: 113   score: 3.0   memory length: 20838   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.43\n","episode: 114   score: 1.0   memory length: 20989   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.43\n","episode: 115   score: 1.0   memory length: 21158   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.44\n","episode: 116   score: 1.0   memory length: 21327   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.43\n","episode: 117   score: 2.0   memory length: 21543   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.43\n","episode: 118   score: 0.0   memory length: 21666   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n","episode: 119   score: 3.0   memory length: 21932   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.43\n","episode: 120   score: 1.0   memory length: 22102   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.44\n","episode: 121   score: 1.0   memory length: 22253   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.44\n","episode: 122   score: 1.0   memory length: 22421   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.43\n","episode: 123   score: 0.0   memory length: 22543   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\n","episode: 124   score: 0.0   memory length: 22666   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n","episode: 125   score: 2.0   memory length: 22864   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\n","episode: 126   score: 4.0   memory length: 23180   epsilon: 1.0    steps: 316    lr: 0.0001     evaluation reward: 1.45\n","episode: 127   score: 3.0   memory length: 23424   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.47\n","episode: 128   score: 3.0   memory length: 23653   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.49\n","episode: 129   score: 0.0   memory length: 23776   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n","episode: 130   score: 0.0   memory length: 23899   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n","episode: 131   score: 0.0   memory length: 24021   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\n","episode: 132   score: 3.0   memory length: 24284   epsilon: 1.0    steps: 263    lr: 0.0001     evaluation reward: 1.43\n","episode: 133   score: 2.0   memory length: 24485   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.41\n","episode: 134   score: 1.0   memory length: 24654   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.37\n","episode: 135   score: 1.0   memory length: 24804   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.34\n","episode: 136   score: 3.0   memory length: 25054   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.37\n","episode: 137   score: 0.0   memory length: 25177   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n","episode: 138   score: 2.0   memory length: 25392   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.35\n","episode: 139   score: 0.0   memory length: 25514   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.32\n","episode: 140   score: 2.0   memory length: 25711   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.32\n","episode: 141   score: 2.0   memory length: 25929   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.34\n","episode: 142   score: 0.0   memory length: 26052   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n","episode: 143   score: 0.0   memory length: 26175   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\n","episode: 144   score: 0.0   memory length: 26298   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\n","episode: 145   score: 5.0   memory length: 26630   epsilon: 1.0    steps: 332    lr: 0.0001     evaluation reward: 1.36\n","episode: 146   score: 5.0   memory length: 26932   epsilon: 1.0    steps: 302    lr: 0.0001     evaluation reward: 1.39\n","episode: 147   score: 0.0   memory length: 27055   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n","episode: 148   score: 2.0   memory length: 27256   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.4\n","episode: 149   score: 2.0   memory length: 27455   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.4\n","episode: 150   score: 1.0   memory length: 27606   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4\n","episode: 151   score: 1.0   memory length: 27757   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.39\n","episode: 152   score: 0.0   memory length: 27880   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n","episode: 153   score: 2.0   memory length: 28077   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.39\n","episode: 154   score: 2.0   memory length: 28277   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.39\n","episode: 155   score: 0.0   memory length: 28400   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n","episode: 156   score: 0.0   memory length: 28523   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n","episode: 157   score: 0.0   memory length: 28645   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.36\n","episode: 158   score: 4.0   memory length: 28939   epsilon: 1.0    steps: 294    lr: 0.0001     evaluation reward: 1.38\n","episode: 159   score: 2.0   memory length: 29137   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.38\n","episode: 160   score: 0.0   memory length: 29259   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.38\n","episode: 161   score: 2.0   memory length: 29459   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.36\n","episode: 162   score: 3.0   memory length: 29671   epsilon: 1.0    steps: 212    lr: 0.0001     evaluation reward: 1.38\n","episode: 163   score: 1.0   memory length: 29843   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.37\n","episode: 164   score: 4.0   memory length: 30098   epsilon: 1.0    steps: 255    lr: 0.0001     evaluation reward: 1.4\n","episode: 165   score: 3.0   memory length: 30349   epsilon: 1.0    steps: 251    lr: 0.0001     evaluation reward: 1.43\n","episode: 166   score: 2.0   memory length: 30568   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.44\n","episode: 167   score: 0.0   memory length: 30691   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n","episode: 168   score: 0.0   memory length: 30813   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\n","episode: 169   score: 1.0   memory length: 30963   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.43\n","episode: 170   score: 0.0   memory length: 31086   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n","episode: 171   score: 0.0   memory length: 31209   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n","episode: 172   score: 1.0   memory length: 31378   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.42\n","episode: 173   score: 2.0   memory length: 31576   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.44\n","episode: 174   score: 1.0   memory length: 31744   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.44\n","episode: 175   score: 4.0   memory length: 32037   epsilon: 1.0    steps: 293    lr: 0.0001     evaluation reward: 1.48\n","episode: 176   score: 1.0   memory length: 32205   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.46\n","episode: 177   score: 1.0   memory length: 32373   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.45\n","episode: 178   score: 2.0   memory length: 32570   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.45\n","episode: 179   score: 0.0   memory length: 32693   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n","episode: 180   score: 2.0   memory length: 32909   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.44\n","episode: 181   score: 1.0   memory length: 33081   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.44\n","episode: 182   score: 3.0   memory length: 33326   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.46\n","episode: 183   score: 2.0   memory length: 33506   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.47\n","episode: 184   score: 2.0   memory length: 33688   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.49\n","episode: 185   score: 0.0   memory length: 33811   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n","episode: 186   score: 0.0   memory length: 33933   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.46\n","episode: 187   score: 1.0   memory length: 34102   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\n","episode: 188   score: 0.0   memory length: 34225   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n","episode: 189   score: 3.0   memory length: 34473   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.46\n","episode: 190   score: 1.0   memory length: 34623   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.38\n","episode: 191   score: 2.0   memory length: 34840   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.4\n","episode: 192   score: 1.0   memory length: 35009   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\n","episode: 193   score: 0.0   memory length: 35132   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n","episode: 194   score: 3.0   memory length: 35401   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.4\n","episode: 195   score: 3.0   memory length: 35667   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.43\n","episode: 196   score: 1.0   memory length: 35817   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.42\n","episode: 197   score: 3.0   memory length: 36086   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.44\n","episode: 198   score: 1.0   memory length: 36258   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.44\n","episode: 199   score: 1.0   memory length: 36409   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.44\n","episode: 200   score: 0.0   memory length: 36531   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.41\n","episode: 201   score: 3.0   memory length: 36758   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.42\n","episode: 202   score: 2.0   memory length: 36956   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.42\n","episode: 203   score: 1.0   memory length: 37108   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.42\n","episode: 204   score: 1.0   memory length: 37279   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.43\n","episode: 205   score: 3.0   memory length: 37524   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.42\n","episode: 206   score: 0.0   memory length: 37646   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\n","episode: 207   score: 3.0   memory length: 37912   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.45\n","episode: 208   score: 3.0   memory length: 38179   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.48\n","episode: 209   score: 2.0   memory length: 38398   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.49\n","episode: 210   score: 0.0   memory length: 38521   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n","episode: 211   score: 3.0   memory length: 38788   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.51\n","episode: 212   score: 1.0   memory length: 38956   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.48\n","episode: 213   score: 1.0   memory length: 39125   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.46\n","episode: 214   score: 2.0   memory length: 39343   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.47\n","episode: 215   score: 2.0   memory length: 39565   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.48\n","episode: 216   score: 1.0   memory length: 39734   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.48\n","episode: 217   score: 3.0   memory length: 40000   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.49\n","episode: 218   score: 0.0   memory length: 40123   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\n","episode: 219   score: 3.0   memory length: 40393   epsilon: 1.0    steps: 270    lr: 0.0001     evaluation reward: 1.49\n","episode: 220   score: 1.0   memory length: 40564   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.49\n","episode: 221   score: 2.0   memory length: 40761   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.5\n","episode: 222   score: 1.0   memory length: 40930   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5\n","episode: 223   score: 2.0   memory length: 41131   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.52\n","episode: 224   score: 2.0   memory length: 41353   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.54\n","episode: 225   score: 0.0   memory length: 41475   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.52\n","episode: 226   score: 2.0   memory length: 41672   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.5\n","episode: 227   score: 4.0   memory length: 41947   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.51\n","episode: 228   score: 3.0   memory length: 42191   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.51\n","episode: 229   score: 1.0   memory length: 42341   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.52\n","episode: 230   score: 0.0   memory length: 42464   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\n","episode: 231   score: 0.0   memory length: 42586   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.52\n","episode: 232   score: 0.0   memory length: 42708   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.49\n","episode: 233   score: 4.0   memory length: 42966   epsilon: 1.0    steps: 258    lr: 0.0001     evaluation reward: 1.51\n","episode: 234   score: 0.0   memory length: 43089   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n","episode: 235   score: 1.0   memory length: 43241   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.5\n","episode: 236   score: 1.0   memory length: 43413   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.48\n","episode: 237   score: 3.0   memory length: 43624   epsilon: 1.0    steps: 211    lr: 0.0001     evaluation reward: 1.51\n","episode: 238   score: 3.0   memory length: 43870   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.52\n","episode: 239   score: 4.0   memory length: 44185   epsilon: 1.0    steps: 315    lr: 0.0001     evaluation reward: 1.56\n","episode: 240   score: 1.0   memory length: 44357   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.55\n","episode: 241   score: 1.0   memory length: 44508   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.54\n","episode: 242   score: 0.0   memory length: 44631   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\n","episode: 243   score: 0.0   memory length: 44754   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\n","episode: 244   score: 1.0   memory length: 44923   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.55\n","episode: 245   score: 6.0   memory length: 45297   epsilon: 1.0    steps: 374    lr: 0.0001     evaluation reward: 1.56\n","episode: 246   score: 1.0   memory length: 45466   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.52\n","episode: 247   score: 0.0   memory length: 45588   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.52\n","episode: 248   score: 1.0   memory length: 45757   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.51\n","episode: 249   score: 3.0   memory length: 46001   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.52\n","episode: 250   score: 1.0   memory length: 46170   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.52\n","episode: 251   score: 2.0   memory length: 46388   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.53\n","episode: 252   score: 0.0   memory length: 46510   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.53\n","episode: 253   score: 1.0   memory length: 46678   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.52\n","episode: 254   score: 1.0   memory length: 46849   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.51\n","episode: 255   score: 1.0   memory length: 47021   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.52\n","episode: 256   score: 1.0   memory length: 47171   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.53\n","episode: 257   score: 2.0   memory length: 47369   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.55\n","episode: 258   score: 2.0   memory length: 47568   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.53\n","episode: 259   score: 2.0   memory length: 47768   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.53\n","episode: 260   score: 2.0   memory length: 47965   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.55\n","episode: 261   score: 1.0   memory length: 48136   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.54\n","episode: 262   score: 2.0   memory length: 48337   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.53\n","episode: 263   score: 0.0   memory length: 48460   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\n","episode: 264   score: 1.0   memory length: 48628   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.49\n","episode: 265   score: 2.0   memory length: 48844   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.48\n","episode: 266   score: 3.0   memory length: 49091   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.49\n","episode: 267   score: 2.0   memory length: 49294   epsilon: 1.0    steps: 203    lr: 0.0001     evaluation reward: 1.51\n","episode: 268   score: 4.0   memory length: 49568   epsilon: 1.0    steps: 274    lr: 0.0001     evaluation reward: 1.55\n","episode: 269   score: 2.0   memory length: 49768   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.56\n","episode: 270   score: 1.0   memory length: 49937   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.57\n","episode: 271   score: 3.0   memory length: 50162   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.6\n","episode: 272   score: 2.0   memory length: 50342   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.61\n","episode: 273   score: 2.0   memory length: 50540   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.61\n","episode: 274   score: 1.0   memory length: 50708   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.61\n","episode: 275   score: 2.0   memory length: 50926   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.59\n","episode: 276   score: 2.0   memory length: 51143   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.6\n","episode: 277   score: 1.0   memory length: 51314   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.6\n","episode: 278   score: 0.0   memory length: 51436   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.58\n","episode: 279   score: 0.0   memory length: 51559   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\n","episode: 280   score: 0.0   memory length: 51682   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\n","episode: 281   score: 0.0   memory length: 51804   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.55\n","episode: 282   score: 2.0   memory length: 51984   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.54\n","episode: 283   score: 1.0   memory length: 52156   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.53\n","episode: 284   score: 2.0   memory length: 52376   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.53\n","episode: 285   score: 6.0   memory length: 52712   epsilon: 1.0    steps: 336    lr: 0.0001     evaluation reward: 1.59\n","episode: 286   score: 1.0   memory length: 52881   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.6\n","episode: 287   score: 3.0   memory length: 53130   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.62\n","episode: 288   score: 1.0   memory length: 53299   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.63\n","episode: 289   score: 4.0   memory length: 53574   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.64\n","episode: 290   score: 3.0   memory length: 53800   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.66\n","episode: 291   score: 4.0   memory length: 54092   epsilon: 1.0    steps: 292    lr: 0.0001     evaluation reward: 1.68\n","episode: 292   score: 1.0   memory length: 54243   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.68\n","episode: 293   score: 0.0   memory length: 54366   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.68\n","episode: 294   score: 0.0   memory length: 54489   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.65\n","episode: 295   score: 1.0   memory length: 54640   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.63\n","episode: 296   score: 2.0   memory length: 54837   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.64\n","episode: 297   score: 5.0   memory length: 55182   epsilon: 1.0    steps: 345    lr: 0.0001     evaluation reward: 1.66\n","episode: 298   score: 2.0   memory length: 55380   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.67\n","episode: 299   score: 0.0   memory length: 55503   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.66\n","episode: 300   score: 3.0   memory length: 55749   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.69\n","episode: 301   score: 1.0   memory length: 55900   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.67\n","episode: 302   score: 3.0   memory length: 56167   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.68\n","episode: 303   score: 3.0   memory length: 56410   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.7\n","episode: 304   score: 0.0   memory length: 56533   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.69\n","episode: 305   score: 0.0   memory length: 56656   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.66\n","episode: 306   score: 0.0   memory length: 56779   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.66\n","episode: 307   score: 1.0   memory length: 56948   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.64\n","episode: 308   score: 1.0   memory length: 57117   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.62\n","episode: 309   score: 1.0   memory length: 57268   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.61\n","episode: 310   score: 0.0   memory length: 57391   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\n","episode: 311   score: 3.0   memory length: 57639   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.61\n","episode: 312   score: 2.0   memory length: 57819   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.62\n","episode: 313   score: 2.0   memory length: 58036   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.63\n","episode: 314   score: 1.0   memory length: 58187   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.62\n","episode: 315   score: 0.0   memory length: 58310   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\n","episode: 316   score: 3.0   memory length: 58578   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.62\n","episode: 317   score: 3.0   memory length: 58826   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.62\n","episode: 318   score: 2.0   memory length: 59024   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.64\n","episode: 319   score: 0.0   memory length: 59147   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\n","episode: 320   score: 1.0   memory length: 59315   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.61\n","episode: 321   score: 2.0   memory length: 59512   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.61\n","episode: 322   score: 0.0   memory length: 59635   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\n","episode: 323   score: 1.0   memory length: 59787   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.59\n","episode: 324   score: 3.0   memory length: 60056   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.6\n","episode: 325   score: 0.0   memory length: 60178   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6\n","episode: 326   score: 3.0   memory length: 60427   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.61\n","episode: 327   score: 1.0   memory length: 60596   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.58\n","episode: 328   score: 1.0   memory length: 60764   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.56\n","episode: 329   score: 2.0   memory length: 60961   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.57\n","episode: 330   score: 1.0   memory length: 61131   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.58\n","episode: 331   score: 3.0   memory length: 61379   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.61\n","episode: 332   score: 3.0   memory length: 61606   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.64\n","episode: 333   score: 0.0   memory length: 61728   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6\n","episode: 334   score: 2.0   memory length: 61926   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.62\n","episode: 335   score: 1.0   memory length: 62095   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.62\n","episode: 336   score: 0.0   memory length: 62218   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\n","episode: 337   score: 1.0   memory length: 62369   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.59\n","episode: 338   score: 4.0   memory length: 62644   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.6\n","episode: 339   score: 2.0   memory length: 62862   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.58\n","episode: 340   score: 0.0   memory length: 62984   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.57\n","episode: 341   score: 1.0   memory length: 63153   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.57\n","episode: 342   score: 0.0   memory length: 63276   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\n","episode: 343   score: 0.0   memory length: 63399   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\n","episode: 344   score: 1.0   memory length: 63571   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.57\n","episode: 345   score: 0.0   memory length: 63694   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n","episode: 346   score: 0.0   memory length: 63817   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n","episode: 347   score: 4.0   memory length: 64092   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.54\n","episode: 348   score: 2.0   memory length: 64290   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.55\n","episode: 349   score: 0.0   memory length: 64413   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\n","episode: 350   score: 0.0   memory length: 64535   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.51\n","episode: 351   score: 2.0   memory length: 64753   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.51\n","episode: 352   score: 2.0   memory length: 64951   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.53\n","episode: 353   score: 0.0   memory length: 65073   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.52\n","episode: 354   score: 0.0   memory length: 65196   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n","episode: 355   score: 0.0   memory length: 65318   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5\n","episode: 356   score: 0.0   memory length: 65441   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\n","episode: 357   score: 1.0   memory length: 65591   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.48\n","episode: 358   score: 1.0   memory length: 65762   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.47\n","episode: 359   score: 0.0   memory length: 65884   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.45\n","episode: 360   score: 1.0   memory length: 66035   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.44\n","episode: 361   score: 2.0   memory length: 66232   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.45\n","episode: 362   score: 2.0   memory length: 66430   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.45\n","episode: 363   score: 2.0   memory length: 66628   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.47\n","episode: 364   score: 0.0   memory length: 66751   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n","episode: 365   score: 1.0   memory length: 66920   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\n","episode: 366   score: 1.0   memory length: 67090   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.43\n","episode: 367   score: 2.0   memory length: 67307   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.43\n","episode: 368   score: 4.0   memory length: 67603   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 1.43\n","episode: 369   score: 0.0   memory length: 67726   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n","episode: 370   score: 0.0   memory length: 67849   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n","episode: 371   score: 3.0   memory length: 68096   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.4\n","episode: 372   score: 1.0   memory length: 68266   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.39\n","episode: 373   score: 7.0   memory length: 68634   epsilon: 1.0    steps: 368    lr: 0.0001     evaluation reward: 1.44\n","episode: 374   score: 2.0   memory length: 68850   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.45\n","episode: 375   score: 1.0   memory length: 69021   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.44\n","episode: 376   score: 0.0   memory length: 69143   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\n","episode: 377   score: 0.0   memory length: 69265   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.41\n","episode: 378   score: 1.0   memory length: 69437   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.42\n","episode: 379   score: 2.0   memory length: 69652   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.44\n","episode: 380   score: 0.0   memory length: 69774   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.44\n","episode: 381   score: 2.0   memory length: 69974   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.46\n","episode: 382   score: 0.0   memory length: 70096   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.44\n","episode: 383   score: 0.0   memory length: 70219   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n","episode: 384   score: 4.0   memory length: 70514   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.45\n","episode: 385   score: 3.0   memory length: 70762   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.42\n","episode: 386   score: 1.0   memory length: 70915   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.42\n","episode: 387   score: 2.0   memory length: 71131   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.41\n","episode: 388   score: 1.0   memory length: 71300   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\n","episode: 389   score: 1.0   memory length: 71451   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.38\n","episode: 390   score: 1.0   memory length: 71602   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.36\n","episode: 391   score: 0.0   memory length: 71724   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.32\n","episode: 392   score: 0.0   memory length: 71847   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.31\n","episode: 393   score: 2.0   memory length: 72064   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.33\n","episode: 394   score: 1.0   memory length: 72236   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.34\n","episode: 395   score: 2.0   memory length: 72452   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.35\n","episode: 396   score: 2.0   memory length: 72670   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.35\n","episode: 397   score: 0.0   memory length: 72793   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n","episode: 398   score: 0.0   memory length: 72915   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.28\n","episode: 399   score: 2.0   memory length: 73132   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.3\n","episode: 400   score: 0.0   memory length: 73255   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.27\n","episode: 401   score: 4.0   memory length: 73551   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 1.3\n","episode: 402   score: 1.0   memory length: 73702   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.28\n","episode: 403   score: 0.0   memory length: 73824   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.25\n","episode: 404   score: 1.0   memory length: 73996   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.26\n","episode: 405   score: 0.0   memory length: 74119   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.26\n","episode: 406   score: 0.0   memory length: 74242   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.26\n","episode: 407   score: 2.0   memory length: 74422   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.27\n","episode: 408   score: 1.0   memory length: 74573   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.27\n","episode: 409   score: 3.0   memory length: 74804   epsilon: 1.0    steps: 231    lr: 0.0001     evaluation reward: 1.29\n","episode: 410   score: 1.0   memory length: 74954   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.3\n","episode: 411   score: 5.0   memory length: 75322   epsilon: 1.0    steps: 368    lr: 0.0001     evaluation reward: 1.32\n","episode: 412   score: 1.0   memory length: 75491   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.31\n","episode: 413   score: 3.0   memory length: 75739   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.32\n","episode: 414   score: 0.0   memory length: 75861   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.31\n","episode: 415   score: 1.0   memory length: 76012   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.32\n","episode: 416   score: 0.0   memory length: 76135   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.29\n","episode: 417   score: 2.0   memory length: 76332   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.28\n","episode: 418   score: 1.0   memory length: 76483   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.27\n","episode: 419   score: 0.0   memory length: 76606   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.27\n","episode: 420   score: 3.0   memory length: 76835   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.29\n","episode: 421   score: 0.0   memory length: 76958   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.27\n","episode: 422   score: 3.0   memory length: 77204   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.3\n","episode: 423   score: 1.0   memory length: 77355   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.3\n","episode: 424   score: 0.0   memory length: 77478   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.27\n","episode: 425   score: 0.0   memory length: 77600   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.27\n","episode: 426   score: 0.0   memory length: 77723   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.24\n","episode: 427   score: 1.0   memory length: 77892   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.24\n","episode: 428   score: 2.0   memory length: 78089   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.25\n","episode: 429   score: 5.0   memory length: 78432   epsilon: 1.0    steps: 343    lr: 0.0001     evaluation reward: 1.28\n","episode: 430   score: 6.0   memory length: 78804   epsilon: 1.0    steps: 372    lr: 0.0001     evaluation reward: 1.33\n","episode: 431   score: 2.0   memory length: 78986   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.32\n","episode: 432   score: 2.0   memory length: 79166   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.31\n","episode: 433   score: 4.0   memory length: 79431   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.35\n","episode: 434   score: 0.0   memory length: 79554   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\n","episode: 435   score: 2.0   memory length: 79733   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.34\n","episode: 436   score: 0.0   memory length: 79856   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n","episode: 437   score: 2.0   memory length: 80074   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.35\n","episode: 438   score: 2.0   memory length: 80276   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.33\n","episode: 439   score: 1.0   memory length: 80427   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.32\n","episode: 440   score: 1.0   memory length: 80599   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.33\n","episode: 441   score: 0.0   memory length: 80722   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\n","episode: 442   score: 3.0   memory length: 80969   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.35\n","episode: 443   score: 2.0   memory length: 81167   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.37\n","episode: 444   score: 1.0   memory length: 81339   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.37\n","episode: 445   score: 0.0   memory length: 81462   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n","episode: 446   score: 2.0   memory length: 81661   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.39\n","episode: 447   score: 1.0   memory length: 81811   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.36\n","episode: 448   score: 3.0   memory length: 82040   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.37\n","episode: 449   score: 0.0   memory length: 82163   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n","episode: 450   score: 2.0   memory length: 82380   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.39\n","episode: 451   score: 0.0   memory length: 82503   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n","episode: 452   score: 2.0   memory length: 82720   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.37\n","episode: 453   score: 2.0   memory length: 82937   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.39\n","episode: 454   score: 0.0   memory length: 83060   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n","episode: 455   score: 0.0   memory length: 83183   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n","episode: 456   score: 2.0   memory length: 83380   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.41\n","episode: 457   score: 0.0   memory length: 83502   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4\n","episode: 458   score: 0.0   memory length: 83625   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n","episode: 459   score: 1.0   memory length: 83793   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.4\n","episode: 460   score: 0.0   memory length: 83916   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n","episode: 461   score: 0.0   memory length: 84039   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n","episode: 462   score: 5.0   memory length: 84369   epsilon: 1.0    steps: 330    lr: 0.0001     evaluation reward: 1.4\n","episode: 463   score: 0.0   memory length: 84492   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n","episode: 464   score: 0.0   memory length: 84615   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n","episode: 465   score: 0.0   memory length: 84738   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n","episode: 466   score: 0.0   memory length: 84861   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n","episode: 467   score: 1.0   memory length: 85031   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.35\n","episode: 468   score: 0.0   memory length: 85154   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.31\n","episode: 469   score: 1.0   memory length: 85323   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.32\n","episode: 470   score: 4.0   memory length: 85582   epsilon: 1.0    steps: 259    lr: 0.0001     evaluation reward: 1.36\n","episode: 471   score: 3.0   memory length: 85807   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.36\n","episode: 472   score: 2.0   memory length: 86029   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.37\n","episode: 473   score: 0.0   memory length: 86152   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n","episode: 474   score: 0.0   memory length: 86275   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.28\n","episode: 475   score: 5.0   memory length: 86594   epsilon: 1.0    steps: 319    lr: 0.0001     evaluation reward: 1.32\n","episode: 476   score: 1.0   memory length: 86762   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.33\n","episode: 477   score: 2.0   memory length: 86981   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.35\n","episode: 478   score: 2.0   memory length: 87178   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.36\n","episode: 479   score: 0.0   memory length: 87301   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n","episode: 480   score: 3.0   memory length: 87549   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.37\n","episode: 481   score: 0.0   memory length: 87671   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.35\n","episode: 482   score: 2.0   memory length: 87868   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.37\n","episode: 483   score: 3.0   memory length: 88114   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.4\n","episode: 484   score: 3.0   memory length: 88380   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.39\n","episode: 485   score: 3.0   memory length: 88649   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.39\n","episode: 486   score: 3.0   memory length: 88899   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.41\n","episode: 487   score: 1.0   memory length: 89068   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.4\n","episode: 488   score: 5.0   memory length: 89396   epsilon: 1.0    steps: 328    lr: 0.0001     evaluation reward: 1.44\n","episode: 489   score: 1.0   memory length: 89565   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.44\n","episode: 490   score: 2.0   memory length: 89762   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.45\n","episode: 491   score: 1.0   memory length: 89932   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.46\n","episode: 492   score: 2.0   memory length: 90148   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.48\n","episode: 493   score: 0.0   memory length: 90271   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n","episode: 494   score: 2.0   memory length: 90469   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.47\n","episode: 495   score: 1.0   memory length: 90620   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.46\n","episode: 496   score: 0.0   memory length: 90743   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\n","episode: 497   score: 2.0   memory length: 90964   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.46\n","episode: 498   score: 2.0   memory length: 91164   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.48\n","episode: 499   score: 0.0   memory length: 91287   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n","episode: 500   score: 2.0   memory length: 91485   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.48\n","episode: 501   score: 1.0   memory length: 91636   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.45\n","episode: 502   score: 1.0   memory length: 91787   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.45\n","episode: 503   score: 1.0   memory length: 91958   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.46\n","episode: 504   score: 2.0   memory length: 92137   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.47\n","episode: 505   score: 0.0   memory length: 92259   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.47\n","episode: 506   score: 0.0   memory length: 92382   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n","episode: 507   score: 3.0   memory length: 92629   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.48\n","episode: 508   score: 0.0   memory length: 92751   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.47\n","episode: 509   score: 1.0   memory length: 92921   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.45\n","episode: 510   score: 4.0   memory length: 93216   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.48\n","episode: 511   score: 1.0   memory length: 93387   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.44\n","episode: 512   score: 3.0   memory length: 93630   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.46\n","episode: 513   score: 3.0   memory length: 93877   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.46\n","episode: 514   score: 2.0   memory length: 94079   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.48\n","episode: 515   score: 0.0   memory length: 94202   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n","episode: 516   score: 2.0   memory length: 94400   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\n","episode: 517   score: 1.0   memory length: 94569   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.48\n","episode: 518   score: 1.0   memory length: 94720   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.48\n","episode: 519   score: 3.0   memory length: 94947   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.51\n","episode: 520   score: 2.0   memory length: 95144   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.5\n","episode: 521   score: 1.0   memory length: 95294   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.51\n","episode: 522   score: 2.0   memory length: 95512   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.5\n","episode: 523   score: 2.0   memory length: 95712   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.51\n","episode: 524   score: 0.0   memory length: 95834   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.51\n","episode: 525   score: 2.0   memory length: 96031   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.53\n","episode: 526   score: 3.0   memory length: 96278   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.56\n","episode: 527   score: 1.0   memory length: 96449   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.56\n","episode: 528   score: 2.0   memory length: 96629   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.56\n","episode: 529   score: 0.0   memory length: 96751   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.51\n","episode: 530   score: 0.0   memory length: 96874   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n","episode: 531   score: 0.0   memory length: 96996   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\n","episode: 532   score: 2.0   memory length: 97194   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\n","episode: 533   score: 0.0   memory length: 97317   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n","episode: 534   score: 1.0   memory length: 97485   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.4\n","episode: 535   score: 2.0   memory length: 97703   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.4\n","episode: 536   score: 1.0   memory length: 97873   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.41\n","episode: 537   score: 1.0   memory length: 98042   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.4\n","episode: 538   score: 2.0   memory length: 98259   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.4\n","episode: 539   score: 1.0   memory length: 98428   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.4\n","episode: 540   score: 0.0   memory length: 98551   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n","episode: 541   score: 2.0   memory length: 98770   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.41\n","episode: 542   score: 3.0   memory length: 99020   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.41\n","episode: 543   score: 2.0   memory length: 99237   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.41\n","episode: 544   score: 1.0   memory length: 99388   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.41\n","episode: 545   score: 3.0   memory length: 99617   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.44\n","episode: 546   score: 1.0   memory length: 99788   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.43\n","episode: 547   score: 0.0   memory length: 99911   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n"]},{"name":"stderr","output_type":"stream","text":["e:\\Personal_Stuff\\UIUC\\Sem_2\\DL for CV (CS_444)\\Assignments\\assignment5\\memory.py:29: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n","  sample = np.array(sample, dtype=object)\n","e:\\Personal_Stuff\\UIUC\\Sem_2\\DL for CV (CS_444)\\Assignments\\assignment5\\agent_double.py:78: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n","  mini_batch = np.array(mini_batch, dtype=object).transpose()\n"]},{"name":"stdout","output_type":"stream","text":["episode: 548   score: 2.0   memory length: 100109   epsilon: 0.9997822000000047    steps: 198    lr: 0.0001     evaluation reward: 1.41\n","episode: 549   score: 2.0   memory length: 100306   epsilon: 0.9993921400000132    steps: 197    lr: 0.0001     evaluation reward: 1.43\n","episode: 550   score: 0.0   memory length: 100429   epsilon: 0.9991486000000185    steps: 123    lr: 0.0001     evaluation reward: 1.41\n","episode: 551   score: 2.0   memory length: 100647   epsilon: 0.9987169600000279    steps: 218    lr: 0.0001     evaluation reward: 1.43\n","episode: 552   score: 0.0   memory length: 100769   epsilon: 0.9984754000000331    steps: 122    lr: 0.0001     evaluation reward: 1.41\n","episode: 553   score: 0.0   memory length: 100891   epsilon: 0.9982338400000383    steps: 122    lr: 0.0001     evaluation reward: 1.39\n","episode: 554   score: 2.0   memory length: 101089   epsilon: 0.9978418000000469    steps: 198    lr: 0.0001     evaluation reward: 1.41\n","episode: 555   score: 0.0   memory length: 101212   epsilon: 0.9975982600000521    steps: 123    lr: 0.0001     evaluation reward: 1.41\n","episode: 556   score: 2.0   memory length: 101430   epsilon: 0.9971666200000615    steps: 218    lr: 0.0001     evaluation reward: 1.41\n","episode: 557   score: 0.0   memory length: 101553   epsilon: 0.9969230800000668    steps: 123    lr: 0.0001     evaluation reward: 1.41\n","episode: 558   score: 3.0   memory length: 101796   epsilon: 0.9964419400000772    steps: 243    lr: 0.0001     evaluation reward: 1.44\n","episode: 559   score: 3.0   memory length: 102025   epsilon: 0.9959885200000871    steps: 229    lr: 0.0001     evaluation reward: 1.46\n","episode: 560   score: 3.0   memory length: 102252   epsilon: 0.9955390600000968    steps: 227    lr: 0.0001     evaluation reward: 1.49\n","episode: 561   score: 0.0   memory length: 102375   epsilon: 0.9952955200001021    steps: 123    lr: 0.0001     evaluation reward: 1.49\n","episode: 562   score: 2.0   memory length: 102594   epsilon: 0.9948619000001115    steps: 219    lr: 0.0001     evaluation reward: 1.46\n","episode: 563   score: 2.0   memory length: 102792   epsilon: 0.99446986000012    steps: 198    lr: 0.0001     evaluation reward: 1.48\n","episode: 564   score: 1.0   memory length: 102962   epsilon: 0.9941332600001274    steps: 170    lr: 0.0001     evaluation reward: 1.49\n","episode: 565   score: 0.0   memory length: 103085   epsilon: 0.9938897200001326    steps: 123    lr: 0.0001     evaluation reward: 1.49\n","episode: 566   score: 1.0   memory length: 103236   epsilon: 0.9935907400001391    steps: 151    lr: 0.0001     evaluation reward: 1.5\n","episode: 567   score: 3.0   memory length: 103463   epsilon: 0.9931412800001489    steps: 227    lr: 0.0001     evaluation reward: 1.52\n","episode: 568   score: 2.0   memory length: 103663   epsilon: 0.9927452800001575    steps: 200    lr: 0.0001     evaluation reward: 1.54\n","episode: 569   score: 0.0   memory length: 103785   epsilon: 0.9925037200001627    steps: 122    lr: 0.0001     evaluation reward: 1.53\n","episode: 570   score: 2.0   memory length: 103967   epsilon: 0.9921433600001706    steps: 182    lr: 0.0001     evaluation reward: 1.51\n","episode: 571   score: 1.0   memory length: 104137   epsilon: 0.9918067600001779    steps: 170    lr: 0.0001     evaluation reward: 1.49\n","episode: 572   score: 2.0   memory length: 104355   epsilon: 0.9913751200001872    steps: 218    lr: 0.0001     evaluation reward: 1.49\n","episode: 573   score: 0.0   memory length: 104478   epsilon: 0.9911315800001925    steps: 123    lr: 0.0001     evaluation reward: 1.49\n","episode: 574   score: 1.0   memory length: 104629   epsilon: 0.990832600000199    steps: 151    lr: 0.0001     evaluation reward: 1.5\n","episode: 575   score: 0.0   memory length: 104752   epsilon: 0.9905890600002043    steps: 123    lr: 0.0001     evaluation reward: 1.45\n","episode: 576   score: 2.0   memory length: 104951   epsilon: 0.9901950400002129    steps: 199    lr: 0.0001     evaluation reward: 1.46\n","episode: 577   score: 3.0   memory length: 105180   epsilon: 0.9897416200002227    steps: 229    lr: 0.0001     evaluation reward: 1.47\n","episode: 578   score: 2.0   memory length: 105398   epsilon: 0.9893099800002321    steps: 218    lr: 0.0001     evaluation reward: 1.47\n","episode: 579   score: 0.0   memory length: 105521   epsilon: 0.9890664400002374    steps: 123    lr: 0.0001     evaluation reward: 1.47\n","episode: 580   score: 1.0   memory length: 105671   epsilon: 0.9887694400002438    steps: 150    lr: 0.0001     evaluation reward: 1.45\n","episode: 581   score: 2.0   memory length: 105868   epsilon: 0.9883793800002523    steps: 197    lr: 0.0001     evaluation reward: 1.47\n","episode: 582   score: 0.0   memory length: 105990   epsilon: 0.9881378200002575    steps: 122    lr: 0.0001     evaluation reward: 1.45\n","episode: 583   score: 0.0   memory length: 106112   epsilon: 0.9878962600002628    steps: 122    lr: 0.0001     evaluation reward: 1.42\n","episode: 584   score: 1.0   memory length: 106262   epsilon: 0.9875992600002692    steps: 150    lr: 0.0001     evaluation reward: 1.4\n","episode: 585   score: 2.0   memory length: 106480   epsilon: 0.9871676200002786    steps: 218    lr: 0.0001     evaluation reward: 1.39\n","episode: 586   score: 1.0   memory length: 106649   epsilon: 0.9868330000002858    steps: 169    lr: 0.0001     evaluation reward: 1.37\n","episode: 587   score: 1.0   memory length: 106820   epsilon: 0.9864944200002932    steps: 171    lr: 0.0001     evaluation reward: 1.37\n","episode: 588   score: 3.0   memory length: 107065   epsilon: 0.9860093200003037    steps: 245    lr: 0.0001     evaluation reward: 1.35\n","episode: 589   score: 0.0   memory length: 107187   epsilon: 0.985767760000309    steps: 122    lr: 0.0001     evaluation reward: 1.34\n","episode: 590   score: 1.0   memory length: 107356   epsilon: 0.9854331400003162    steps: 169    lr: 0.0001     evaluation reward: 1.33\n","episode: 591   score: 0.0   memory length: 107479   epsilon: 0.9851896000003215    steps: 123    lr: 0.0001     evaluation reward: 1.32\n","episode: 592   score: 0.0   memory length: 107602   epsilon: 0.9849460600003268    steps: 123    lr: 0.0001     evaluation reward: 1.3\n","episode: 593   score: 1.0   memory length: 107771   epsilon: 0.9846114400003341    steps: 169    lr: 0.0001     evaluation reward: 1.31\n","episode: 594   score: 2.0   memory length: 107968   epsilon: 0.9842213800003425    steps: 197    lr: 0.0001     evaluation reward: 1.31\n","episode: 595   score: 1.0   memory length: 108137   epsilon: 0.9838867600003498    steps: 169    lr: 0.0001     evaluation reward: 1.31\n","episode: 596   score: 0.0   memory length: 108259   epsilon: 0.983645200000355    steps: 122    lr: 0.0001     evaluation reward: 1.31\n","episode: 597   score: 1.0   memory length: 108428   epsilon: 0.9833105800003623    steps: 169    lr: 0.0001     evaluation reward: 1.3\n","episode: 598   score: 1.0   memory length: 108597   epsilon: 0.9829759600003696    steps: 169    lr: 0.0001     evaluation reward: 1.29\n","episode: 599   score: 0.0   memory length: 108720   epsilon: 0.9827324200003749    steps: 123    lr: 0.0001     evaluation reward: 1.29\n","episode: 600   score: 3.0   memory length: 108964   epsilon: 0.9822493000003854    steps: 244    lr: 0.0001     evaluation reward: 1.3\n","episode: 601   score: 2.0   memory length: 109165   epsilon: 0.981851320000394    steps: 201    lr: 0.0001     evaluation reward: 1.31\n","episode: 602   score: 1.0   memory length: 109333   epsilon: 0.9815186800004012    steps: 168    lr: 0.0001     evaluation reward: 1.31\n","episode: 603   score: 0.0   memory length: 109456   epsilon: 0.9812751400004065    steps: 123    lr: 0.0001     evaluation reward: 1.3\n","episode: 604   score: 4.0   memory length: 109775   epsilon: 0.9806435200004202    steps: 319    lr: 0.0001     evaluation reward: 1.32\n","episode: 605   score: 2.0   memory length: 109993   epsilon: 0.9802118800004296    steps: 218    lr: 0.0001     evaluation reward: 1.34\n","episode: 606   score: 0.0   memory length: 110116   epsilon: 0.9799683400004349    steps: 123    lr: 0.0001     evaluation reward: 1.34\n","episode: 607   score: 2.0   memory length: 110336   epsilon: 0.9795327400004443    steps: 220    lr: 0.0001     evaluation reward: 1.33\n","episode: 608   score: 1.0   memory length: 110487   epsilon: 0.9792337600004508    steps: 151    lr: 0.0001     evaluation reward: 1.34\n","episode: 609   score: 0.0   memory length: 110610   epsilon: 0.9789902200004561    steps: 123    lr: 0.0001     evaluation reward: 1.33\n","episode: 610   score: 2.0   memory length: 110808   epsilon: 0.9785981800004646    steps: 198    lr: 0.0001     evaluation reward: 1.31\n","episode: 611   score: 3.0   memory length: 111074   epsilon: 0.978071500000476    steps: 266    lr: 0.0001     evaluation reward: 1.33\n","episode: 612   score: 3.0   memory length: 111320   epsilon: 0.9775844200004866    steps: 246    lr: 0.0001     evaluation reward: 1.33\n","episode: 613   score: 1.0   memory length: 111488   epsilon: 0.9772517800004938    steps: 168    lr: 0.0001     evaluation reward: 1.31\n","episode: 614   score: 5.0   memory length: 111785   epsilon: 0.9766637200005066    steps: 297    lr: 0.0001     evaluation reward: 1.34\n","episode: 615   score: 4.0   memory length: 112082   epsilon: 0.9760756600005194    steps: 297    lr: 0.0001     evaluation reward: 1.38\n","episode: 616   score: 0.0   memory length: 112204   epsilon: 0.9758341000005246    steps: 122    lr: 0.0001     evaluation reward: 1.36\n","episode: 617   score: 1.0   memory length: 112373   epsilon: 0.9754994800005319    steps: 169    lr: 0.0001     evaluation reward: 1.36\n","episode: 618   score: 2.0   memory length: 112571   epsilon: 0.9751074400005404    steps: 198    lr: 0.0001     evaluation reward: 1.37\n","episode: 619   score: 1.0   memory length: 112722   epsilon: 0.9748084600005469    steps: 151    lr: 0.0001     evaluation reward: 1.35\n","episode: 620   score: 0.0   memory length: 112845   epsilon: 0.9745649200005522    steps: 123    lr: 0.0001     evaluation reward: 1.33\n","episode: 621   score: 3.0   memory length: 113093   epsilon: 0.9740738800005628    steps: 248    lr: 0.0001     evaluation reward: 1.35\n","episode: 622   score: 2.0   memory length: 113291   epsilon: 0.9736818400005713    steps: 198    lr: 0.0001     evaluation reward: 1.35\n","episode: 623   score: 1.0   memory length: 113459   epsilon: 0.9733492000005786    steps: 168    lr: 0.0001     evaluation reward: 1.34\n","episode: 624   score: 4.0   memory length: 113778   epsilon: 0.9727175800005923    steps: 319    lr: 0.0001     evaluation reward: 1.38\n","episode: 625   score: 0.0   memory length: 113901   epsilon: 0.9724740400005976    steps: 123    lr: 0.0001     evaluation reward: 1.36\n","episode: 626   score: 2.0   memory length: 114099   epsilon: 0.9720820000006061    steps: 198    lr: 0.0001     evaluation reward: 1.35\n","episode: 627   score: 1.0   memory length: 114267   epsilon: 0.9717493600006133    steps: 168    lr: 0.0001     evaluation reward: 1.35\n","episode: 628   score: 3.0   memory length: 114515   epsilon: 0.971258320000624    steps: 248    lr: 0.0001     evaluation reward: 1.36\n","episode: 629   score: 1.0   memory length: 114684   epsilon: 0.9709237000006312    steps: 169    lr: 0.0001     evaluation reward: 1.37\n","episode: 630   score: 2.0   memory length: 114902   epsilon: 0.9704920600006406    steps: 218    lr: 0.0001     evaluation reward: 1.39\n","episode: 631   score: 0.0   memory length: 115025   epsilon: 0.9702485200006459    steps: 123    lr: 0.0001     evaluation reward: 1.39\n","episode: 632   score: 5.0   memory length: 115363   epsilon: 0.9695792800006604    steps: 338    lr: 0.0001     evaluation reward: 1.42\n","episode: 633   score: 0.0   memory length: 115485   epsilon: 0.9693377200006656    steps: 122    lr: 0.0001     evaluation reward: 1.42\n","episode: 634   score: 0.0   memory length: 115608   epsilon: 0.9690941800006709    steps: 123    lr: 0.0001     evaluation reward: 1.41\n","episode: 635   score: 1.0   memory length: 115777   epsilon: 0.9687595600006782    steps: 169    lr: 0.0001     evaluation reward: 1.4\n","episode: 636   score: 3.0   memory length: 116022   epsilon: 0.9682744600006887    steps: 245    lr: 0.0001     evaluation reward: 1.42\n","episode: 637   score: 1.0   memory length: 116191   epsilon: 0.967939840000696    steps: 169    lr: 0.0001     evaluation reward: 1.42\n","episode: 638   score: 1.0   memory length: 116362   epsilon: 0.9676012600007033    steps: 171    lr: 0.0001     evaluation reward: 1.41\n","episode: 639   score: 0.0   memory length: 116485   epsilon: 0.9673577200007086    steps: 123    lr: 0.0001     evaluation reward: 1.4\n","episode: 640   score: 1.0   memory length: 116636   epsilon: 0.9670587400007151    steps: 151    lr: 0.0001     evaluation reward: 1.41\n","episode: 641   score: 0.0   memory length: 116758   epsilon: 0.9668171800007204    steps: 122    lr: 0.0001     evaluation reward: 1.39\n","episode: 642   score: 3.0   memory length: 116985   epsilon: 0.9663677200007301    steps: 227    lr: 0.0001     evaluation reward: 1.39\n","episode: 643   score: 3.0   memory length: 117251   epsilon: 0.9658410400007416    steps: 266    lr: 0.0001     evaluation reward: 1.4\n","episode: 644   score: 2.0   memory length: 117433   epsilon: 0.9654806800007494    steps: 182    lr: 0.0001     evaluation reward: 1.41\n","episode: 645   score: 2.0   memory length: 117630   epsilon: 0.9650906200007578    steps: 197    lr: 0.0001     evaluation reward: 1.4\n","episode: 646   score: 1.0   memory length: 117798   epsilon: 0.9647579800007651    steps: 168    lr: 0.0001     evaluation reward: 1.4\n","episode: 647   score: 2.0   memory length: 117995   epsilon: 0.9643679200007735    steps: 197    lr: 0.0001     evaluation reward: 1.42\n","episode: 648   score: 1.0   memory length: 118146   epsilon: 0.96406894000078    steps: 151    lr: 0.0001     evaluation reward: 1.41\n","episode: 649   score: 2.0   memory length: 118363   epsilon: 0.9636392800007894    steps: 217    lr: 0.0001     evaluation reward: 1.41\n","episode: 650   score: 0.0   memory length: 118486   epsilon: 0.9633957400007946    steps: 123    lr: 0.0001     evaluation reward: 1.41\n","episode: 651   score: 4.0   memory length: 118798   epsilon: 0.962777980000808    steps: 312    lr: 0.0001     evaluation reward: 1.43\n","episode: 652   score: 0.0   memory length: 118920   epsilon: 0.9625364200008133    steps: 122    lr: 0.0001     evaluation reward: 1.43\n","episode: 653   score: 0.0   memory length: 119043   epsilon: 0.9622928800008186    steps: 123    lr: 0.0001     evaluation reward: 1.43\n","episode: 654   score: 2.0   memory length: 119241   epsilon: 0.9619008400008271    steps: 198    lr: 0.0001     evaluation reward: 1.43\n","episode: 655   score: 0.0   memory length: 119363   epsilon: 0.9616592800008323    steps: 122    lr: 0.0001     evaluation reward: 1.43\n","episode: 656   score: 2.0   memory length: 119561   epsilon: 0.9612672400008409    steps: 198    lr: 0.0001     evaluation reward: 1.43\n","episode: 657   score: 1.0   memory length: 119712   epsilon: 0.9609682600008473    steps: 151    lr: 0.0001     evaluation reward: 1.44\n","episode: 658   score: 2.0   memory length: 119910   epsilon: 0.9605762200008559    steps: 198    lr: 0.0001     evaluation reward: 1.43\n","episode: 659   score: 4.0   memory length: 120180   epsilon: 0.9600416200008675    steps: 270    lr: 0.0001     evaluation reward: 1.44\n","episode: 660   score: 0.0   memory length: 120303   epsilon: 0.9597980800008727    steps: 123    lr: 0.0001     evaluation reward: 1.41\n","episode: 661   score: 1.0   memory length: 120456   epsilon: 0.9594951400008793    steps: 153    lr: 0.0001     evaluation reward: 1.42\n","episode: 662   score: 1.0   memory length: 120606   epsilon: 0.9591981400008858    steps: 150    lr: 0.0001     evaluation reward: 1.41\n","episode: 663   score: 0.0   memory length: 120729   epsilon: 0.958954600000891    steps: 123    lr: 0.0001     evaluation reward: 1.39\n","episode: 664   score: 0.0   memory length: 120852   epsilon: 0.9587110600008963    steps: 123    lr: 0.0001     evaluation reward: 1.38\n","episode: 665   score: 2.0   memory length: 121050   epsilon: 0.9583190200009049    steps: 198    lr: 0.0001     evaluation reward: 1.4\n","episode: 666   score: 2.0   memory length: 121232   epsilon: 0.9579586600009127    steps: 182    lr: 0.0001     evaluation reward: 1.41\n","episode: 667   score: 1.0   memory length: 121383   epsilon: 0.9576596800009192    steps: 151    lr: 0.0001     evaluation reward: 1.39\n","episode: 668   score: 0.0   memory length: 121506   epsilon: 0.9574161400009245    steps: 123    lr: 0.0001     evaluation reward: 1.37\n","episode: 669   score: 0.0   memory length: 121629   epsilon: 0.9571726000009297    steps: 123    lr: 0.0001     evaluation reward: 1.37\n","episode: 670   score: 1.0   memory length: 121798   epsilon: 0.956837980000937    steps: 169    lr: 0.0001     evaluation reward: 1.36\n","episode: 671   score: 3.0   memory length: 122045   epsilon: 0.9563489200009476    steps: 247    lr: 0.0001     evaluation reward: 1.38\n","episode: 672   score: 3.0   memory length: 122271   epsilon: 0.9559014400009573    steps: 226    lr: 0.0001     evaluation reward: 1.39\n","episode: 673   score: 3.0   memory length: 122517   epsilon: 0.9554143600009679    steps: 246    lr: 0.0001     evaluation reward: 1.42\n","episode: 674   score: 3.0   memory length: 122769   epsilon: 0.9549154000009787    steps: 252    lr: 0.0001     evaluation reward: 1.44\n","episode: 675   score: 1.0   memory length: 122938   epsilon: 0.954580780000986    steps: 169    lr: 0.0001     evaluation reward: 1.45\n","episode: 676   score: 4.0   memory length: 123192   epsilon: 0.9540778600009969    steps: 254    lr: 0.0001     evaluation reward: 1.47\n","episode: 677   score: 5.0   memory length: 123540   epsilon: 0.9533888200010119    steps: 348    lr: 0.0001     evaluation reward: 1.49\n","episode: 678   score: 0.0   memory length: 123663   epsilon: 0.9531452800010172    steps: 123    lr: 0.0001     evaluation reward: 1.47\n","episode: 679   score: 1.0   memory length: 123831   epsilon: 0.9528126400010244    steps: 168    lr: 0.0001     evaluation reward: 1.48\n","episode: 680   score: 2.0   memory length: 124029   epsilon: 0.9524206000010329    steps: 198    lr: 0.0001     evaluation reward: 1.49\n","episode: 681   score: 3.0   memory length: 124275   epsilon: 0.9519335200010435    steps: 246    lr: 0.0001     evaluation reward: 1.5\n","episode: 682   score: 1.0   memory length: 124444   epsilon: 0.9515989000010507    steps: 169    lr: 0.0001     evaluation reward: 1.51\n","episode: 683   score: 0.0   memory length: 124567   epsilon: 0.951355360001056    steps: 123    lr: 0.0001     evaluation reward: 1.51\n","episode: 684   score: 2.0   memory length: 124747   epsilon: 0.9509989600010638    steps: 180    lr: 0.0001     evaluation reward: 1.52\n","episode: 685   score: 1.0   memory length: 124917   epsilon: 0.9506623600010711    steps: 170    lr: 0.0001     evaluation reward: 1.51\n","episode: 686   score: 2.0   memory length: 125097   epsilon: 0.9503059600010788    steps: 180    lr: 0.0001     evaluation reward: 1.52\n","episode: 687   score: 1.0   memory length: 125266   epsilon: 0.9499713400010861    steps: 169    lr: 0.0001     evaluation reward: 1.52\n","episode: 688   score: 3.0   memory length: 125492   epsilon: 0.9495238600010958    steps: 226    lr: 0.0001     evaluation reward: 1.52\n","episode: 689   score: 2.0   memory length: 125712   epsilon: 0.9490882600011052    steps: 220    lr: 0.0001     evaluation reward: 1.54\n","episode: 690   score: 0.0   memory length: 125834   epsilon: 0.9488467000011105    steps: 122    lr: 0.0001     evaluation reward: 1.53\n","episode: 691   score: 2.0   memory length: 126032   epsilon: 0.948454660001119    steps: 198    lr: 0.0001     evaluation reward: 1.55\n","episode: 692   score: 1.0   memory length: 126202   epsilon: 0.9481180600011263    steps: 170    lr: 0.0001     evaluation reward: 1.56\n","episode: 693   score: 1.0   memory length: 126372   epsilon: 0.9477814600011336    steps: 170    lr: 0.0001     evaluation reward: 1.56\n","episode: 694   score: 5.0   memory length: 126678   epsilon: 0.9471755800011468    steps: 306    lr: 0.0001     evaluation reward: 1.59\n","episode: 695   score: 2.0   memory length: 126876   epsilon: 0.9467835400011553    steps: 198    lr: 0.0001     evaluation reward: 1.6\n","episode: 696   score: 1.0   memory length: 127027   epsilon: 0.9464845600011618    steps: 151    lr: 0.0001     evaluation reward: 1.61\n","episode: 697   score: 0.0   memory length: 127150   epsilon: 0.946241020001167    steps: 123    lr: 0.0001     evaluation reward: 1.6\n","episode: 698   score: 4.0   memory length: 127448   epsilon: 0.9456509800011799    steps: 298    lr: 0.0001     evaluation reward: 1.63\n","episode: 699   score: 2.0   memory length: 127663   epsilon: 0.9452252800011891    steps: 215    lr: 0.0001     evaluation reward: 1.65\n","episode: 700   score: 3.0   memory length: 127909   epsilon: 0.9447382000011997    steps: 246    lr: 0.0001     evaluation reward: 1.65\n","episode: 701   score: 0.0   memory length: 128032   epsilon: 0.944494660001205    steps: 123    lr: 0.0001     evaluation reward: 1.63\n","episode: 702   score: 1.0   memory length: 128202   epsilon: 0.9441580600012123    steps: 170    lr: 0.0001     evaluation reward: 1.63\n","episode: 703   score: 3.0   memory length: 128466   epsilon: 0.9436353400012236    steps: 264    lr: 0.0001     evaluation reward: 1.66\n","episode: 704   score: 5.0   memory length: 128775   epsilon: 0.9430235200012369    steps: 309    lr: 0.0001     evaluation reward: 1.67\n","episode: 705   score: 1.0   memory length: 128927   epsilon: 0.9427225600012434    steps: 152    lr: 0.0001     evaluation reward: 1.66\n","episode: 706   score: 0.0   memory length: 129050   epsilon: 0.9424790200012487    steps: 123    lr: 0.0001     evaluation reward: 1.66\n","episode: 707   score: 1.0   memory length: 129200   epsilon: 0.9421820200012552    steps: 150    lr: 0.0001     evaluation reward: 1.65\n","episode: 708   score: 1.0   memory length: 129368   epsilon: 0.9418493800012624    steps: 168    lr: 0.0001     evaluation reward: 1.65\n","episode: 709   score: 2.0   memory length: 129566   epsilon: 0.9414573400012709    steps: 198    lr: 0.0001     evaluation reward: 1.67\n","episode: 710   score: 0.0   memory length: 129688   epsilon: 0.9412157800012761    steps: 122    lr: 0.0001     evaluation reward: 1.65\n","episode: 711   score: 3.0   memory length: 129956   epsilon: 0.9406851400012877    steps: 268    lr: 0.0001     evaluation reward: 1.65\n","episode: 712   score: 2.0   memory length: 130138   epsilon: 0.9403247800012955    steps: 182    lr: 0.0001     evaluation reward: 1.64\n","episode: 713   score: 4.0   memory length: 130435   epsilon: 0.9397367200013083    steps: 297    lr: 0.0001     evaluation reward: 1.67\n","episode: 714   score: 3.0   memory length: 130679   epsilon: 0.9392536000013187    steps: 244    lr: 0.0001     evaluation reward: 1.65\n","episode: 715   score: 1.0   memory length: 130849   epsilon: 0.938917000001326    steps: 170    lr: 0.0001     evaluation reward: 1.62\n","episode: 716   score: 1.0   memory length: 131000   epsilon: 0.9386180200013325    steps: 151    lr: 0.0001     evaluation reward: 1.63\n","episode: 717   score: 2.0   memory length: 131182   epsilon: 0.9382576600013404    steps: 182    lr: 0.0001     evaluation reward: 1.64\n","episode: 718   score: 1.0   memory length: 131334   epsilon: 0.9379567000013469    steps: 152    lr: 0.0001     evaluation reward: 1.63\n","episode: 719   score: 2.0   memory length: 131556   epsilon: 0.9375171400013564    steps: 222    lr: 0.0001     evaluation reward: 1.64\n","episode: 720   score: 2.0   memory length: 131754   epsilon: 0.937125100001365    steps: 198    lr: 0.0001     evaluation reward: 1.66\n","episode: 721   score: 2.0   memory length: 131951   epsilon: 0.9367350400013734    steps: 197    lr: 0.0001     evaluation reward: 1.65\n","episode: 722   score: 5.0   memory length: 132261   epsilon: 0.9361212400013867    steps: 310    lr: 0.0001     evaluation reward: 1.68\n","episode: 723   score: 2.0   memory length: 132460   epsilon: 0.9357272200013953    steps: 199    lr: 0.0001     evaluation reward: 1.69\n","episode: 724   score: 2.0   memory length: 132658   epsilon: 0.9353351800014038    steps: 198    lr: 0.0001     evaluation reward: 1.67\n","episode: 725   score: 5.0   memory length: 132981   epsilon: 0.9346956400014177    steps: 323    lr: 0.0001     evaluation reward: 1.72\n","episode: 726   score: 2.0   memory length: 133179   epsilon: 0.9343036000014262    steps: 198    lr: 0.0001     evaluation reward: 1.72\n","episode: 727   score: 3.0   memory length: 133445   epsilon: 0.9337769200014376    steps: 266    lr: 0.0001     evaluation reward: 1.74\n","episode: 728   score: 0.0   memory length: 133568   epsilon: 0.9335333800014429    steps: 123    lr: 0.0001     evaluation reward: 1.71\n","episode: 729   score: 3.0   memory length: 133816   epsilon: 0.9330423400014536    steps: 248    lr: 0.0001     evaluation reward: 1.73\n","episode: 730   score: 4.0   memory length: 134073   epsilon: 0.9325334800014646    steps: 257    lr: 0.0001     evaluation reward: 1.75\n","episode: 731   score: 2.0   memory length: 134291   epsilon: 0.932101840001474    steps: 218    lr: 0.0001     evaluation reward: 1.77\n","episode: 732   score: 3.0   memory length: 134556   epsilon: 0.9315771400014854    steps: 265    lr: 0.0001     evaluation reward: 1.75\n","episode: 733   score: 2.0   memory length: 134771   epsilon: 0.9311514400014946    steps: 215    lr: 0.0001     evaluation reward: 1.77\n","episode: 734   score: 1.0   memory length: 134922   epsilon: 0.9308524600015011    steps: 151    lr: 0.0001     evaluation reward: 1.78\n","episode: 735   score: 2.0   memory length: 135104   epsilon: 0.930492100001509    steps: 182    lr: 0.0001     evaluation reward: 1.79\n","episode: 736   score: 3.0   memory length: 135349   epsilon: 0.9300070000015195    steps: 245    lr: 0.0001     evaluation reward: 1.79\n","episode: 737   score: 1.0   memory length: 135519   epsilon: 0.9296704000015268    steps: 170    lr: 0.0001     evaluation reward: 1.79\n","episode: 738   score: 0.0   memory length: 135642   epsilon: 0.9294268600015321    steps: 123    lr: 0.0001     evaluation reward: 1.78\n","episode: 739   score: 1.0   memory length: 135793   epsilon: 0.9291278800015386    steps: 151    lr: 0.0001     evaluation reward: 1.79\n","episode: 740   score: 1.0   memory length: 135962   epsilon: 0.9287932600015458    steps: 169    lr: 0.0001     evaluation reward: 1.79\n","episode: 741   score: 3.0   memory length: 136210   epsilon: 0.9283022200015565    steps: 248    lr: 0.0001     evaluation reward: 1.82\n","episode: 742   score: 2.0   memory length: 136410   epsilon: 0.9279062200015651    steps: 200    lr: 0.0001     evaluation reward: 1.81\n","episode: 743   score: 0.0   memory length: 136532   epsilon: 0.9276646600015703    steps: 122    lr: 0.0001     evaluation reward: 1.78\n","episode: 744   score: 2.0   memory length: 136754   epsilon: 0.9272251000015799    steps: 222    lr: 0.0001     evaluation reward: 1.78\n","episode: 745   score: 2.0   memory length: 136969   epsilon: 0.9267994000015891    steps: 215    lr: 0.0001     evaluation reward: 1.78\n","episode: 746   score: 3.0   memory length: 137195   epsilon: 0.9263519200015988    steps: 226    lr: 0.0001     evaluation reward: 1.8\n","episode: 747   score: 0.0   memory length: 137318   epsilon: 0.9261083800016041    steps: 123    lr: 0.0001     evaluation reward: 1.78\n","episode: 748   score: 7.0   memory length: 137724   epsilon: 0.9253045000016216    steps: 406    lr: 0.0001     evaluation reward: 1.84\n","episode: 749   score: 4.0   memory length: 137984   epsilon: 0.9247897000016327    steps: 260    lr: 0.0001     evaluation reward: 1.86\n","episode: 750   score: 2.0   memory length: 138182   epsilon: 0.9243976600016413    steps: 198    lr: 0.0001     evaluation reward: 1.88\n","episode: 751   score: 0.0   memory length: 138305   epsilon: 0.9241541200016465    steps: 123    lr: 0.0001     evaluation reward: 1.84\n","episode: 752   score: 2.0   memory length: 138485   epsilon: 0.9237977200016543    steps: 180    lr: 0.0001     evaluation reward: 1.86\n","episode: 753   score: 0.0   memory length: 138608   epsilon: 0.9235541800016596    steps: 123    lr: 0.0001     evaluation reward: 1.86\n","episode: 754   score: 2.0   memory length: 138806   epsilon: 0.9231621400016681    steps: 198    lr: 0.0001     evaluation reward: 1.86\n","episode: 755   score: 2.0   memory length: 139003   epsilon: 0.9227720800016765    steps: 197    lr: 0.0001     evaluation reward: 1.88\n","episode: 756   score: 3.0   memory length: 139232   epsilon: 0.9223186600016864    steps: 229    lr: 0.0001     evaluation reward: 1.89\n","episode: 757   score: 2.0   memory length: 139449   epsilon: 0.9218890000016957    steps: 217    lr: 0.0001     evaluation reward: 1.9\n","episode: 758   score: 3.0   memory length: 139695   epsilon: 0.9214019200017063    steps: 246    lr: 0.0001     evaluation reward: 1.91\n","episode: 759   score: 1.0   memory length: 139846   epsilon: 0.9211029400017128    steps: 151    lr: 0.0001     evaluation reward: 1.88\n","episode: 760   score: 1.0   memory length: 139996   epsilon: 0.9208059400017192    steps: 150    lr: 0.0001     evaluation reward: 1.89\n","episode: 761   score: 7.0   memory length: 140377   epsilon: 0.9200515600017356    steps: 381    lr: 0.0001     evaluation reward: 1.95\n","episode: 762   score: 2.0   memory length: 140575   epsilon: 0.9196595200017441    steps: 198    lr: 0.0001     evaluation reward: 1.96\n","episode: 763   score: 2.0   memory length: 140792   epsilon: 0.9192298600017534    steps: 217    lr: 0.0001     evaluation reward: 1.98\n","episode: 764   score: 2.0   memory length: 141009   epsilon: 0.9188002000017628    steps: 217    lr: 0.0001     evaluation reward: 2.0\n","episode: 765   score: 2.0   memory length: 141189   epsilon: 0.9184438000017705    steps: 180    lr: 0.0001     evaluation reward: 2.0\n","episode: 766   score: 1.0   memory length: 141358   epsilon: 0.9181091800017778    steps: 169    lr: 0.0001     evaluation reward: 1.99\n","episode: 767   score: 0.0   memory length: 141480   epsilon: 0.917867620001783    steps: 122    lr: 0.0001     evaluation reward: 1.98\n","episode: 768   score: 4.0   memory length: 141777   epsilon: 0.9172795600017958    steps: 297    lr: 0.0001     evaluation reward: 2.02\n","episode: 769   score: 2.0   memory length: 141957   epsilon: 0.9169231600018035    steps: 180    lr: 0.0001     evaluation reward: 2.04\n","episode: 770   score: 1.0   memory length: 142108   epsilon: 0.91662418000181    steps: 151    lr: 0.0001     evaluation reward: 2.04\n","episode: 771   score: 2.0   memory length: 142324   epsilon: 0.9161965000018193    steps: 216    lr: 0.0001     evaluation reward: 2.03\n","episode: 772   score: 3.0   memory length: 142573   epsilon: 0.91570348000183    steps: 249    lr: 0.0001     evaluation reward: 2.03\n","episode: 773   score: 3.0   memory length: 142821   epsilon: 0.9152124400018407    steps: 248    lr: 0.0001     evaluation reward: 2.03\n","episode: 774   score: 2.0   memory length: 143020   epsilon: 0.9148184200018492    steps: 199    lr: 0.0001     evaluation reward: 2.02\n","episode: 775   score: 0.0   memory length: 143143   epsilon: 0.9145748800018545    steps: 123    lr: 0.0001     evaluation reward: 2.01\n","episode: 776   score: 1.0   memory length: 143312   epsilon: 0.9142402600018618    steps: 169    lr: 0.0001     evaluation reward: 1.98\n","episode: 777   score: 0.0   memory length: 143435   epsilon: 0.913996720001867    steps: 123    lr: 0.0001     evaluation reward: 1.93\n","episode: 778   score: 0.0   memory length: 143557   epsilon: 0.9137551600018723    steps: 122    lr: 0.0001     evaluation reward: 1.93\n","episode: 779   score: 3.0   memory length: 143783   epsilon: 0.913307680001882    steps: 226    lr: 0.0001     evaluation reward: 1.95\n","episode: 780   score: 2.0   memory length: 144002   epsilon: 0.9128740600018914    steps: 219    lr: 0.0001     evaluation reward: 1.95\n","episode: 781   score: 0.0   memory length: 144125   epsilon: 0.9126305200018967    steps: 123    lr: 0.0001     evaluation reward: 1.92\n","episode: 782   score: 2.0   memory length: 144304   epsilon: 0.9122761000019044    steps: 179    lr: 0.0001     evaluation reward: 1.93\n","episode: 783   score: 2.0   memory length: 144502   epsilon: 0.9118840600019129    steps: 198    lr: 0.0001     evaluation reward: 1.95\n","episode: 784   score: 4.0   memory length: 144781   epsilon: 0.9113316400019249    steps: 279    lr: 0.0001     evaluation reward: 1.97\n","episode: 785   score: 4.0   memory length: 145076   epsilon: 0.9107475400019376    steps: 295    lr: 0.0001     evaluation reward: 2.0\n","episode: 786   score: 3.0   memory length: 145301   epsilon: 0.9103020400019473    steps: 225    lr: 0.0001     evaluation reward: 2.01\n","episode: 787   score: 4.0   memory length: 145596   epsilon: 0.9097179400019599    steps: 295    lr: 0.0001     evaluation reward: 2.04\n","episode: 788   score: 2.0   memory length: 145780   epsilon: 0.9093536200019678    steps: 184    lr: 0.0001     evaluation reward: 2.03\n","episode: 789   score: 0.0   memory length: 145902   epsilon: 0.9091120600019731    steps: 122    lr: 0.0001     evaluation reward: 2.01\n","episode: 790   score: 2.0   memory length: 146100   epsilon: 0.9087200200019816    steps: 198    lr: 0.0001     evaluation reward: 2.03\n","episode: 791   score: 1.0   memory length: 146268   epsilon: 0.9083873800019888    steps: 168    lr: 0.0001     evaluation reward: 2.02\n","episode: 792   score: 1.0   memory length: 146419   epsilon: 0.9080884000019953    steps: 151    lr: 0.0001     evaluation reward: 2.02\n","episode: 793   score: 2.0   memory length: 146622   epsilon: 0.907686460002004    steps: 203    lr: 0.0001     evaluation reward: 2.03\n","episode: 794   score: 1.0   memory length: 146793   epsilon: 0.9073478800020114    steps: 171    lr: 0.0001     evaluation reward: 1.99\n","episode: 795   score: 4.0   memory length: 147068   epsilon: 0.9068033800020232    steps: 275    lr: 0.0001     evaluation reward: 2.01\n","episode: 796   score: 1.0   memory length: 147218   epsilon: 0.9065063800020297    steps: 150    lr: 0.0001     evaluation reward: 2.01\n","episode: 797   score: 1.0   memory length: 147370   epsilon: 0.9062054200020362    steps: 152    lr: 0.0001     evaluation reward: 2.02\n","episode: 798   score: 5.0   memory length: 147713   epsilon: 0.9055262800020509    steps: 343    lr: 0.0001     evaluation reward: 2.03\n","episode: 799   score: 3.0   memory length: 147942   epsilon: 0.9050728600020608    steps: 229    lr: 0.0001     evaluation reward: 2.04\n","episode: 800   score: 1.0   memory length: 148092   epsilon: 0.9047758600020672    steps: 150    lr: 0.0001     evaluation reward: 2.02\n","episode: 801   score: 5.0   memory length: 148417   epsilon: 0.9041323600020812    steps: 325    lr: 0.0001     evaluation reward: 2.07\n","episode: 802   score: 2.0   memory length: 148635   epsilon: 0.9037007200020906    steps: 218    lr: 0.0001     evaluation reward: 2.08\n","episode: 803   score: 4.0   memory length: 148949   epsilon: 0.9030790000021041    steps: 314    lr: 0.0001     evaluation reward: 2.09\n","episode: 804   score: 6.0   memory length: 149322   epsilon: 0.9023404600021201    steps: 373    lr: 0.0001     evaluation reward: 2.1\n","episode: 805   score: 0.0   memory length: 149445   epsilon: 0.9020969200021254    steps: 123    lr: 0.0001     evaluation reward: 2.09\n","episode: 806   score: 0.0   memory length: 149568   epsilon: 0.9018533800021307    steps: 123    lr: 0.0001     evaluation reward: 2.09\n","episode: 807   score: 0.0   memory length: 149691   epsilon: 0.901609840002136    steps: 123    lr: 0.0001     evaluation reward: 2.08\n","episode: 808   score: 1.0   memory length: 149863   epsilon: 0.9012692800021433    steps: 172    lr: 0.0001     evaluation reward: 2.08\n","episode: 809   score: 2.0   memory length: 150045   epsilon: 0.9009089200021512    steps: 182    lr: 0.0001     evaluation reward: 2.08\n","episode: 810   score: 2.0   memory length: 150245   epsilon: 0.9005129200021598    steps: 200    lr: 0.0001     evaluation reward: 2.1\n","episode: 811   score: 8.0   memory length: 150696   epsilon: 0.8996199400021792    steps: 451    lr: 0.0001     evaluation reward: 2.15\n","episode: 812   score: 2.0   memory length: 150894   epsilon: 0.8992279000021877    steps: 198    lr: 0.0001     evaluation reward: 2.15\n","episode: 813   score: 1.0   memory length: 151045   epsilon: 0.8989289200021942    steps: 151    lr: 0.0001     evaluation reward: 2.12\n","episode: 814   score: 2.0   memory length: 151242   epsilon: 0.8985388600022026    steps: 197    lr: 0.0001     evaluation reward: 2.11\n","episode: 815   score: 1.0   memory length: 151414   epsilon: 0.89819830000221    steps: 172    lr: 0.0001     evaluation reward: 2.11\n","episode: 816   score: 2.0   memory length: 151632   epsilon: 0.8977666600022194    steps: 218    lr: 0.0001     evaluation reward: 2.12\n","episode: 817   score: 2.0   memory length: 151830   epsilon: 0.8973746200022279    steps: 198    lr: 0.0001     evaluation reward: 2.12\n","episode: 818   score: 0.0   memory length: 151953   epsilon: 0.8971310800022332    steps: 123    lr: 0.0001     evaluation reward: 2.11\n","episode: 819   score: 4.0   memory length: 152272   epsilon: 0.8964994600022469    steps: 319    lr: 0.0001     evaluation reward: 2.13\n","episode: 820   score: 2.0   memory length: 152453   epsilon: 0.8961410800022547    steps: 181    lr: 0.0001     evaluation reward: 2.13\n","episode: 821   score: 3.0   memory length: 152699   epsilon: 0.8956540000022652    steps: 246    lr: 0.0001     evaluation reward: 2.14\n","episode: 822   score: 2.0   memory length: 152917   epsilon: 0.8952223600022746    steps: 218    lr: 0.0001     evaluation reward: 2.11\n","episode: 823   score: 5.0   memory length: 153219   epsilon: 0.8946244000022876    steps: 302    lr: 0.0001     evaluation reward: 2.14\n","episode: 824   score: 1.0   memory length: 153388   epsilon: 0.8942897800022949    steps: 169    lr: 0.0001     evaluation reward: 2.13\n","episode: 825   score: 2.0   memory length: 153604   epsilon: 0.8938621000023041    steps: 216    lr: 0.0001     evaluation reward: 2.1\n","episode: 826   score: 0.0   memory length: 153726   epsilon: 0.8936205400023094    steps: 122    lr: 0.0001     evaluation reward: 2.08\n","episode: 827   score: 0.0   memory length: 153848   epsilon: 0.8933789800023146    steps: 122    lr: 0.0001     evaluation reward: 2.05\n","episode: 828   score: 6.0   memory length: 154223   epsilon: 0.8926364800023308    steps: 375    lr: 0.0001     evaluation reward: 2.11\n","episode: 829   score: 2.0   memory length: 154442   epsilon: 0.8922028600023402    steps: 219    lr: 0.0001     evaluation reward: 2.1\n","episode: 830   score: 2.0   memory length: 154658   epsilon: 0.8917751800023495    steps: 216    lr: 0.0001     evaluation reward: 2.08\n","episode: 831   score: 1.0   memory length: 154809   epsilon: 0.891476200002356    steps: 151    lr: 0.0001     evaluation reward: 2.07\n","episode: 832   score: 2.0   memory length: 155028   epsilon: 0.8910425800023654    steps: 219    lr: 0.0001     evaluation reward: 2.06\n","episode: 833   score: 1.0   memory length: 155197   epsilon: 0.8907079600023726    steps: 169    lr: 0.0001     evaluation reward: 2.05\n","episode: 834   score: 1.0   memory length: 155366   epsilon: 0.8903733400023799    steps: 169    lr: 0.0001     evaluation reward: 2.05\n","episode: 835   score: 1.0   memory length: 155535   epsilon: 0.8900387200023872    steps: 169    lr: 0.0001     evaluation reward: 2.04\n","episode: 836   score: 1.0   memory length: 155686   epsilon: 0.8897397400023936    steps: 151    lr: 0.0001     evaluation reward: 2.02\n","episode: 837   score: 3.0   memory length: 155930   epsilon: 0.8892566200024041    steps: 244    lr: 0.0001     evaluation reward: 2.04\n","episode: 838   score: 2.0   memory length: 156111   epsilon: 0.8888982400024119    steps: 181    lr: 0.0001     evaluation reward: 2.06\n","episode: 839   score: 2.0   memory length: 156332   epsilon: 0.8884606600024214    steps: 221    lr: 0.0001     evaluation reward: 2.07\n","episode: 840   score: 3.0   memory length: 156598   epsilon: 0.8879339800024328    steps: 266    lr: 0.0001     evaluation reward: 2.09\n","episode: 841   score: 3.0   memory length: 156845   epsilon: 0.8874449200024435    steps: 247    lr: 0.0001     evaluation reward: 2.09\n","episode: 842   score: 2.0   memory length: 157043   epsilon: 0.887052880002452    steps: 198    lr: 0.0001     evaluation reward: 2.09\n","episode: 843   score: 1.0   memory length: 157194   epsilon: 0.8867539000024585    steps: 151    lr: 0.0001     evaluation reward: 2.1\n","episode: 844   score: 1.0   memory length: 157345   epsilon: 0.886454920002465    steps: 151    lr: 0.0001     evaluation reward: 2.09\n","episode: 845   score: 2.0   memory length: 157563   epsilon: 0.8860232800024743    steps: 218    lr: 0.0001     evaluation reward: 2.09\n","episode: 846   score: 0.0   memory length: 157686   epsilon: 0.8857797400024796    steps: 123    lr: 0.0001     evaluation reward: 2.06\n","episode: 847   score: 1.0   memory length: 157837   epsilon: 0.8854807600024861    steps: 151    lr: 0.0001     evaluation reward: 2.07\n","episode: 848   score: 1.0   memory length: 157988   epsilon: 0.8851817800024926    steps: 151    lr: 0.0001     evaluation reward: 2.01\n","episode: 849   score: 4.0   memory length: 158274   epsilon: 0.8846155000025049    steps: 286    lr: 0.0001     evaluation reward: 2.01\n","episode: 850   score: 1.0   memory length: 158443   epsilon: 0.8842808800025121    steps: 169    lr: 0.0001     evaluation reward: 2.0\n","episode: 851   score: 3.0   memory length: 158672   epsilon: 0.883827460002522    steps: 229    lr: 0.0001     evaluation reward: 2.03\n","episode: 852   score: 8.0   memory length: 159077   epsilon: 0.8830255600025394    steps: 405    lr: 0.0001     evaluation reward: 2.09\n","episode: 853   score: 4.0   memory length: 159352   epsilon: 0.8824810600025512    steps: 275    lr: 0.0001     evaluation reward: 2.13\n","episode: 854   score: 4.0   memory length: 159611   epsilon: 0.8819682400025624    steps: 259    lr: 0.0001     evaluation reward: 2.15\n","episode: 855   score: 2.0   memory length: 159829   epsilon: 0.8815366000025717    steps: 218    lr: 0.0001     evaluation reward: 2.15\n","episode: 856   score: 0.0   memory length: 159952   epsilon: 0.881293060002577    steps: 123    lr: 0.0001     evaluation reward: 2.12\n","episode: 857   score: 1.0   memory length: 160121   epsilon: 0.8809584400025843    steps: 169    lr: 0.0001     evaluation reward: 2.11\n","episode: 858   score: 7.0   memory length: 160492   epsilon: 0.8802238600026002    steps: 371    lr: 0.0001     evaluation reward: 2.15\n","episode: 859   score: 1.0   memory length: 160660   epsilon: 0.8798912200026074    steps: 168    lr: 0.0001     evaluation reward: 2.15\n","episode: 860   score: 3.0   memory length: 160886   epsilon: 0.8794437400026172    steps: 226    lr: 0.0001     evaluation reward: 2.17\n","episode: 861   score: 3.0   memory length: 161115   epsilon: 0.878990320002627    steps: 229    lr: 0.0001     evaluation reward: 2.13\n","episode: 862   score: 1.0   memory length: 161285   epsilon: 0.8786537200026343    steps: 170    lr: 0.0001     evaluation reward: 2.12\n","episode: 863   score: 3.0   memory length: 161517   epsilon: 0.8781943600026443    steps: 232    lr: 0.0001     evaluation reward: 2.13\n","episode: 864   score: 1.0   memory length: 161668   epsilon: 0.8778953800026508    steps: 151    lr: 0.0001     evaluation reward: 2.12\n","episode: 865   score: 2.0   memory length: 161885   epsilon: 0.8774657200026601    steps: 217    lr: 0.0001     evaluation reward: 2.12\n","episode: 866   score: 1.0   memory length: 162054   epsilon: 0.8771311000026674    steps: 169    lr: 0.0001     evaluation reward: 2.12\n","episode: 867   score: 1.0   memory length: 162205   epsilon: 0.8768321200026739    steps: 151    lr: 0.0001     evaluation reward: 2.13\n","episode: 868   score: 2.0   memory length: 162402   epsilon: 0.8764420600026823    steps: 197    lr: 0.0001     evaluation reward: 2.11\n","episode: 869   score: 1.0   memory length: 162571   epsilon: 0.8761074400026896    steps: 169    lr: 0.0001     evaluation reward: 2.1\n","episode: 870   score: 0.0   memory length: 162693   epsilon: 0.8758658800026948    steps: 122    lr: 0.0001     evaluation reward: 2.09\n","episode: 871   score: 2.0   memory length: 162891   epsilon: 0.8754738400027033    steps: 198    lr: 0.0001     evaluation reward: 2.09\n","episode: 872   score: 1.0   memory length: 163043   epsilon: 0.8751728800027099    steps: 152    lr: 0.0001     evaluation reward: 2.07\n","episode: 873   score: 6.0   memory length: 163417   epsilon: 0.874432360002726    steps: 374    lr: 0.0001     evaluation reward: 2.1\n","episode: 874   score: 5.0   memory length: 163720   epsilon: 0.873832420002739    steps: 303    lr: 0.0001     evaluation reward: 2.13\n","episode: 875   score: 4.0   memory length: 164013   epsilon: 0.8732522800027516    steps: 293    lr: 0.0001     evaluation reward: 2.17\n","episode: 876   score: 3.0   memory length: 164279   epsilon: 0.872725600002763    steps: 266    lr: 0.0001     evaluation reward: 2.19\n","episode: 877   score: 1.0   memory length: 164450   epsilon: 0.8723870200027704    steps: 171    lr: 0.0001     evaluation reward: 2.2\n","episode: 878   score: 5.0   memory length: 164773   epsilon: 0.8717474800027842    steps: 323    lr: 0.0001     evaluation reward: 2.25\n","episode: 879   score: 3.0   memory length: 165040   epsilon: 0.8712188200027957    steps: 267    lr: 0.0001     evaluation reward: 2.25\n","episode: 880   score: 1.0   memory length: 165209   epsilon: 0.870884200002803    steps: 169    lr: 0.0001     evaluation reward: 2.24\n","episode: 881   score: 10.0   memory length: 165631   epsilon: 0.8700486400028211    steps: 422    lr: 0.0001     evaluation reward: 2.34\n","episode: 882   score: 3.0   memory length: 165876   epsilon: 0.8695635400028316    steps: 245    lr: 0.0001     evaluation reward: 2.35\n","episode: 883   score: 1.0   memory length: 166026   epsilon: 0.8692665400028381    steps: 150    lr: 0.0001     evaluation reward: 2.34\n","episode: 884   score: 1.0   memory length: 166195   epsilon: 0.8689319200028454    steps: 169    lr: 0.0001     evaluation reward: 2.31\n","episode: 885   score: 4.0   memory length: 166474   epsilon: 0.8683795000028574    steps: 279    lr: 0.0001     evaluation reward: 2.31\n","episode: 886   score: 2.0   memory length: 166692   epsilon: 0.8679478600028667    steps: 218    lr: 0.0001     evaluation reward: 2.3\n","episode: 887   score: 3.0   memory length: 166940   epsilon: 0.8674568200028774    steps: 248    lr: 0.0001     evaluation reward: 2.29\n","episode: 888   score: 3.0   memory length: 167187   epsilon: 0.866967760002888    steps: 247    lr: 0.0001     evaluation reward: 2.3\n","episode: 889   score: 2.0   memory length: 167385   epsilon: 0.8665757200028965    steps: 198    lr: 0.0001     evaluation reward: 2.32\n","episode: 890   score: 3.0   memory length: 167614   epsilon: 0.8661223000029064    steps: 229    lr: 0.0001     evaluation reward: 2.33\n","episode: 891   score: 2.0   memory length: 167811   epsilon: 0.8657322400029148    steps: 197    lr: 0.0001     evaluation reward: 2.34\n","episode: 892   score: 5.0   memory length: 168136   epsilon: 0.8650887400029288    steps: 325    lr: 0.0001     evaluation reward: 2.38\n","episode: 893   score: 4.0   memory length: 168414   epsilon: 0.8645383000029407    steps: 278    lr: 0.0001     evaluation reward: 2.4\n","episode: 894   score: 1.0   memory length: 168565   epsilon: 0.8642393200029472    steps: 151    lr: 0.0001     evaluation reward: 2.4\n","episode: 895   score: 3.0   memory length: 168830   epsilon: 0.8637146200029586    steps: 265    lr: 0.0001     evaluation reward: 2.39\n","episode: 896   score: 1.0   memory length: 168999   epsilon: 0.8633800000029659    steps: 169    lr: 0.0001     evaluation reward: 2.39\n","episode: 897   score: 7.0   memory length: 169368   epsilon: 0.8626493800029817    steps: 369    lr: 0.0001     evaluation reward: 2.45\n","episode: 898   score: 3.0   memory length: 169601   epsilon: 0.8621880400029918    steps: 233    lr: 0.0001     evaluation reward: 2.43\n","episode: 899   score: 2.0   memory length: 169780   epsilon: 0.8618336200029995    steps: 179    lr: 0.0001     evaluation reward: 2.42\n","episode: 900   score: 4.0   memory length: 170079   epsilon: 0.8612416000030123    steps: 299    lr: 0.0001     evaluation reward: 2.45\n","episode: 901   score: 4.0   memory length: 170392   epsilon: 0.8606218600030258    steps: 313    lr: 0.0001     evaluation reward: 2.44\n","episode: 902   score: 2.0   memory length: 170610   epsilon: 0.8601902200030351    steps: 218    lr: 0.0001     evaluation reward: 2.44\n","episode: 903   score: 2.0   memory length: 170828   epsilon: 0.8597585800030445    steps: 218    lr: 0.0001     evaluation reward: 2.42\n","episode: 904   score: 6.0   memory length: 171210   epsilon: 0.8590022200030609    steps: 382    lr: 0.0001     evaluation reward: 2.42\n","episode: 905   score: 1.0   memory length: 171379   epsilon: 0.8586676000030682    steps: 169    lr: 0.0001     evaluation reward: 2.43\n","episode: 906   score: 3.0   memory length: 171626   epsilon: 0.8581785400030788    steps: 247    lr: 0.0001     evaluation reward: 2.46\n","episode: 907   score: 3.0   memory length: 171851   epsilon: 0.8577330400030885    steps: 225    lr: 0.0001     evaluation reward: 2.49\n","episode: 908   score: 2.0   memory length: 172071   epsilon: 0.8572974400030979    steps: 220    lr: 0.0001     evaluation reward: 2.5\n","episode: 909   score: 3.0   memory length: 172339   epsilon: 0.8567668000031095    steps: 268    lr: 0.0001     evaluation reward: 2.51\n","episode: 910   score: 1.0   memory length: 172507   epsilon: 0.8564341600031167    steps: 168    lr: 0.0001     evaluation reward: 2.5\n","episode: 911   score: 1.0   memory length: 172676   epsilon: 0.8560995400031239    steps: 169    lr: 0.0001     evaluation reward: 2.43\n","episode: 912   score: 7.0   memory length: 173080   epsilon: 0.8552996200031413    steps: 404    lr: 0.0001     evaluation reward: 2.48\n","episode: 913   score: 1.0   memory length: 173249   epsilon: 0.8549650000031486    steps: 169    lr: 0.0001     evaluation reward: 2.48\n","episode: 914   score: 0.0   memory length: 173372   epsilon: 0.8547214600031539    steps: 123    lr: 0.0001     evaluation reward: 2.46\n","episode: 915   score: 1.0   memory length: 173543   epsilon: 0.8543828800031612    steps: 171    lr: 0.0001     evaluation reward: 2.46\n","episode: 916   score: 1.0   memory length: 173714   epsilon: 0.8540443000031686    steps: 171    lr: 0.0001     evaluation reward: 2.45\n","episode: 917   score: 2.0   memory length: 173932   epsilon: 0.8536126600031779    steps: 218    lr: 0.0001     evaluation reward: 2.45\n","episode: 918   score: 3.0   memory length: 174178   epsilon: 0.8531255800031885    steps: 246    lr: 0.0001     evaluation reward: 2.48\n","episode: 919   score: 4.0   memory length: 174455   epsilon: 0.8525771200032004    steps: 277    lr: 0.0001     evaluation reward: 2.48\n","episode: 920   score: 2.0   memory length: 174678   epsilon: 0.85213558000321    steps: 223    lr: 0.0001     evaluation reward: 2.48\n","episode: 921   score: 3.0   memory length: 174908   epsilon: 0.8516801800032199    steps: 230    lr: 0.0001     evaluation reward: 2.48\n","episode: 922   score: 3.0   memory length: 175136   epsilon: 0.8512287400032297    steps: 228    lr: 0.0001     evaluation reward: 2.49\n","episode: 923   score: 4.0   memory length: 175429   epsilon: 0.8506486000032423    steps: 293    lr: 0.0001     evaluation reward: 2.48\n","episode: 924   score: 2.0   memory length: 175627   epsilon: 0.8502565600032508    steps: 198    lr: 0.0001     evaluation reward: 2.49\n","episode: 925   score: 4.0   memory length: 175920   epsilon: 0.8496764200032634    steps: 293    lr: 0.0001     evaluation reward: 2.51\n","episode: 926   score: 4.0   memory length: 176195   epsilon: 0.8491319200032752    steps: 275    lr: 0.0001     evaluation reward: 2.55\n","episode: 927   score: 0.0   memory length: 176318   epsilon: 0.8488883800032805    steps: 123    lr: 0.0001     evaluation reward: 2.55\n","episode: 928   score: 6.0   memory length: 176570   epsilon: 0.8483894200032913    steps: 252    lr: 0.0001     evaluation reward: 2.55\n","episode: 929   score: 4.0   memory length: 176829   epsilon: 0.8478766000033024    steps: 259    lr: 0.0001     evaluation reward: 2.57\n","episode: 930   score: 2.0   memory length: 177029   epsilon: 0.847480600003311    steps: 200    lr: 0.0001     evaluation reward: 2.57\n","episode: 931   score: 3.0   memory length: 177277   epsilon: 0.8469895600033217    steps: 248    lr: 0.0001     evaluation reward: 2.59\n","episode: 932   score: 2.0   memory length: 177492   epsilon: 0.846563860003331    steps: 215    lr: 0.0001     evaluation reward: 2.59\n","episode: 933   score: 2.0   memory length: 177713   epsilon: 0.8461262800033404    steps: 221    lr: 0.0001     evaluation reward: 2.6\n","episode: 934   score: 4.0   memory length: 177989   epsilon: 0.8455798000033523    steps: 276    lr: 0.0001     evaluation reward: 2.63\n","episode: 935   score: 5.0   memory length: 178292   epsilon: 0.8449798600033653    steps: 303    lr: 0.0001     evaluation reward: 2.67\n","episode: 936   score: 6.0   memory length: 178667   epsilon: 0.8442373600033815    steps: 375    lr: 0.0001     evaluation reward: 2.72\n","episode: 937   score: 1.0   memory length: 178837   epsilon: 0.8439007600033888    steps: 170    lr: 0.0001     evaluation reward: 2.7\n","episode: 938   score: 1.0   memory length: 179008   epsilon: 0.8435621800033961    steps: 171    lr: 0.0001     evaluation reward: 2.69\n","episode: 939   score: 3.0   memory length: 179254   epsilon: 0.8430751000034067    steps: 246    lr: 0.0001     evaluation reward: 2.7\n","episode: 940   score: 3.0   memory length: 179503   epsilon: 0.8425820800034174    steps: 249    lr: 0.0001     evaluation reward: 2.7\n","episode: 941   score: 1.0   memory length: 179654   epsilon: 0.8422831000034239    steps: 151    lr: 0.0001     evaluation reward: 2.68\n","episode: 942   score: 1.0   memory length: 179826   epsilon: 0.8419425400034313    steps: 172    lr: 0.0001     evaluation reward: 2.67\n","episode: 943   score: 3.0   memory length: 180057   epsilon: 0.8414851600034412    steps: 231    lr: 0.0001     evaluation reward: 2.69\n","episode: 944   score: 0.0   memory length: 180179   epsilon: 0.8412436000034464    steps: 122    lr: 0.0001     evaluation reward: 2.68\n","episode: 945   score: 0.0   memory length: 180301   epsilon: 0.8410020400034517    steps: 122    lr: 0.0001     evaluation reward: 2.66\n","episode: 946   score: 2.0   memory length: 180521   epsilon: 0.8405664400034611    steps: 220    lr: 0.0001     evaluation reward: 2.68\n","episode: 947   score: 4.0   memory length: 180796   epsilon: 0.840021940003473    steps: 275    lr: 0.0001     evaluation reward: 2.71\n","episode: 948   score: 4.0   memory length: 181091   epsilon: 0.8394378400034856    steps: 295    lr: 0.0001     evaluation reward: 2.74\n","episode: 949   score: 1.0   memory length: 181242   epsilon: 0.8391388600034921    steps: 151    lr: 0.0001     evaluation reward: 2.71\n","episode: 950   score: 1.0   memory length: 181393   epsilon: 0.8388398800034986    steps: 151    lr: 0.0001     evaluation reward: 2.71\n","episode: 951   score: 1.0   memory length: 181543   epsilon: 0.8385428800035051    steps: 150    lr: 0.0001     evaluation reward: 2.69\n","episode: 952   score: 0.0   memory length: 181666   epsilon: 0.8382993400035104    steps: 123    lr: 0.0001     evaluation reward: 2.61\n","episode: 953   score: 3.0   memory length: 181933   epsilon: 0.8377706800035218    steps: 267    lr: 0.0001     evaluation reward: 2.6\n","episode: 954   score: 3.0   memory length: 182181   epsilon: 0.8372796400035325    steps: 248    lr: 0.0001     evaluation reward: 2.59\n","episode: 955   score: 3.0   memory length: 182428   epsilon: 0.8367905800035431    steps: 247    lr: 0.0001     evaluation reward: 2.6\n","episode: 956   score: 2.0   memory length: 182628   epsilon: 0.8363945800035517    steps: 200    lr: 0.0001     evaluation reward: 2.62\n","episode: 957   score: 0.0   memory length: 182751   epsilon: 0.836151040003557    steps: 123    lr: 0.0001     evaluation reward: 2.61\n","episode: 958   score: 2.0   memory length: 182950   epsilon: 0.8357570200035656    steps: 199    lr: 0.0001     evaluation reward: 2.56\n","episode: 959   score: 0.0   memory length: 183072   epsilon: 0.8355154600035708    steps: 122    lr: 0.0001     evaluation reward: 2.55\n","episode: 960   score: 5.0   memory length: 183394   epsilon: 0.8348779000035846    steps: 322    lr: 0.0001     evaluation reward: 2.57\n","episode: 961   score: 2.0   memory length: 183610   epsilon: 0.8344502200035939    steps: 216    lr: 0.0001     evaluation reward: 2.56\n","episode: 962   score: 1.0   memory length: 183778   epsilon: 0.8341175800036011    steps: 168    lr: 0.0001     evaluation reward: 2.56\n","episode: 963   score: 3.0   memory length: 183991   epsilon: 0.8336958400036103    steps: 213    lr: 0.0001     evaluation reward: 2.56\n","episode: 964   score: 5.0   memory length: 184335   epsilon: 0.8330147200036251    steps: 344    lr: 0.0001     evaluation reward: 2.6\n","episode: 965   score: 2.0   memory length: 184532   epsilon: 0.8326246600036336    steps: 197    lr: 0.0001     evaluation reward: 2.6\n","episode: 966   score: 4.0   memory length: 184811   epsilon: 0.8320722400036455    steps: 279    lr: 0.0001     evaluation reward: 2.63\n","episode: 967   score: 1.0   memory length: 184981   epsilon: 0.8317356400036529    steps: 170    lr: 0.0001     evaluation reward: 2.63\n","episode: 968   score: 1.0   memory length: 185153   epsilon: 0.8313950800036602    steps: 172    lr: 0.0001     evaluation reward: 2.62\n","episode: 969   score: 1.0   memory length: 185303   epsilon: 0.8310980800036667    steps: 150    lr: 0.0001     evaluation reward: 2.62\n","episode: 970   score: 1.0   memory length: 185453   epsilon: 0.8308010800036731    steps: 150    lr: 0.0001     evaluation reward: 2.63\n","episode: 971   score: 1.0   memory length: 185603   epsilon: 0.8305040800036796    steps: 150    lr: 0.0001     evaluation reward: 2.62\n","episode: 972   score: 3.0   memory length: 185850   epsilon: 0.8300150200036902    steps: 247    lr: 0.0001     evaluation reward: 2.64\n","episode: 973   score: 4.0   memory length: 186111   epsilon: 0.8294982400037014    steps: 261    lr: 0.0001     evaluation reward: 2.62\n","episode: 974   score: 1.0   memory length: 186264   epsilon: 0.829195300003708    steps: 153    lr: 0.0001     evaluation reward: 2.58\n","episode: 975   score: 3.0   memory length: 186510   epsilon: 0.8287082200037186    steps: 246    lr: 0.0001     evaluation reward: 2.57\n","episode: 976   score: 2.0   memory length: 186692   epsilon: 0.8283478600037264    steps: 182    lr: 0.0001     evaluation reward: 2.56\n","episode: 977   score: 1.0   memory length: 186842   epsilon: 0.8280508600037328    steps: 150    lr: 0.0001     evaluation reward: 2.56\n","episode: 978   score: 0.0   memory length: 186964   epsilon: 0.8278093000037381    steps: 122    lr: 0.0001     evaluation reward: 2.51\n","episode: 979   score: 3.0   memory length: 187178   epsilon: 0.8273855800037473    steps: 214    lr: 0.0001     evaluation reward: 2.51\n","episode: 980   score: 1.0   memory length: 187348   epsilon: 0.8270489800037546    steps: 170    lr: 0.0001     evaluation reward: 2.51\n","episode: 981   score: 4.0   memory length: 187643   epsilon: 0.8264648800037673    steps: 295    lr: 0.0001     evaluation reward: 2.45\n","episode: 982   score: 4.0   memory length: 187941   epsilon: 0.8258748400037801    steps: 298    lr: 0.0001     evaluation reward: 2.46\n","episode: 983   score: 5.0   memory length: 188230   epsilon: 0.8253026200037925    steps: 289    lr: 0.0001     evaluation reward: 2.5\n","episode: 984   score: 2.0   memory length: 188410   epsilon: 0.8249462200038002    steps: 180    lr: 0.0001     evaluation reward: 2.51\n","episode: 985   score: 2.0   memory length: 188610   epsilon: 0.8245502200038088    steps: 200    lr: 0.0001     evaluation reward: 2.49\n","episode: 986   score: 2.0   memory length: 188808   epsilon: 0.8241581800038174    steps: 198    lr: 0.0001     evaluation reward: 2.49\n","episode: 987   score: 4.0   memory length: 189102   epsilon: 0.82357606000383    steps: 294    lr: 0.0001     evaluation reward: 2.5\n","episode: 988   score: 2.0   memory length: 189304   epsilon: 0.8231761000038387    steps: 202    lr: 0.0001     evaluation reward: 2.49\n","episode: 989   score: 0.0   memory length: 189426   epsilon: 0.8229345400038439    steps: 122    lr: 0.0001     evaluation reward: 2.47\n","episode: 990   score: 1.0   memory length: 189594   epsilon: 0.8226019000038511    steps: 168    lr: 0.0001     evaluation reward: 2.45\n","episode: 991   score: 1.0   memory length: 189763   epsilon: 0.8222672800038584    steps: 169    lr: 0.0001     evaluation reward: 2.44\n","episode: 992   score: 1.0   memory length: 189935   epsilon: 0.8219267200038658    steps: 172    lr: 0.0001     evaluation reward: 2.4\n","episode: 993   score: 4.0   memory length: 190228   epsilon: 0.8213465800038784    steps: 293    lr: 0.0001     evaluation reward: 2.4\n","episode: 994   score: 1.0   memory length: 190398   epsilon: 0.8210099800038857    steps: 170    lr: 0.0001     evaluation reward: 2.4\n","episode: 995   score: 1.0   memory length: 190549   epsilon: 0.8207110000038922    steps: 151    lr: 0.0001     evaluation reward: 2.38\n","episode: 996   score: 0.0   memory length: 190672   epsilon: 0.8204674600038975    steps: 123    lr: 0.0001     evaluation reward: 2.37\n","episode: 997   score: 5.0   memory length: 190975   epsilon: 0.8198675200039105    steps: 303    lr: 0.0001     evaluation reward: 2.35\n","episode: 998   score: 2.0   memory length: 191172   epsilon: 0.819477460003919    steps: 197    lr: 0.0001     evaluation reward: 2.34\n","episode: 999   score: 4.0   memory length: 191434   epsilon: 0.8189587000039302    steps: 262    lr: 0.0001     evaluation reward: 2.36\n","episode: 1000   score: 5.0   memory length: 191781   epsilon: 0.8182716400039451    steps: 347    lr: 0.0001     evaluation reward: 2.37\n","episode: 1001   score: 3.0   memory length: 192027   epsilon: 0.8177845600039557    steps: 246    lr: 0.0001     evaluation reward: 2.36\n","episode: 1002   score: 3.0   memory length: 192296   epsilon: 0.8172519400039673    steps: 269    lr: 0.0001     evaluation reward: 2.37\n","episode: 1003   score: 3.0   memory length: 192526   epsilon: 0.8167965400039772    steps: 230    lr: 0.0001     evaluation reward: 2.38\n","episode: 1004   score: 2.0   memory length: 192743   epsilon: 0.8163668800039865    steps: 217    lr: 0.0001     evaluation reward: 2.34\n","episode: 1005   score: 3.0   memory length: 192969   epsilon: 0.8159194000039962    steps: 226    lr: 0.0001     evaluation reward: 2.36\n","episode: 1006   score: 2.0   memory length: 193167   epsilon: 0.8155273600040047    steps: 198    lr: 0.0001     evaluation reward: 2.35\n","episode: 1007   score: 2.0   memory length: 193365   epsilon: 0.8151353200040132    steps: 198    lr: 0.0001     evaluation reward: 2.34\n","episode: 1008   score: 0.0   memory length: 193488   epsilon: 0.8148917800040185    steps: 123    lr: 0.0001     evaluation reward: 2.32\n","episode: 1009   score: 0.0   memory length: 193611   epsilon: 0.8146482400040238    steps: 123    lr: 0.0001     evaluation reward: 2.29\n","episode: 1010   score: 3.0   memory length: 193840   epsilon: 0.8141948200040336    steps: 229    lr: 0.0001     evaluation reward: 2.31\n","episode: 1011   score: 3.0   memory length: 194050   epsilon: 0.8137790200040427    steps: 210    lr: 0.0001     evaluation reward: 2.33\n","episode: 1012   score: 4.0   memory length: 194343   epsilon: 0.8131988800040553    steps: 293    lr: 0.0001     evaluation reward: 2.3\n","episode: 1013   score: 0.0   memory length: 194466   epsilon: 0.8129553400040606    steps: 123    lr: 0.0001     evaluation reward: 2.29\n","episode: 1014   score: 5.0   memory length: 194790   epsilon: 0.8123138200040745    steps: 324    lr: 0.0001     evaluation reward: 2.34\n","episode: 1015   score: 4.0   memory length: 195081   epsilon: 0.811737640004087    steps: 291    lr: 0.0001     evaluation reward: 2.37\n","episode: 1016   score: 4.0   memory length: 195361   epsilon: 0.811183240004099    steps: 280    lr: 0.0001     evaluation reward: 2.4\n","episode: 1017   score: 4.0   memory length: 195655   epsilon: 0.8106011200041117    steps: 294    lr: 0.0001     evaluation reward: 2.42\n","episode: 1018   score: 6.0   memory length: 195991   epsilon: 0.8099358400041261    steps: 336    lr: 0.0001     evaluation reward: 2.45\n","episode: 1019   score: 6.0   memory length: 196385   epsilon: 0.809155720004143    steps: 394    lr: 0.0001     evaluation reward: 2.47\n","episode: 1020   score: 2.0   memory length: 196603   epsilon: 0.8087240800041524    steps: 218    lr: 0.0001     evaluation reward: 2.47\n","episode: 1021   score: 2.0   memory length: 196801   epsilon: 0.8083320400041609    steps: 198    lr: 0.0001     evaluation reward: 2.46\n","episode: 1022   score: 3.0   memory length: 197031   epsilon: 0.8078766400041708    steps: 230    lr: 0.0001     evaluation reward: 2.46\n","episode: 1023   score: 6.0   memory length: 197384   epsilon: 0.807177700004186    steps: 353    lr: 0.0001     evaluation reward: 2.48\n","episode: 1024   score: 3.0   memory length: 197653   epsilon: 0.8066450800041975    steps: 269    lr: 0.0001     evaluation reward: 2.49\n","episode: 1025   score: 6.0   memory length: 198044   epsilon: 0.8058709000042144    steps: 391    lr: 0.0001     evaluation reward: 2.51\n","episode: 1026   score: 4.0   memory length: 198338   epsilon: 0.805288780004227    steps: 294    lr: 0.0001     evaluation reward: 2.51\n","episode: 1027   score: 5.0   memory length: 198670   epsilon: 0.8046314200042413    steps: 332    lr: 0.0001     evaluation reward: 2.56\n","episode: 1028   score: 0.0   memory length: 198792   epsilon: 0.8043898600042465    steps: 122    lr: 0.0001     evaluation reward: 2.5\n","episode: 1029   score: 1.0   memory length: 198962   epsilon: 0.8040532600042538    steps: 170    lr: 0.0001     evaluation reward: 2.47\n","episode: 1030   score: 3.0   memory length: 199228   epsilon: 0.8035265800042652    steps: 266    lr: 0.0001     evaluation reward: 2.48\n","episode: 1031   score: 3.0   memory length: 199475   epsilon: 0.8030375200042759    steps: 247    lr: 0.0001     evaluation reward: 2.48\n","episode: 1032   score: 2.0   memory length: 199673   epsilon: 0.8026454800042844    steps: 198    lr: 0.0001     evaluation reward: 2.48\n","episode: 1033   score: 0.0   memory length: 199795   epsilon: 0.8024039200042896    steps: 122    lr: 0.0001     evaluation reward: 2.46\n","episode: 1034   score: 4.0   memory length: 200070   epsilon: 0.8018594200043014    steps: 275    lr: 4e-05     evaluation reward: 2.46\n","episode: 1035   score: 1.0   memory length: 200223   epsilon: 0.801556480004308    steps: 153    lr: 4e-05     evaluation reward: 2.42\n","episode: 1036   score: 1.0   memory length: 200373   epsilon: 0.8012594800043145    steps: 150    lr: 4e-05     evaluation reward: 2.37\n","episode: 1037   score: 1.0   memory length: 200543   epsilon: 0.8009228800043218    steps: 170    lr: 4e-05     evaluation reward: 2.37\n","episode: 1038   score: 0.0   memory length: 200666   epsilon: 0.8006793400043271    steps: 123    lr: 4e-05     evaluation reward: 2.36\n","episode: 1039   score: 0.0   memory length: 200788   epsilon: 0.8004377800043323    steps: 122    lr: 4e-05     evaluation reward: 2.33\n","episode: 1040   score: 7.0   memory length: 201212   epsilon: 0.7995982600043505    steps: 424    lr: 4e-05     evaluation reward: 2.37\n","episode: 1041   score: 3.0   memory length: 201463   epsilon: 0.7991012800043613    steps: 251    lr: 4e-05     evaluation reward: 2.39\n","episode: 1042   score: 3.0   memory length: 201692   epsilon: 0.7986478600043712    steps: 229    lr: 4e-05     evaluation reward: 2.41\n","episode: 1043   score: 0.0   memory length: 201815   epsilon: 0.7984043200043764    steps: 123    lr: 4e-05     evaluation reward: 2.38\n","episode: 1044   score: 0.0   memory length: 201937   epsilon: 0.7981627600043817    steps: 122    lr: 4e-05     evaluation reward: 2.38\n","episode: 1045   score: 3.0   memory length: 202163   epsilon: 0.7977152800043914    steps: 226    lr: 4e-05     evaluation reward: 2.41\n","episode: 1046   score: 1.0   memory length: 202333   epsilon: 0.7973786800043987    steps: 170    lr: 4e-05     evaluation reward: 2.4\n","episode: 1047   score: 6.0   memory length: 202705   epsilon: 0.7966421200044147    steps: 372    lr: 4e-05     evaluation reward: 2.42\n","episode: 1048   score: 4.0   memory length: 203003   epsilon: 0.7960520800044275    steps: 298    lr: 4e-05     evaluation reward: 2.42\n","episode: 1049   score: 4.0   memory length: 203278   epsilon: 0.7955075800044393    steps: 275    lr: 4e-05     evaluation reward: 2.45\n","episode: 1050   score: 9.0   memory length: 203625   epsilon: 0.7948205200044542    steps: 347    lr: 4e-05     evaluation reward: 2.53\n","episode: 1051   score: 2.0   memory length: 203824   epsilon: 0.7944265000044628    steps: 199    lr: 4e-05     evaluation reward: 2.54\n","episode: 1052   score: 3.0   memory length: 204070   epsilon: 0.7939394200044734    steps: 246    lr: 4e-05     evaluation reward: 2.57\n","episode: 1053   score: 1.0   memory length: 204238   epsilon: 0.7936067800044806    steps: 168    lr: 4e-05     evaluation reward: 2.55\n","episode: 1054   score: 4.0   memory length: 204554   epsilon: 0.7929811000044942    steps: 316    lr: 4e-05     evaluation reward: 2.56\n","episode: 1055   score: 2.0   memory length: 204773   epsilon: 0.7925474800045036    steps: 219    lr: 4e-05     evaluation reward: 2.55\n","episode: 1056   score: 1.0   memory length: 204941   epsilon: 0.7922148400045108    steps: 168    lr: 4e-05     evaluation reward: 2.54\n","episode: 1057   score: 7.0   memory length: 205349   epsilon: 0.7914070000045283    steps: 408    lr: 4e-05     evaluation reward: 2.61\n","episode: 1058   score: 6.0   memory length: 205738   epsilon: 0.7906367800045451    steps: 389    lr: 4e-05     evaluation reward: 2.65\n","episode: 1059   score: 1.0   memory length: 205907   epsilon: 0.7903021600045523    steps: 169    lr: 4e-05     evaluation reward: 2.66\n","episode: 1060   score: 0.0   memory length: 206029   epsilon: 0.7900606000045576    steps: 122    lr: 4e-05     evaluation reward: 2.61\n","episode: 1061   score: 3.0   memory length: 206297   epsilon: 0.7895299600045691    steps: 268    lr: 4e-05     evaluation reward: 2.62\n","episode: 1062   score: 3.0   memory length: 206543   epsilon: 0.7890428800045797    steps: 246    lr: 4e-05     evaluation reward: 2.64\n","episode: 1063   score: 1.0   memory length: 206715   epsilon: 0.7887023200045871    steps: 172    lr: 4e-05     evaluation reward: 2.62\n","episode: 1064   score: 5.0   memory length: 207020   epsilon: 0.7880984200046002    steps: 305    lr: 4e-05     evaluation reward: 2.62\n","episode: 1065   score: 2.0   memory length: 207217   epsilon: 0.7877083600046086    steps: 197    lr: 4e-05     evaluation reward: 2.62\n","episode: 1066   score: 2.0   memory length: 207414   epsilon: 0.7873183000046171    steps: 197    lr: 4e-05     evaluation reward: 2.6\n","episode: 1067   score: 2.0   memory length: 207611   epsilon: 0.7869282400046256    steps: 197    lr: 4e-05     evaluation reward: 2.61\n","episode: 1068   score: 3.0   memory length: 207879   epsilon: 0.7863976000046371    steps: 268    lr: 4e-05     evaluation reward: 2.63\n","episode: 1069   score: 1.0   memory length: 208050   epsilon: 0.7860590200046444    steps: 171    lr: 4e-05     evaluation reward: 2.63\n","episode: 1070   score: 6.0   memory length: 208422   epsilon: 0.7853224600046604    steps: 372    lr: 4e-05     evaluation reward: 2.68\n","episode: 1071   score: 1.0   memory length: 208574   epsilon: 0.785021500004667    steps: 152    lr: 4e-05     evaluation reward: 2.68\n","episode: 1072   score: 3.0   memory length: 208785   epsilon: 0.784603720004676    steps: 211    lr: 4e-05     evaluation reward: 2.68\n","episode: 1073   score: 1.0   memory length: 208935   epsilon: 0.7843067200046825    steps: 150    lr: 4e-05     evaluation reward: 2.65\n","episode: 1074   score: 1.0   memory length: 209085   epsilon: 0.7840097200046889    steps: 150    lr: 4e-05     evaluation reward: 2.65\n","episode: 1075   score: 3.0   memory length: 209331   epsilon: 0.7835226400046995    steps: 246    lr: 4e-05     evaluation reward: 2.65\n","episode: 1076   score: 2.0   memory length: 209528   epsilon: 0.783132580004708    steps: 197    lr: 4e-05     evaluation reward: 2.65\n","episode: 1077   score: 4.0   memory length: 209820   epsilon: 0.7825544200047205    steps: 292    lr: 4e-05     evaluation reward: 2.68\n","episode: 1078   score: 2.0   memory length: 210039   epsilon: 0.7821208000047299    steps: 219    lr: 4e-05     evaluation reward: 2.7\n","episode: 1079   score: 2.0   memory length: 210236   epsilon: 0.7817307400047384    steps: 197    lr: 4e-05     evaluation reward: 2.69\n","episode: 1080   score: 1.0   memory length: 210387   epsilon: 0.7814317600047449    steps: 151    lr: 4e-05     evaluation reward: 2.69\n","episode: 1081   score: 2.0   memory length: 210606   epsilon: 0.7809981400047543    steps: 219    lr: 4e-05     evaluation reward: 2.67\n","episode: 1082   score: 3.0   memory length: 210853   epsilon: 0.7805090800047649    steps: 247    lr: 4e-05     evaluation reward: 2.66\n","episode: 1083   score: 3.0   memory length: 211099   epsilon: 0.7800220000047755    steps: 246    lr: 4e-05     evaluation reward: 2.64\n","episode: 1084   score: 3.0   memory length: 211312   epsilon: 0.7796002600047847    steps: 213    lr: 4e-05     evaluation reward: 2.65\n","episode: 1085   score: 1.0   memory length: 211481   epsilon: 0.7792656400047919    steps: 169    lr: 4e-05     evaluation reward: 2.64\n","episode: 1086   score: 6.0   memory length: 211853   epsilon: 0.7785290800048079    steps: 372    lr: 4e-05     evaluation reward: 2.68\n","episode: 1087   score: 2.0   memory length: 212032   epsilon: 0.7781746600048156    steps: 179    lr: 4e-05     evaluation reward: 2.66\n","episode: 1088   score: 0.0   memory length: 212154   epsilon: 0.7779331000048209    steps: 122    lr: 4e-05     evaluation reward: 2.64\n","episode: 1089   score: 3.0   memory length: 212379   epsilon: 0.7774876000048305    steps: 225    lr: 4e-05     evaluation reward: 2.67\n","episode: 1090   score: 3.0   memory length: 212624   epsilon: 0.7770025000048411    steps: 245    lr: 4e-05     evaluation reward: 2.69\n","episode: 1091   score: 1.0   memory length: 212793   epsilon: 0.7766678800048483    steps: 169    lr: 4e-05     evaluation reward: 2.69\n","episode: 1092   score: 2.0   memory length: 213009   epsilon: 0.7762402000048576    steps: 216    lr: 4e-05     evaluation reward: 2.7\n","episode: 1093   score: 3.0   memory length: 213234   epsilon: 0.7757947000048673    steps: 225    lr: 4e-05     evaluation reward: 2.69\n","episode: 1094   score: 3.0   memory length: 213479   epsilon: 0.7753096000048778    steps: 245    lr: 4e-05     evaluation reward: 2.71\n","episode: 1095   score: 1.0   memory length: 213649   epsilon: 0.7749730000048851    steps: 170    lr: 4e-05     evaluation reward: 2.71\n","episode: 1096   score: 3.0   memory length: 213912   epsilon: 0.7744522600048964    steps: 263    lr: 4e-05     evaluation reward: 2.74\n","episode: 1097   score: 5.0   memory length: 214237   epsilon: 0.7738087600049104    steps: 325    lr: 4e-05     evaluation reward: 2.74\n","episode: 1098   score: 1.0   memory length: 214408   epsilon: 0.7734701800049177    steps: 171    lr: 4e-05     evaluation reward: 2.73\n","episode: 1099   score: 1.0   memory length: 214579   epsilon: 0.7731316000049251    steps: 171    lr: 4e-05     evaluation reward: 2.7\n","episode: 1100   score: 2.0   memory length: 214776   epsilon: 0.7727415400049336    steps: 197    lr: 4e-05     evaluation reward: 2.67\n","episode: 1101   score: 1.0   memory length: 214948   epsilon: 0.772400980004941    steps: 172    lr: 4e-05     evaluation reward: 2.65\n","episode: 1102   score: 4.0   memory length: 215235   epsilon: 0.7718327200049533    steps: 287    lr: 4e-05     evaluation reward: 2.66\n","episode: 1103   score: 3.0   memory length: 215464   epsilon: 0.7713793000049631    steps: 229    lr: 4e-05     evaluation reward: 2.66\n","episode: 1104   score: 4.0   memory length: 215744   epsilon: 0.7708249000049752    steps: 280    lr: 4e-05     evaluation reward: 2.68\n","episode: 1105   score: 4.0   memory length: 216058   epsilon: 0.7702031800049887    steps: 314    lr: 4e-05     evaluation reward: 2.69\n","episode: 1106   score: 8.0   memory length: 216490   epsilon: 0.7693478200050072    steps: 432    lr: 4e-05     evaluation reward: 2.75\n","episode: 1107   score: 2.0   memory length: 216670   epsilon: 0.768991420005015    steps: 180    lr: 4e-05     evaluation reward: 2.75\n","episode: 1108   score: 3.0   memory length: 216938   epsilon: 0.7684607800050265    steps: 268    lr: 4e-05     evaluation reward: 2.78\n","episode: 1109   score: 3.0   memory length: 217185   epsilon: 0.7679717200050371    steps: 247    lr: 4e-05     evaluation reward: 2.81\n","episode: 1110   score: 2.0   memory length: 217383   epsilon: 0.7675796800050456    steps: 198    lr: 4e-05     evaluation reward: 2.8\n","episode: 1111   score: 5.0   memory length: 217693   epsilon: 0.7669658800050589    steps: 310    lr: 4e-05     evaluation reward: 2.82\n","episode: 1112   score: 5.0   memory length: 217985   epsilon: 0.7663877200050715    steps: 292    lr: 4e-05     evaluation reward: 2.83\n","episode: 1113   score: 5.0   memory length: 218327   epsilon: 0.7657105600050862    steps: 342    lr: 4e-05     evaluation reward: 2.88\n","episode: 1114   score: 1.0   memory length: 218496   epsilon: 0.7653759400050935    steps: 169    lr: 4e-05     evaluation reward: 2.84\n","episode: 1115   score: 1.0   memory length: 218667   epsilon: 0.7650373600051008    steps: 171    lr: 4e-05     evaluation reward: 2.81\n","episode: 1116   score: 4.0   memory length: 218942   epsilon: 0.7644928600051126    steps: 275    lr: 4e-05     evaluation reward: 2.81\n","episode: 1117   score: 3.0   memory length: 219169   epsilon: 0.7640434000051224    steps: 227    lr: 4e-05     evaluation reward: 2.8\n","episode: 1118   score: 0.0   memory length: 219292   epsilon: 0.7637998600051277    steps: 123    lr: 4e-05     evaluation reward: 2.74\n","episode: 1119   score: 1.0   memory length: 219462   epsilon: 0.763463260005135    steps: 170    lr: 4e-05     evaluation reward: 2.69\n","episode: 1120   score: 3.0   memory length: 219687   epsilon: 0.7630177600051447    steps: 225    lr: 4e-05     evaluation reward: 2.7\n","episode: 1121   score: 5.0   memory length: 220045   epsilon: 0.76230892000516    steps: 358    lr: 4e-05     evaluation reward: 2.73\n","episode: 1122   score: 3.0   memory length: 220260   epsilon: 0.7618832200051693    steps: 215    lr: 4e-05     evaluation reward: 2.73\n","episode: 1123   score: 4.0   memory length: 220535   epsilon: 0.7613387200051811    steps: 275    lr: 4e-05     evaluation reward: 2.71\n","episode: 1124   score: 3.0   memory length: 220786   epsilon: 0.7608417400051919    steps: 251    lr: 4e-05     evaluation reward: 2.71\n","episode: 1125   score: 3.0   memory length: 221054   epsilon: 0.7603111000052034    steps: 268    lr: 4e-05     evaluation reward: 2.68\n","episode: 1126   score: 0.0   memory length: 221177   epsilon: 0.7600675600052087    steps: 123    lr: 4e-05     evaluation reward: 2.64\n","episode: 1127   score: 3.0   memory length: 221388   epsilon: 0.7596497800052178    steps: 211    lr: 4e-05     evaluation reward: 2.62\n","episode: 1128   score: 4.0   memory length: 221682   epsilon: 0.7590676600052304    steps: 294    lr: 4e-05     evaluation reward: 2.66\n","episode: 1129   score: 4.0   memory length: 221995   epsilon: 0.7584479200052439    steps: 313    lr: 4e-05     evaluation reward: 2.69\n","episode: 1130   score: 5.0   memory length: 222319   epsilon: 0.7578064000052578    steps: 324    lr: 4e-05     evaluation reward: 2.71\n","episode: 1131   score: 5.0   memory length: 222596   epsilon: 0.7572579400052697    steps: 277    lr: 4e-05     evaluation reward: 2.73\n","episode: 1132   score: 4.0   memory length: 222871   epsilon: 0.7567134400052815    steps: 275    lr: 4e-05     evaluation reward: 2.75\n","episode: 1133   score: 2.0   memory length: 223050   epsilon: 0.7563590200052892    steps: 179    lr: 4e-05     evaluation reward: 2.77\n","episode: 1134   score: 3.0   memory length: 223301   epsilon: 0.7558620400053    steps: 251    lr: 4e-05     evaluation reward: 2.76\n","episode: 1135   score: 4.0   memory length: 223597   epsilon: 0.7552759600053127    steps: 296    lr: 4e-05     evaluation reward: 2.79\n","episode: 1136   score: 3.0   memory length: 223822   epsilon: 0.7548304600053224    steps: 225    lr: 4e-05     evaluation reward: 2.81\n","episode: 1137   score: 2.0   memory length: 224024   epsilon: 0.7544305000053311    steps: 202    lr: 4e-05     evaluation reward: 2.82\n","episode: 1138   score: 2.0   memory length: 224224   epsilon: 0.7540345000053397    steps: 200    lr: 4e-05     evaluation reward: 2.84\n","episode: 1139   score: 6.0   memory length: 224577   epsilon: 0.7533355600053548    steps: 353    lr: 4e-05     evaluation reward: 2.9\n","episode: 1140   score: 1.0   memory length: 224748   epsilon: 0.7529969800053622    steps: 171    lr: 4e-05     evaluation reward: 2.84\n","episode: 1141   score: 3.0   memory length: 225015   epsilon: 0.7524683200053737    steps: 267    lr: 4e-05     evaluation reward: 2.84\n","episode: 1142   score: 1.0   memory length: 225183   epsilon: 0.7521356800053809    steps: 168    lr: 4e-05     evaluation reward: 2.82\n","episode: 1143   score: 3.0   memory length: 225412   epsilon: 0.7516822600053907    steps: 229    lr: 4e-05     evaluation reward: 2.85\n","episode: 1144   score: 2.0   memory length: 225610   epsilon: 0.7512902200053992    steps: 198    lr: 4e-05     evaluation reward: 2.87\n","episode: 1145   score: 1.0   memory length: 225779   epsilon: 0.7509556000054065    steps: 169    lr: 4e-05     evaluation reward: 2.85\n","episode: 1146   score: 4.0   memory length: 226054   epsilon: 0.7504111000054183    steps: 275    lr: 4e-05     evaluation reward: 2.88\n","episode: 1147   score: 2.0   memory length: 226253   epsilon: 0.7500170800054269    steps: 199    lr: 4e-05     evaluation reward: 2.84\n","episode: 1148   score: 3.0   memory length: 226484   epsilon: 0.7495597000054368    steps: 231    lr: 4e-05     evaluation reward: 2.83\n","episode: 1149   score: 4.0   memory length: 226778   epsilon: 0.7489775800054495    steps: 294    lr: 4e-05     evaluation reward: 2.83\n","episode: 1150   score: 2.0   memory length: 226976   epsilon: 0.748585540005458    steps: 198    lr: 4e-05     evaluation reward: 2.76\n","episode: 1151   score: 1.0   memory length: 227127   epsilon: 0.7482865600054645    steps: 151    lr: 4e-05     evaluation reward: 2.75\n","episode: 1152   score: 6.0   memory length: 227494   epsilon: 0.7475599000054802    steps: 367    lr: 4e-05     evaluation reward: 2.78\n","episode: 1153   score: 1.0   memory length: 227666   epsilon: 0.7472193400054876    steps: 172    lr: 4e-05     evaluation reward: 2.78\n","episode: 1154   score: 2.0   memory length: 227864   epsilon: 0.7468273000054961    steps: 198    lr: 4e-05     evaluation reward: 2.76\n","episode: 1155   score: 2.0   memory length: 228061   epsilon: 0.7464372400055046    steps: 197    lr: 4e-05     evaluation reward: 2.76\n","episode: 1156   score: 5.0   memory length: 228399   epsilon: 0.7457680000055191    steps: 338    lr: 4e-05     evaluation reward: 2.8\n","episode: 1157   score: 3.0   memory length: 228646   epsilon: 0.7452789400055297    steps: 247    lr: 4e-05     evaluation reward: 2.76\n","episode: 1158   score: 5.0   memory length: 228990   epsilon: 0.7445978200055445    steps: 344    lr: 4e-05     evaluation reward: 2.75\n","episode: 1159   score: 2.0   memory length: 229189   epsilon: 0.7442038000055531    steps: 199    lr: 4e-05     evaluation reward: 2.76\n","episode: 1160   score: 5.0   memory length: 229513   epsilon: 0.743562280005567    steps: 324    lr: 4e-05     evaluation reward: 2.81\n","episode: 1161   score: 3.0   memory length: 229760   epsilon: 0.7430732200055776    steps: 247    lr: 4e-05     evaluation reward: 2.81\n","episode: 1162   score: 4.0   memory length: 230055   epsilon: 0.7424891200055903    steps: 295    lr: 4e-05     evaluation reward: 2.82\n","episode: 1163   score: 4.0   memory length: 230329   epsilon: 0.7419466000056021    steps: 274    lr: 4e-05     evaluation reward: 2.85\n","episode: 1164   score: 2.0   memory length: 230527   epsilon: 0.7415545600056106    steps: 198    lr: 4e-05     evaluation reward: 2.82\n","episode: 1165   score: 5.0   memory length: 230849   epsilon: 0.7409170000056244    steps: 322    lr: 4e-05     evaluation reward: 2.85\n","episode: 1166   score: 1.0   memory length: 231020   epsilon: 0.7405784200056318    steps: 171    lr: 4e-05     evaluation reward: 2.84\n","episode: 1167   score: 4.0   memory length: 231297   epsilon: 0.7400299600056437    steps: 277    lr: 4e-05     evaluation reward: 2.86\n","episode: 1168   score: 4.0   memory length: 231576   epsilon: 0.7394775400056557    steps: 279    lr: 4e-05     evaluation reward: 2.87\n","episode: 1169   score: 3.0   memory length: 231802   epsilon: 0.7390300600056654    steps: 226    lr: 4e-05     evaluation reward: 2.89\n","episode: 1170   score: 4.0   memory length: 232118   epsilon: 0.738404380005679    steps: 316    lr: 4e-05     evaluation reward: 2.87\n","episode: 1171   score: 1.0   memory length: 232287   epsilon: 0.7380697600056862    steps: 169    lr: 4e-05     evaluation reward: 2.87\n","episode: 1172   score: 12.0   memory length: 232789   epsilon: 0.7370758000057078    steps: 502    lr: 4e-05     evaluation reward: 2.96\n","episode: 1173   score: 2.0   memory length: 232986   epsilon: 0.7366857400057163    steps: 197    lr: 4e-05     evaluation reward: 2.97\n","episode: 1174   score: 1.0   memory length: 233155   epsilon: 0.7363511200057236    steps: 169    lr: 4e-05     evaluation reward: 2.97\n","episode: 1175   score: 3.0   memory length: 233384   epsilon: 0.7358977000057334    steps: 229    lr: 4e-05     evaluation reward: 2.97\n","episode: 1176   score: 1.0   memory length: 233553   epsilon: 0.7355630800057407    steps: 169    lr: 4e-05     evaluation reward: 2.96\n","episode: 1177   score: 6.0   memory length: 233945   epsilon: 0.7347869200057575    steps: 392    lr: 4e-05     evaluation reward: 2.98\n","episode: 1178   score: 4.0   memory length: 234189   epsilon: 0.734303800005768    steps: 244    lr: 4e-05     evaluation reward: 3.0\n","episode: 1179   score: 8.0   memory length: 234595   epsilon: 0.7334999200057855    steps: 406    lr: 4e-05     evaluation reward: 3.06\n","episode: 1180   score: 3.0   memory length: 234863   epsilon: 0.732969280005797    steps: 268    lr: 4e-05     evaluation reward: 3.08\n","episode: 1181   score: 5.0   memory length: 235187   epsilon: 0.7323277600058109    steps: 324    lr: 4e-05     evaluation reward: 3.11\n","episode: 1182   score: 2.0   memory length: 235368   epsilon: 0.7319693800058187    steps: 181    lr: 4e-05     evaluation reward: 3.1\n","episode: 1183   score: 4.0   memory length: 235634   epsilon: 0.7314427000058301    steps: 266    lr: 4e-05     evaluation reward: 3.11\n","episode: 1184   score: 4.0   memory length: 235893   epsilon: 0.7309298800058412    steps: 259    lr: 4e-05     evaluation reward: 3.12\n","episode: 1185   score: 3.0   memory length: 236139   epsilon: 0.7304428000058518    steps: 246    lr: 4e-05     evaluation reward: 3.14\n","episode: 1186   score: 5.0   memory length: 236449   epsilon: 0.7298290000058651    steps: 310    lr: 4e-05     evaluation reward: 3.13\n","episode: 1187   score: 2.0   memory length: 236648   epsilon: 0.7294349800058737    steps: 199    lr: 4e-05     evaluation reward: 3.13\n","episode: 1188   score: 3.0   memory length: 236875   epsilon: 0.7289855200058835    steps: 227    lr: 4e-05     evaluation reward: 3.16\n","episode: 1189   score: 4.0   memory length: 237172   epsilon: 0.7283974600058962    steps: 297    lr: 4e-05     evaluation reward: 3.17\n","episode: 1190   score: 5.0   memory length: 237502   epsilon: 0.7277440600059104    steps: 330    lr: 4e-05     evaluation reward: 3.19\n","episode: 1191   score: 1.0   memory length: 237671   epsilon: 0.7274094400059177    steps: 169    lr: 4e-05     evaluation reward: 3.19\n","episode: 1192   score: 3.0   memory length: 237901   epsilon: 0.7269540400059276    steps: 230    lr: 4e-05     evaluation reward: 3.2\n","episode: 1193   score: 1.0   memory length: 238052   epsilon: 0.726655060005934    steps: 151    lr: 4e-05     evaluation reward: 3.18\n","episode: 1194   score: 4.0   memory length: 238329   epsilon: 0.726106600005946    steps: 277    lr: 4e-05     evaluation reward: 3.19\n","episode: 1195   score: 2.0   memory length: 238548   epsilon: 0.7256729800059554    steps: 219    lr: 4e-05     evaluation reward: 3.2\n","episode: 1196   score: 4.0   memory length: 238845   epsilon: 0.7250849200059681    steps: 297    lr: 4e-05     evaluation reward: 3.21\n","episode: 1197   score: 1.0   memory length: 238996   epsilon: 0.7247859400059746    steps: 151    lr: 4e-05     evaluation reward: 3.17\n","episode: 1198   score: 8.0   memory length: 239448   epsilon: 0.7238909800059941    steps: 452    lr: 4e-05     evaluation reward: 3.24\n","episode: 1199   score: 3.0   memory length: 239674   epsilon: 0.7234435000060038    steps: 226    lr: 4e-05     evaluation reward: 3.26\n","episode: 1200   score: 5.0   memory length: 239980   epsilon: 0.7228376200060169    steps: 306    lr: 4e-05     evaluation reward: 3.29\n","episode: 1201   score: 5.0   memory length: 240327   epsilon: 0.7221505600060318    steps: 347    lr: 4e-05     evaluation reward: 3.33\n","episode: 1202   score: 7.0   memory length: 240693   epsilon: 0.7214258800060476    steps: 366    lr: 4e-05     evaluation reward: 3.36\n","episode: 1203   score: 5.0   memory length: 241001   epsilon: 0.7208160400060608    steps: 308    lr: 4e-05     evaluation reward: 3.38\n","episode: 1204   score: 1.0   memory length: 241152   epsilon: 0.7205170600060673    steps: 151    lr: 4e-05     evaluation reward: 3.35\n","episode: 1205   score: 1.0   memory length: 241303   epsilon: 0.7202180800060738    steps: 151    lr: 4e-05     evaluation reward: 3.32\n","episode: 1206   score: 6.0   memory length: 241688   epsilon: 0.7194557800060903    steps: 385    lr: 4e-05     evaluation reward: 3.3\n","episode: 1207   score: 3.0   memory length: 241936   epsilon: 0.718964740006101    steps: 248    lr: 4e-05     evaluation reward: 3.31\n","episode: 1208   score: 5.0   memory length: 242238   epsilon: 0.718366780006114    steps: 302    lr: 4e-05     evaluation reward: 3.33\n","episode: 1209   score: 6.0   memory length: 242561   epsilon: 0.7177272400061279    steps: 323    lr: 4e-05     evaluation reward: 3.36\n","episode: 1210   score: 4.0   memory length: 242854   epsilon: 0.7171471000061405    steps: 293    lr: 4e-05     evaluation reward: 3.38\n","episode: 1211   score: 3.0   memory length: 243082   epsilon: 0.7166956600061503    steps: 228    lr: 4e-05     evaluation reward: 3.36\n","episode: 1212   score: 4.0   memory length: 243395   epsilon: 0.7160759200061637    steps: 313    lr: 4e-05     evaluation reward: 3.35\n","episode: 1213   score: 1.0   memory length: 243546   epsilon: 0.7157769400061702    steps: 151    lr: 4e-05     evaluation reward: 3.31\n","episode: 1214   score: 3.0   memory length: 243811   epsilon: 0.7152522400061816    steps: 265    lr: 4e-05     evaluation reward: 3.33\n","episode: 1215   score: 4.0   memory length: 244104   epsilon: 0.7146721000061942    steps: 293    lr: 4e-05     evaluation reward: 3.36\n","episode: 1216   score: 3.0   memory length: 244332   epsilon: 0.714220660006204    steps: 228    lr: 4e-05     evaluation reward: 3.35\n","episode: 1217   score: 5.0   memory length: 244658   epsilon: 0.713575180006218    steps: 326    lr: 4e-05     evaluation reward: 3.37\n","episode: 1218   score: 0.0   memory length: 244781   epsilon: 0.7133316400062233    steps: 123    lr: 4e-05     evaluation reward: 3.37\n","episode: 1219   score: 3.0   memory length: 244991   epsilon: 0.7129158400062323    steps: 210    lr: 4e-05     evaluation reward: 3.39\n","episode: 1220   score: 9.0   memory length: 245391   epsilon: 0.7121238400062495    steps: 400    lr: 4e-05     evaluation reward: 3.45\n","episode: 1221   score: 4.0   memory length: 245666   epsilon: 0.7115793400062613    steps: 275    lr: 4e-05     evaluation reward: 3.44\n","episode: 1222   score: 3.0   memory length: 245877   epsilon: 0.7111615600062704    steps: 211    lr: 4e-05     evaluation reward: 3.44\n","episode: 1223   score: 7.0   memory length: 246239   epsilon: 0.710444800006286    steps: 362    lr: 4e-05     evaluation reward: 3.47\n","episode: 1224   score: 3.0   memory length: 246486   epsilon: 0.7099557400062966    steps: 247    lr: 4e-05     evaluation reward: 3.47\n","episode: 1225   score: 3.0   memory length: 246715   epsilon: 0.7095023200063064    steps: 229    lr: 4e-05     evaluation reward: 3.47\n","episode: 1226   score: 4.0   memory length: 246978   epsilon: 0.7089815800063177    steps: 263    lr: 4e-05     evaluation reward: 3.51\n","episode: 1227   score: 0.0   memory length: 247101   epsilon: 0.708738040006323    steps: 123    lr: 4e-05     evaluation reward: 3.48\n","episode: 1228   score: 6.0   memory length: 247481   epsilon: 0.7079856400063393    steps: 380    lr: 4e-05     evaluation reward: 3.5\n","episode: 1229   score: 5.0   memory length: 247823   epsilon: 0.707308480006354    steps: 342    lr: 4e-05     evaluation reward: 3.51\n","episode: 1230   score: 5.0   memory length: 248151   epsilon: 0.7066590400063681    steps: 328    lr: 4e-05     evaluation reward: 3.51\n","episode: 1231   score: 2.0   memory length: 248351   epsilon: 0.7062630400063767    steps: 200    lr: 4e-05     evaluation reward: 3.48\n","episode: 1232   score: 2.0   memory length: 248568   epsilon: 0.7058333800063861    steps: 217    lr: 4e-05     evaluation reward: 3.46\n","episode: 1233   score: 2.0   memory length: 248765   epsilon: 0.7054433200063945    steps: 197    lr: 4e-05     evaluation reward: 3.46\n","episode: 1234   score: 2.0   memory length: 248947   epsilon: 0.7050829600064024    steps: 182    lr: 4e-05     evaluation reward: 3.45\n","episode: 1235   score: 4.0   memory length: 249222   epsilon: 0.7045384600064142    steps: 275    lr: 4e-05     evaluation reward: 3.45\n","episode: 1236   score: 2.0   memory length: 249401   epsilon: 0.7041840400064219    steps: 179    lr: 4e-05     evaluation reward: 3.44\n","episode: 1237   score: 4.0   memory length: 249696   epsilon: 0.7035999400064346    steps: 295    lr: 4e-05     evaluation reward: 3.46\n","episode: 1238   score: 3.0   memory length: 249944   epsilon: 0.7031089000064452    steps: 248    lr: 4e-05     evaluation reward: 3.47\n","episode: 1239   score: 4.0   memory length: 250200   epsilon: 0.7026020200064562    steps: 256    lr: 4e-05     evaluation reward: 3.45\n","episode: 1240   score: 6.0   memory length: 250612   epsilon: 0.7017862600064739    steps: 412    lr: 4e-05     evaluation reward: 3.5\n","episode: 1241   score: 3.0   memory length: 250859   epsilon: 0.7012972000064845    steps: 247    lr: 4e-05     evaluation reward: 3.5\n","episode: 1242   score: 3.0   memory length: 251105   epsilon: 0.7008101200064951    steps: 246    lr: 4e-05     evaluation reward: 3.52\n","episode: 1243   score: 2.0   memory length: 251304   epsilon: 0.7004161000065037    steps: 199    lr: 4e-05     evaluation reward: 3.51\n","episode: 1244   score: 2.0   memory length: 251522   epsilon: 0.699984460006513    steps: 218    lr: 4e-05     evaluation reward: 3.51\n","episode: 1245   score: 1.0   memory length: 251691   epsilon: 0.6996498400065203    steps: 169    lr: 4e-05     evaluation reward: 3.51\n","episode: 1246   score: 3.0   memory length: 251938   epsilon: 0.6991607800065309    steps: 247    lr: 4e-05     evaluation reward: 3.5\n","episode: 1247   score: 4.0   memory length: 252214   epsilon: 0.6986143000065428    steps: 276    lr: 4e-05     evaluation reward: 3.52\n","episode: 1248   score: 0.0   memory length: 252337   epsilon: 0.6983707600065481    steps: 123    lr: 4e-05     evaluation reward: 3.49\n","episode: 1249   score: 5.0   memory length: 252678   epsilon: 0.6976955800065627    steps: 341    lr: 4e-05     evaluation reward: 3.5\n","episode: 1250   score: 2.0   memory length: 252858   epsilon: 0.6973391800065705    steps: 180    lr: 4e-05     evaluation reward: 3.5\n","episode: 1251   score: 5.0   memory length: 253162   epsilon: 0.6967372600065835    steps: 304    lr: 4e-05     evaluation reward: 3.54\n","episode: 1252   score: 3.0   memory length: 253411   epsilon: 0.6962442400065942    steps: 249    lr: 4e-05     evaluation reward: 3.51\n","episode: 1253   score: 5.0   memory length: 253722   epsilon: 0.6956284600066076    steps: 311    lr: 4e-05     evaluation reward: 3.55\n","episode: 1254   score: 4.0   memory length: 253998   epsilon: 0.6950819800066195    steps: 276    lr: 4e-05     evaluation reward: 3.57\n","episode: 1255   score: 7.0   memory length: 254369   epsilon: 0.6943474000066354    steps: 371    lr: 4e-05     evaluation reward: 3.62\n","episode: 1256   score: 6.0   memory length: 254738   epsilon: 0.6936167800066513    steps: 369    lr: 4e-05     evaluation reward: 3.63\n","episode: 1257   score: 5.0   memory length: 255026   epsilon: 0.6930465400066637    steps: 288    lr: 4e-05     evaluation reward: 3.65\n","episode: 1258   score: 1.0   memory length: 255195   epsilon: 0.6927119200066709    steps: 169    lr: 4e-05     evaluation reward: 3.61\n","episode: 1259   score: 5.0   memory length: 255560   epsilon: 0.6919892200066866    steps: 365    lr: 4e-05     evaluation reward: 3.64\n","episode: 1260   score: 1.0   memory length: 255728   epsilon: 0.6916565800066938    steps: 168    lr: 4e-05     evaluation reward: 3.6\n","episode: 1261   score: 2.0   memory length: 255944   epsilon: 0.6912289000067031    steps: 216    lr: 4e-05     evaluation reward: 3.59\n","episode: 1262   score: 2.0   memory length: 256125   epsilon: 0.6908705200067109    steps: 181    lr: 4e-05     evaluation reward: 3.57\n","episode: 1263   score: 3.0   memory length: 256351   epsilon: 0.6904230400067206    steps: 226    lr: 4e-05     evaluation reward: 3.56\n","episode: 1264   score: 2.0   memory length: 256551   epsilon: 0.6900270400067292    steps: 200    lr: 4e-05     evaluation reward: 3.56\n","episode: 1265   score: 2.0   memory length: 256731   epsilon: 0.689670640006737    steps: 180    lr: 4e-05     evaluation reward: 3.53\n","episode: 1266   score: 3.0   memory length: 256979   epsilon: 0.6891796000067476    steps: 248    lr: 4e-05     evaluation reward: 3.55\n","episode: 1267   score: 7.0   memory length: 257381   epsilon: 0.6883836400067649    steps: 402    lr: 4e-05     evaluation reward: 3.58\n","episode: 1268   score: 7.0   memory length: 257800   epsilon: 0.6875540200067829    steps: 419    lr: 4e-05     evaluation reward: 3.61\n","episode: 1269   score: 3.0   memory length: 258026   epsilon: 0.6871065400067926    steps: 226    lr: 4e-05     evaluation reward: 3.61\n","episode: 1270   score: 5.0   memory length: 258351   epsilon: 0.6864630400068066    steps: 325    lr: 4e-05     evaluation reward: 3.62\n","episode: 1271   score: 2.0   memory length: 258549   epsilon: 0.6860710000068151    steps: 198    lr: 4e-05     evaluation reward: 3.63\n","episode: 1272   score: 3.0   memory length: 258776   epsilon: 0.6856215400068248    steps: 227    lr: 4e-05     evaluation reward: 3.54\n","episode: 1273   score: 3.0   memory length: 259023   epsilon: 0.6851324800068355    steps: 247    lr: 4e-05     evaluation reward: 3.55\n","episode: 1274   score: 3.0   memory length: 259269   epsilon: 0.684645400006846    steps: 246    lr: 4e-05     evaluation reward: 3.57\n","episode: 1275   score: 1.0   memory length: 259422   epsilon: 0.6843424600068526    steps: 153    lr: 4e-05     evaluation reward: 3.55\n","episode: 1276   score: 1.0   memory length: 259591   epsilon: 0.6840078400068599    steps: 169    lr: 4e-05     evaluation reward: 3.55\n","episode: 1277   score: 3.0   memory length: 259837   epsilon: 0.6835207600068705    steps: 246    lr: 4e-05     evaluation reward: 3.52\n","episode: 1278   score: 2.0   memory length: 260037   epsilon: 0.683124760006879    steps: 200    lr: 4e-05     evaluation reward: 3.5\n","episode: 1279   score: 3.0   memory length: 260247   epsilon: 0.6827089600068881    steps: 210    lr: 4e-05     evaluation reward: 3.45\n","episode: 1280   score: 6.0   memory length: 260617   epsilon: 0.681976360006904    steps: 370    lr: 4e-05     evaluation reward: 3.48\n","episode: 1281   score: 3.0   memory length: 260883   epsilon: 0.6814496800069154    steps: 266    lr: 4e-05     evaluation reward: 3.46\n","episode: 1282   score: 5.0   memory length: 261197   epsilon: 0.6808279600069289    steps: 314    lr: 4e-05     evaluation reward: 3.49\n","episode: 1283   score: 5.0   memory length: 261487   epsilon: 0.6802537600069414    steps: 290    lr: 4e-05     evaluation reward: 3.5\n","episode: 1284   score: 4.0   memory length: 261779   epsilon: 0.6796756000069539    steps: 292    lr: 4e-05     evaluation reward: 3.5\n","episode: 1285   score: 4.0   memory length: 262057   epsilon: 0.6791251600069659    steps: 278    lr: 4e-05     evaluation reward: 3.51\n","episode: 1286   score: 5.0   memory length: 262363   epsilon: 0.678519280006979    steps: 306    lr: 4e-05     evaluation reward: 3.51\n","episode: 1287   score: 1.0   memory length: 262514   epsilon: 0.6782203000069855    steps: 151    lr: 4e-05     evaluation reward: 3.5\n","episode: 1288   score: 6.0   memory length: 262872   epsilon: 0.6775114600070009    steps: 358    lr: 4e-05     evaluation reward: 3.53\n","episode: 1289   score: 2.0   memory length: 263072   epsilon: 0.6771154600070095    steps: 200    lr: 4e-05     evaluation reward: 3.51\n","episode: 1290   score: 2.0   memory length: 263269   epsilon: 0.676725400007018    steps: 197    lr: 4e-05     evaluation reward: 3.48\n","episode: 1291   score: 4.0   memory length: 263553   epsilon: 0.6761630800070302    steps: 284    lr: 4e-05     evaluation reward: 3.51\n","episode: 1292   score: 2.0   memory length: 263751   epsilon: 0.6757710400070387    steps: 198    lr: 4e-05     evaluation reward: 3.5\n","episode: 1293   score: 10.0   memory length: 264249   epsilon: 0.6747850000070601    steps: 498    lr: 4e-05     evaluation reward: 3.59\n","episode: 1294   score: 9.0   memory length: 264701   epsilon: 0.6738900400070795    steps: 452    lr: 4e-05     evaluation reward: 3.64\n","episode: 1295   score: 3.0   memory length: 264950   epsilon: 0.6733970200070902    steps: 249    lr: 4e-05     evaluation reward: 3.65\n","episode: 1296   score: 4.0   memory length: 265227   epsilon: 0.6728485600071021    steps: 277    lr: 4e-05     evaluation reward: 3.65\n","episode: 1297   score: 4.0   memory length: 265526   epsilon: 0.672256540007115    steps: 299    lr: 4e-05     evaluation reward: 3.68\n","episode: 1298   score: 3.0   memory length: 265795   epsilon: 0.6717239200071266    steps: 269    lr: 4e-05     evaluation reward: 3.63\n","episode: 1299   score: 1.0   memory length: 265946   epsilon: 0.671424940007133    steps: 151    lr: 4e-05     evaluation reward: 3.61\n","episode: 1300   score: 3.0   memory length: 266194   epsilon: 0.6709339000071437    steps: 248    lr: 4e-05     evaluation reward: 3.59\n","episode: 1301   score: 6.0   memory length: 266551   epsilon: 0.670227040007159    steps: 357    lr: 4e-05     evaluation reward: 3.6\n","episode: 1302   score: 4.0   memory length: 266826   epsilon: 0.6696825400071709    steps: 275    lr: 4e-05     evaluation reward: 3.57\n","episode: 1303   score: 2.0   memory length: 267027   epsilon: 0.6692845600071795    steps: 201    lr: 4e-05     evaluation reward: 3.54\n","episode: 1304   score: 7.0   memory length: 267466   epsilon: 0.6684153400071984    steps: 439    lr: 4e-05     evaluation reward: 3.6\n","episode: 1305   score: 4.0   memory length: 267781   epsilon: 0.6677916400072119    steps: 315    lr: 4e-05     evaluation reward: 3.63\n","episode: 1306   score: 3.0   memory length: 267991   epsilon: 0.6673758400072209    steps: 210    lr: 4e-05     evaluation reward: 3.6\n","episode: 1307   score: 4.0   memory length: 268253   epsilon: 0.6668570800072322    steps: 262    lr: 4e-05     evaluation reward: 3.61\n","episode: 1308   score: 5.0   memory length: 268577   epsilon: 0.6662155600072461    steps: 324    lr: 4e-05     evaluation reward: 3.61\n","episode: 1309   score: 10.0   memory length: 268998   epsilon: 0.6653819800072642    steps: 421    lr: 4e-05     evaluation reward: 3.65\n","episode: 1310   score: 6.0   memory length: 269312   epsilon: 0.6647602600072777    steps: 314    lr: 4e-05     evaluation reward: 3.67\n","episode: 1311   score: 4.0   memory length: 269612   epsilon: 0.6641662600072906    steps: 300    lr: 4e-05     evaluation reward: 3.68\n","episode: 1312   score: 5.0   memory length: 269955   epsilon: 0.6634871200073054    steps: 343    lr: 4e-05     evaluation reward: 3.69\n","episode: 1313   score: 1.0   memory length: 270106   epsilon: 0.6631881400073119    steps: 151    lr: 4e-05     evaluation reward: 3.69\n","episode: 1314   score: 5.0   memory length: 270421   epsilon: 0.6625644400073254    steps: 315    lr: 4e-05     evaluation reward: 3.71\n","episode: 1315   score: 5.0   memory length: 270746   epsilon: 0.6619209400073394    steps: 325    lr: 4e-05     evaluation reward: 3.72\n","episode: 1316   score: 2.0   memory length: 270966   epsilon: 0.6614853400073488    steps: 220    lr: 4e-05     evaluation reward: 3.71\n","episode: 1317   score: 1.0   memory length: 271117   epsilon: 0.6611863600073553    steps: 151    lr: 4e-05     evaluation reward: 3.67\n","episode: 1318   score: 5.0   memory length: 271423   epsilon: 0.6605804800073685    steps: 306    lr: 4e-05     evaluation reward: 3.72\n","episode: 1319   score: 10.0   memory length: 271937   epsilon: 0.6595627600073906    steps: 514    lr: 4e-05     evaluation reward: 3.79\n","episode: 1320   score: 3.0   memory length: 272183   epsilon: 0.6590756800074011    steps: 246    lr: 4e-05     evaluation reward: 3.73\n","episode: 1321   score: 5.0   memory length: 272511   epsilon: 0.6584262400074152    steps: 328    lr: 4e-05     evaluation reward: 3.74\n","episode: 1322   score: 3.0   memory length: 272758   epsilon: 0.6579371800074258    steps: 247    lr: 4e-05     evaluation reward: 3.74\n","episode: 1323   score: 6.0   memory length: 273114   epsilon: 0.6572323000074412    steps: 356    lr: 4e-05     evaluation reward: 3.73\n","episode: 1324   score: 7.0   memory length: 273482   epsilon: 0.656503660007457    steps: 368    lr: 4e-05     evaluation reward: 3.77\n","episode: 1325   score: 1.0   memory length: 273632   epsilon: 0.6562066600074634    steps: 150    lr: 4e-05     evaluation reward: 3.75\n","episode: 1326   score: 3.0   memory length: 273878   epsilon: 0.655719580007474    steps: 246    lr: 4e-05     evaluation reward: 3.74\n","episode: 1327   score: 4.0   memory length: 274169   epsilon: 0.6551434000074865    steps: 291    lr: 4e-05     evaluation reward: 3.78\n","episode: 1328   score: 3.0   memory length: 274413   epsilon: 0.654660280007497    steps: 244    lr: 4e-05     evaluation reward: 3.75\n","episode: 1329   score: 2.0   memory length: 274613   epsilon: 0.6542642800075056    steps: 200    lr: 4e-05     evaluation reward: 3.72\n","episode: 1330   score: 5.0   memory length: 274903   epsilon: 0.653690080007518    steps: 290    lr: 4e-05     evaluation reward: 3.72\n","episode: 1331   score: 1.0   memory length: 275073   epsilon: 0.6533534800075254    steps: 170    lr: 4e-05     evaluation reward: 3.71\n","episode: 1332   score: 4.0   memory length: 275350   epsilon: 0.6528050200075373    steps: 277    lr: 4e-05     evaluation reward: 3.73\n","episode: 1333   score: 4.0   memory length: 275610   epsilon: 0.6522902200075484    steps: 260    lr: 4e-05     evaluation reward: 3.75\n","episode: 1334   score: 1.0   memory length: 275760   epsilon: 0.6519932200075549    steps: 150    lr: 4e-05     evaluation reward: 3.74\n","episode: 1335   score: 6.0   memory length: 276123   epsilon: 0.6512744800075705    steps: 363    lr: 4e-05     evaluation reward: 3.76\n","episode: 1336   score: 4.0   memory length: 276415   epsilon: 0.650696320007583    steps: 292    lr: 4e-05     evaluation reward: 3.78\n","episode: 1337   score: 3.0   memory length: 276661   epsilon: 0.6502092400075936    steps: 246    lr: 4e-05     evaluation reward: 3.77\n","episode: 1338   score: 2.0   memory length: 276859   epsilon: 0.6498172000076021    steps: 198    lr: 4e-05     evaluation reward: 3.76\n","episode: 1339   score: 4.0   memory length: 277136   epsilon: 0.649268740007614    steps: 277    lr: 4e-05     evaluation reward: 3.76\n","episode: 1340   score: 4.0   memory length: 277431   epsilon: 0.6486846400076267    steps: 295    lr: 4e-05     evaluation reward: 3.74\n","episode: 1341   score: 1.0   memory length: 277582   epsilon: 0.6483856600076332    steps: 151    lr: 4e-05     evaluation reward: 3.72\n","episode: 1342   score: 4.0   memory length: 277857   epsilon: 0.647841160007645    steps: 275    lr: 4e-05     evaluation reward: 3.73\n","episode: 1343   score: 7.0   memory length: 278224   epsilon: 0.6471145000076608    steps: 367    lr: 4e-05     evaluation reward: 3.78\n","episode: 1344   score: 3.0   memory length: 278455   epsilon: 0.6466571200076707    steps: 231    lr: 4e-05     evaluation reward: 3.79\n","episode: 1345   score: 5.0   memory length: 278761   epsilon: 0.6460512400076839    steps: 306    lr: 4e-05     evaluation reward: 3.83\n","episode: 1346   score: 5.0   memory length: 279047   epsilon: 0.6454849600076962    steps: 286    lr: 4e-05     evaluation reward: 3.85\n","episode: 1347   score: 6.0   memory length: 279402   epsilon: 0.6447820600077114    steps: 355    lr: 4e-05     evaluation reward: 3.87\n","episode: 1348   score: 2.0   memory length: 279600   epsilon: 0.6443900200077199    steps: 198    lr: 4e-05     evaluation reward: 3.89\n","episode: 1349   score: 5.0   memory length: 279868   epsilon: 0.6438593800077315    steps: 268    lr: 4e-05     evaluation reward: 3.89\n","episode: 1350   score: 2.0   memory length: 280050   epsilon: 0.6434990200077393    steps: 182    lr: 4e-05     evaluation reward: 3.89\n","episode: 1351   score: 1.0   memory length: 280201   epsilon: 0.6432000400077458    steps: 151    lr: 4e-05     evaluation reward: 3.85\n","episode: 1352   score: 3.0   memory length: 280447   epsilon: 0.6427129600077564    steps: 246    lr: 4e-05     evaluation reward: 3.85\n","episode: 1353   score: 5.0   memory length: 280792   epsilon: 0.6420298600077712    steps: 345    lr: 4e-05     evaluation reward: 3.85\n","episode: 1354   score: 6.0   memory length: 281148   epsilon: 0.6413249800077865    steps: 356    lr: 4e-05     evaluation reward: 3.87\n","episode: 1355   score: 8.0   memory length: 281595   epsilon: 0.6404399200078057    steps: 447    lr: 4e-05     evaluation reward: 3.88\n","episode: 1356   score: 2.0   memory length: 281777   epsilon: 0.6400795600078135    steps: 182    lr: 4e-05     evaluation reward: 3.84\n","episode: 1357   score: 3.0   memory length: 282026   epsilon: 0.6395865400078242    steps: 249    lr: 4e-05     evaluation reward: 3.82\n","episode: 1358   score: 5.0   memory length: 282352   epsilon: 0.6389410600078382    steps: 326    lr: 4e-05     evaluation reward: 3.86\n","episode: 1359   score: 4.0   memory length: 282628   epsilon: 0.6383945800078501    steps: 276    lr: 4e-05     evaluation reward: 3.85\n","episode: 1360   score: 6.0   memory length: 282982   epsilon: 0.6376936600078653    steps: 354    lr: 4e-05     evaluation reward: 3.9\n","episode: 1361   score: 3.0   memory length: 283233   epsilon: 0.6371966800078761    steps: 251    lr: 4e-05     evaluation reward: 3.91\n","episode: 1362   score: 9.0   memory length: 283739   epsilon: 0.6361948000078979    steps: 506    lr: 4e-05     evaluation reward: 3.98\n","episode: 1363   score: 3.0   memory length: 283965   epsilon: 0.6357473200079076    steps: 226    lr: 4e-05     evaluation reward: 3.98\n","episode: 1364   score: 5.0   memory length: 284309   epsilon: 0.6350662000079224    steps: 344    lr: 4e-05     evaluation reward: 4.01\n","episode: 1365   score: 4.0   memory length: 284605   epsilon: 0.6344801200079351    steps: 296    lr: 4e-05     evaluation reward: 4.03\n","episode: 1366   score: 8.0   memory length: 285052   epsilon: 0.6335950600079543    steps: 447    lr: 4e-05     evaluation reward: 4.08\n","episode: 1367   score: 3.0   memory length: 285298   epsilon: 0.6331079800079649    steps: 246    lr: 4e-05     evaluation reward: 4.04\n","episode: 1368   score: 4.0   memory length: 285558   epsilon: 0.632593180007976    steps: 260    lr: 4e-05     evaluation reward: 4.01\n","episode: 1369   score: 3.0   memory length: 285787   epsilon: 0.6321397600079859    steps: 229    lr: 4e-05     evaluation reward: 4.01\n","episode: 1370   score: 5.0   memory length: 286129   epsilon: 0.6314626000080006    steps: 342    lr: 4e-05     evaluation reward: 4.01\n","episode: 1371   score: 3.0   memory length: 286376   epsilon: 0.6309735400080112    steps: 247    lr: 4e-05     evaluation reward: 4.02\n","episode: 1372   score: 10.0   memory length: 286911   epsilon: 0.6299142400080342    steps: 535    lr: 4e-05     evaluation reward: 4.09\n","episode: 1373   score: 4.0   memory length: 287172   epsilon: 0.6293974600080454    steps: 261    lr: 4e-05     evaluation reward: 4.1\n","episode: 1374   score: 1.0   memory length: 287343   epsilon: 0.6290588800080528    steps: 171    lr: 4e-05     evaluation reward: 4.08\n","episode: 1375   score: 4.0   memory length: 287638   epsilon: 0.6284747800080654    steps: 295    lr: 4e-05     evaluation reward: 4.11\n","episode: 1376   score: 3.0   memory length: 287867   epsilon: 0.6280213600080753    steps: 229    lr: 4e-05     evaluation reward: 4.13\n","episode: 1377   score: 5.0   memory length: 288155   epsilon: 0.6274511200080877    steps: 288    lr: 4e-05     evaluation reward: 4.15\n","episode: 1378   score: 6.0   memory length: 288492   epsilon: 0.6267838600081022    steps: 337    lr: 4e-05     evaluation reward: 4.19\n","episode: 1379   score: 3.0   memory length: 288717   epsilon: 0.6263383600081118    steps: 225    lr: 4e-05     evaluation reward: 4.19\n","episode: 1380   score: 3.0   memory length: 288928   epsilon: 0.6259205800081209    steps: 211    lr: 4e-05     evaluation reward: 4.16\n","episode: 1381   score: 3.0   memory length: 289140   epsilon: 0.62550082000813    steps: 212    lr: 4e-05     evaluation reward: 4.16\n","episode: 1382   score: 3.0   memory length: 289353   epsilon: 0.6250790800081392    steps: 213    lr: 4e-05     evaluation reward: 4.14\n","episode: 1383   score: 5.0   memory length: 289657   epsilon: 0.6244771600081522    steps: 304    lr: 4e-05     evaluation reward: 4.14\n","episode: 1384   score: 4.0   memory length: 289933   epsilon: 0.6239306800081641    steps: 276    lr: 4e-05     evaluation reward: 4.14\n","episode: 1385   score: 3.0   memory length: 290198   epsilon: 0.6234059800081755    steps: 265    lr: 4e-05     evaluation reward: 4.13\n","episode: 1386   score: 3.0   memory length: 290444   epsilon: 0.6229189000081861    steps: 246    lr: 4e-05     evaluation reward: 4.11\n","episode: 1387   score: 2.0   memory length: 290642   epsilon: 0.6225268600081946    steps: 198    lr: 4e-05     evaluation reward: 4.12\n","episode: 1388   score: 4.0   memory length: 290904   epsilon: 0.6220081000082058    steps: 262    lr: 4e-05     evaluation reward: 4.1\n","episode: 1389   score: 5.0   memory length: 291248   epsilon: 0.6213269800082206    steps: 344    lr: 4e-05     evaluation reward: 4.13\n","episode: 1390   score: 5.0   memory length: 291571   epsilon: 0.6206874400082345    steps: 323    lr: 4e-05     evaluation reward: 4.16\n","episode: 1391   score: 4.0   memory length: 291846   epsilon: 0.6201429400082463    steps: 275    lr: 4e-05     evaluation reward: 4.16\n","episode: 1392   score: 8.0   memory length: 292285   epsilon: 0.6192737200082652    steps: 439    lr: 4e-05     evaluation reward: 4.22\n","episode: 1393   score: 5.0   memory length: 292594   epsilon: 0.6186619000082785    steps: 309    lr: 4e-05     evaluation reward: 4.17\n","episode: 1394   score: 4.0   memory length: 292849   epsilon: 0.6181570000082894    steps: 255    lr: 4e-05     evaluation reward: 4.12\n","episode: 1395   score: 6.0   memory length: 293218   epsilon: 0.6174263800083053    steps: 369    lr: 4e-05     evaluation reward: 4.15\n","episode: 1396   score: 3.0   memory length: 293463   epsilon: 0.6169412800083158    steps: 245    lr: 4e-05     evaluation reward: 4.14\n","episode: 1397   score: 7.0   memory length: 293834   epsilon: 0.6162067000083318    steps: 371    lr: 4e-05     evaluation reward: 4.17\n","episode: 1398   score: 4.0   memory length: 294131   epsilon: 0.6156186400083445    steps: 297    lr: 4e-05     evaluation reward: 4.18\n","episode: 1399   score: 5.0   memory length: 294472   epsilon: 0.6149434600083592    steps: 341    lr: 4e-05     evaluation reward: 4.22\n","episode: 1400   score: 4.0   memory length: 294745   epsilon: 0.6144029200083709    steps: 273    lr: 4e-05     evaluation reward: 4.23\n","episode: 1401   score: 6.0   memory length: 295103   epsilon: 0.6136940800083863    steps: 358    lr: 4e-05     evaluation reward: 4.23\n","episode: 1402   score: 0.0   memory length: 295226   epsilon: 0.6134505400083916    steps: 123    lr: 4e-05     evaluation reward: 4.19\n","episode: 1403   score: 4.0   memory length: 295521   epsilon: 0.6128664400084043    steps: 295    lr: 4e-05     evaluation reward: 4.21\n","episode: 1404   score: 6.0   memory length: 295880   epsilon: 0.6121556200084197    steps: 359    lr: 4e-05     evaluation reward: 4.2\n","episode: 1405   score: 4.0   memory length: 296155   epsilon: 0.6116111200084315    steps: 275    lr: 4e-05     evaluation reward: 4.2\n","episode: 1406   score: 0.0   memory length: 296278   epsilon: 0.6113675800084368    steps: 123    lr: 4e-05     evaluation reward: 4.17\n","episode: 1407   score: 7.0   memory length: 296681   epsilon: 0.6105696400084542    steps: 403    lr: 4e-05     evaluation reward: 4.2\n","episode: 1408   score: 3.0   memory length: 296910   epsilon: 0.610116220008464    steps: 229    lr: 4e-05     evaluation reward: 4.18\n","episode: 1409   score: 8.0   memory length: 297319   epsilon: 0.6093064000084816    steps: 409    lr: 4e-05     evaluation reward: 4.16\n","episode: 1410   score: 4.0   memory length: 297577   epsilon: 0.6087955600084927    steps: 258    lr: 4e-05     evaluation reward: 4.14\n","episode: 1411   score: 10.0   memory length: 298083   epsilon: 0.6077936800085144    steps: 506    lr: 4e-05     evaluation reward: 4.2\n","episode: 1412   score: 3.0   memory length: 298327   epsilon: 0.6073105600085249    steps: 244    lr: 4e-05     evaluation reward: 4.18\n","episode: 1413   score: 6.0   memory length: 298689   epsilon: 0.6065938000085405    steps: 362    lr: 4e-05     evaluation reward: 4.23\n","episode: 1414   score: 3.0   memory length: 298918   epsilon: 0.6061403800085503    steps: 229    lr: 4e-05     evaluation reward: 4.21\n","episode: 1415   score: 3.0   memory length: 299130   epsilon: 0.6057206200085594    steps: 212    lr: 4e-05     evaluation reward: 4.19\n","episode: 1416   score: 7.0   memory length: 299553   epsilon: 0.6048830800085776    steps: 423    lr: 4e-05     evaluation reward: 4.24\n","episode: 1417   score: 5.0   memory length: 299862   epsilon: 0.6042712600085909    steps: 309    lr: 4e-05     evaluation reward: 4.28\n","episode: 1418   score: 6.0   memory length: 300239   epsilon: 0.6035248000086071    steps: 377    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n","episode: 1419   score: 6.0   memory length: 300639   epsilon: 0.6027328000086243    steps: 400    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n","episode: 1420   score: 4.0   memory length: 300916   epsilon: 0.6021843400086362    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n","episode: 1421   score: 13.0   memory length: 301397   epsilon: 0.6012319600086569    steps: 481    lr: 1.6000000000000003e-05     evaluation reward: 4.34\n","episode: 1422   score: 3.0   memory length: 301625   epsilon: 0.6007805200086667    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.34\n","episode: 1423   score: 5.0   memory length: 301968   epsilon: 0.6001013800086814    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 4.33\n","episode: 1424   score: 4.0   memory length: 302227   epsilon: 0.5995885600086925    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n","episode: 1425   score: 6.0   memory length: 302583   epsilon: 0.5988836800087078    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 4.35\n","episode: 1426   score: 4.0   memory length: 302862   epsilon: 0.5983312600087198    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 4.36\n","episode: 1427   score: 2.0   memory length: 303062   epsilon: 0.5979352600087284    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.34\n","episode: 1428   score: 7.0   memory length: 303488   epsilon: 0.5970917800087467    steps: 426    lr: 1.6000000000000003e-05     evaluation reward: 4.38\n","episode: 1429   score: 5.0   memory length: 303812   epsilon: 0.5964502600087607    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.41\n","episode: 1430   score: 5.0   memory length: 304155   epsilon: 0.5957711200087754    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 4.41\n","episode: 1431   score: 3.0   memory length: 304403   epsilon: 0.5952800800087861    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 4.43\n","episode: 1432   score: 6.0   memory length: 304743   epsilon: 0.5946068800088007    steps: 340    lr: 1.6000000000000003e-05     evaluation reward: 4.45\n","episode: 1433   score: 3.0   memory length: 304993   epsilon: 0.5941118800088114    steps: 250    lr: 1.6000000000000003e-05     evaluation reward: 4.44\n","episode: 1434   score: 11.0   memory length: 305416   epsilon: 0.5932743400088296    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 4.54\n","episode: 1435   score: 9.0   memory length: 305893   epsilon: 0.5923298800088501    steps: 477    lr: 1.6000000000000003e-05     evaluation reward: 4.57\n","episode: 1436   score: 4.0   memory length: 306152   epsilon: 0.5918170600088613    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.57\n","episode: 1437   score: 5.0   memory length: 306460   epsilon: 0.5912072200088745    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.59\n","episode: 1438   score: 5.0   memory length: 306784   epsilon: 0.5905657000088884    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.62\n","episode: 1439   score: 5.0   memory length: 307055   epsilon: 0.5900291200089001    steps: 271    lr: 1.6000000000000003e-05     evaluation reward: 4.63\n","episode: 1440   score: 3.0   memory length: 307281   epsilon: 0.5895816400089098    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.62\n","episode: 1441   score: 1.0   memory length: 307431   epsilon: 0.5892846400089162    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 4.62\n","episode: 1442   score: 8.0   memory length: 307792   epsilon: 0.5885698600089317    steps: 361    lr: 1.6000000000000003e-05     evaluation reward: 4.66\n","episode: 1443   score: 4.0   memory length: 308070   epsilon: 0.5880194200089437    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.63\n","episode: 1444   score: 4.0   memory length: 308348   epsilon: 0.5874689800089556    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.64\n","episode: 1445   score: 7.0   memory length: 308750   epsilon: 0.5866730200089729    steps: 402    lr: 1.6000000000000003e-05     evaluation reward: 4.66\n","episode: 1446   score: 3.0   memory length: 308996   epsilon: 0.5861859400089835    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 4.64\n","episode: 1447   score: 6.0   memory length: 309368   epsilon: 0.5854493800089995    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 4.64\n","episode: 1448   score: 0.0   memory length: 309491   epsilon: 0.5852058400090048    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 4.62\n","episode: 1449   score: 4.0   memory length: 309770   epsilon: 0.5846534200090168    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 4.61\n","episode: 1450   score: 8.0   memory length: 310229   epsilon: 0.5837446000090365    steps: 459    lr: 1.6000000000000003e-05     evaluation reward: 4.67\n","episode: 1451   score: 3.0   memory length: 310477   epsilon: 0.5832535600090472    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 4.69\n","episode: 1452   score: 7.0   memory length: 310845   epsilon: 0.582524920009063    steps: 368    lr: 1.6000000000000003e-05     evaluation reward: 4.73\n","episode: 1453   score: 7.0   memory length: 311271   epsilon: 0.5816814400090813    steps: 426    lr: 1.6000000000000003e-05     evaluation reward: 4.75\n","episode: 1454   score: 4.0   memory length: 311526   epsilon: 0.5811765400090922    steps: 255    lr: 1.6000000000000003e-05     evaluation reward: 4.73\n","episode: 1455   score: 7.0   memory length: 311875   epsilon: 0.5804855200091072    steps: 349    lr: 1.6000000000000003e-05     evaluation reward: 4.72\n","episode: 1456   score: 9.0   memory length: 312355   epsilon: 0.5795351200091279    steps: 480    lr: 1.6000000000000003e-05     evaluation reward: 4.79\n","episode: 1457   score: 7.0   memory length: 312731   epsilon: 0.578790640009144    steps: 376    lr: 1.6000000000000003e-05     evaluation reward: 4.83\n","episode: 1458   score: 5.0   memory length: 313052   epsilon: 0.5781550600091578    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 4.83\n","episode: 1459   score: 6.0   memory length: 313416   epsilon: 0.5774343400091735    steps: 364    lr: 1.6000000000000003e-05     evaluation reward: 4.85\n","episode: 1460   score: 10.0   memory length: 313788   epsilon: 0.5766977800091895    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 4.89\n","episode: 1461   score: 7.0   memory length: 314177   epsilon: 0.5759275600092062    steps: 389    lr: 1.6000000000000003e-05     evaluation reward: 4.93\n","episode: 1462   score: 7.0   memory length: 314602   epsilon: 0.5750860600092245    steps: 425    lr: 1.6000000000000003e-05     evaluation reward: 4.91\n","episode: 1463   score: 10.0   memory length: 315064   epsilon: 0.5741713000092443    steps: 462    lr: 1.6000000000000003e-05     evaluation reward: 4.98\n","episode: 1464   score: 4.0   memory length: 315340   epsilon: 0.5736248200092562    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.97\n","episode: 1465   score: 4.0   memory length: 315618   epsilon: 0.5730743800092681    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.97\n","episode: 1466   score: 10.0   memory length: 316088   epsilon: 0.5721437800092883    steps: 470    lr: 1.6000000000000003e-05     evaluation reward: 4.99\n","episode: 1467   score: 6.0   memory length: 316488   epsilon: 0.5713517800093055    steps: 400    lr: 1.6000000000000003e-05     evaluation reward: 5.02\n","episode: 1468   score: 3.0   memory length: 316734   epsilon: 0.5708647000093161    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 5.01\n","episode: 1469   score: 7.0   memory length: 317157   epsilon: 0.5700271600093343    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 5.05\n","episode: 1470   score: 3.0   memory length: 317386   epsilon: 0.5695737400093441    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 5.03\n","episode: 1471   score: 7.0   memory length: 317775   epsilon: 0.5688035200093609    steps: 389    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n","episode: 1472   score: 2.0   memory length: 317975   epsilon: 0.5684075200093694    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.99\n","episode: 1473   score: 4.0   memory length: 318252   epsilon: 0.5678590600093814    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.99\n","episode: 1474   score: 5.0   memory length: 318565   epsilon: 0.5672393200093948    steps: 313    lr: 1.6000000000000003e-05     evaluation reward: 5.03\n","episode: 1475   score: 9.0   memory length: 319026   epsilon: 0.5663265400094146    steps: 461    lr: 1.6000000000000003e-05     evaluation reward: 5.08\n","episode: 1476   score: 3.0   memory length: 319256   epsilon: 0.5658711400094245    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 5.08\n","episode: 1477   score: 7.0   memory length: 319664   epsilon: 0.565063300009442    steps: 408    lr: 1.6000000000000003e-05     evaluation reward: 5.1\n","episode: 1478   score: 4.0   memory length: 319943   epsilon: 0.564510880009454    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 5.08\n","episode: 1479   score: 7.0   memory length: 320335   epsilon: 0.5637347200094709    steps: 392    lr: 1.6000000000000003e-05     evaluation reward: 5.12\n","episode: 1480   score: 2.0   memory length: 320533   epsilon: 0.5633426800094794    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 5.11\n","episode: 1481   score: 6.0   memory length: 320890   epsilon: 0.5626358200094947    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 5.14\n","episode: 1482   score: 7.0   memory length: 321292   epsilon: 0.561839860009512    steps: 402    lr: 1.6000000000000003e-05     evaluation reward: 5.18\n","episode: 1483   score: 8.0   memory length: 321742   epsilon: 0.5609488600095314    steps: 450    lr: 1.6000000000000003e-05     evaluation reward: 5.21\n","episode: 1484   score: 9.0   memory length: 322219   epsilon: 0.5600044000095519    steps: 477    lr: 1.6000000000000003e-05     evaluation reward: 5.26\n","episode: 1485   score: 4.0   memory length: 322478   epsilon: 0.559491580009563    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 5.27\n","episode: 1486   score: 7.0   memory length: 322865   epsilon: 0.5587253200095796    steps: 387    lr: 1.6000000000000003e-05     evaluation reward: 5.31\n","episode: 1487   score: 7.0   memory length: 323311   epsilon: 0.5578422400095988    steps: 446    lr: 1.6000000000000003e-05     evaluation reward: 5.36\n","episode: 1488   score: 4.0   memory length: 323612   epsilon: 0.5572462600096117    steps: 301    lr: 1.6000000000000003e-05     evaluation reward: 5.36\n","episode: 1489   score: 7.0   memory length: 323995   epsilon: 0.5564879200096282    steps: 383    lr: 1.6000000000000003e-05     evaluation reward: 5.38\n","episode: 1490   score: 6.0   memory length: 324367   epsilon: 0.5557513600096442    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 5.39\n","episode: 1491   score: 6.0   memory length: 324723   epsilon: 0.5550464800096595    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 5.41\n","episode: 1492   score: 5.0   memory length: 325054   epsilon: 0.5543911000096737    steps: 331    lr: 1.6000000000000003e-05     evaluation reward: 5.38\n","episode: 1493   score: 6.0   memory length: 325376   epsilon: 0.5537535400096876    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 5.39\n","episode: 1494   score: 3.0   memory length: 325606   epsilon: 0.5532981400096975    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 5.38\n","episode: 1495   score: 7.0   memory length: 325957   epsilon: 0.5526031600097125    steps: 351    lr: 1.6000000000000003e-05     evaluation reward: 5.39\n","episode: 1496   score: 5.0   memory length: 326264   epsilon: 0.5519953000097257    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 5.41\n","episode: 1497   score: 8.0   memory length: 326704   epsilon: 0.5511241000097447    steps: 440    lr: 1.6000000000000003e-05     evaluation reward: 5.42\n","episode: 1498   score: 7.0   memory length: 327073   epsilon: 0.5503934800097605    steps: 369    lr: 1.6000000000000003e-05     evaluation reward: 5.45\n","episode: 1499   score: 2.0   memory length: 327271   epsilon: 0.550001440009769    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 5.42\n","episode: 1500   score: 9.0   memory length: 327685   epsilon: 0.5491817200097868    steps: 414    lr: 1.6000000000000003e-05     evaluation reward: 5.47\n","episode: 1501   score: 5.0   memory length: 328025   epsilon: 0.5485085200098014    steps: 340    lr: 1.6000000000000003e-05     evaluation reward: 5.46\n","episode: 1502   score: 5.0   memory length: 328372   epsilon: 0.5478214600098164    steps: 347    lr: 1.6000000000000003e-05     evaluation reward: 5.51\n","episode: 1503   score: 3.0   memory length: 328599   epsilon: 0.5473720000098261    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 5.5\n","episode: 1504   score: 1.0   memory length: 328771   epsilon: 0.5470314400098335    steps: 172    lr: 1.6000000000000003e-05     evaluation reward: 5.45\n","episode: 1505   score: 9.0   memory length: 329116   epsilon: 0.5463483400098483    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 5.5\n","episode: 1506   score: 11.0   memory length: 329541   epsilon: 0.5455068400098666    steps: 425    lr: 1.6000000000000003e-05     evaluation reward: 5.61\n","episode: 1507   score: 13.0   memory length: 330026   epsilon: 0.5445465400098874    steps: 485    lr: 1.6000000000000003e-05     evaluation reward: 5.67\n","episode: 1508   score: 6.0   memory length: 330400   epsilon: 0.5438060200099035    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 5.7\n","episode: 1509   score: 5.0   memory length: 330709   epsilon: 0.5431942000099168    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 5.67\n","episode: 1510   score: 8.0   memory length: 331140   epsilon: 0.5423408200099353    steps: 431    lr: 1.6000000000000003e-05     evaluation reward: 5.71\n","episode: 1511   score: 6.0   memory length: 331493   epsilon: 0.5416418800099505    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 5.67\n","episode: 1512   score: 2.0   memory length: 331674   epsilon: 0.5412835000099583    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 5.66\n","episode: 1513   score: 5.0   memory length: 332001   epsilon: 0.5406360400099723    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 5.65\n","episode: 1514   score: 7.0   memory length: 332382   epsilon: 0.5398816600099887    steps: 381    lr: 1.6000000000000003e-05     evaluation reward: 5.69\n","episode: 1515   score: 9.0   memory length: 332875   epsilon: 0.5389055200100099    steps: 493    lr: 1.6000000000000003e-05     evaluation reward: 5.75\n","episode: 1516   score: 5.0   memory length: 333217   epsilon: 0.5382283600100246    steps: 342    lr: 1.6000000000000003e-05     evaluation reward: 5.73\n","episode: 1517   score: 2.0   memory length: 333415   epsilon: 0.5378363200100331    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 5.7\n","episode: 1518   score: 8.0   memory length: 333853   epsilon: 0.536969080010052    steps: 438    lr: 1.6000000000000003e-05     evaluation reward: 5.72\n","episode: 1519   score: 7.0   memory length: 334244   epsilon: 0.5361949000100688    steps: 391    lr: 1.6000000000000003e-05     evaluation reward: 5.73\n","episode: 1520   score: 7.0   memory length: 334612   epsilon: 0.5354662600100846    steps: 368    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n","episode: 1521   score: 6.0   memory length: 334951   epsilon: 0.5347950400100991    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 5.69\n","episode: 1522   score: 4.0   memory length: 335208   epsilon: 0.5342861800101102    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 5.7\n","episode: 1523   score: 4.0   memory length: 335505   epsilon: 0.533698120010123    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 5.69\n","episode: 1524   score: 1.0   memory length: 335656   epsilon: 0.5333991400101294    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 5.66\n","episode: 1525   score: 9.0   memory length: 336120   epsilon: 0.5324804200101494    steps: 464    lr: 1.6000000000000003e-05     evaluation reward: 5.69\n","episode: 1526   score: 2.0   memory length: 336338   epsilon: 0.5320487800101588    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 5.67\n","episode: 1527   score: 2.0   memory length: 336556   epsilon: 0.5316171400101681    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 5.67\n","episode: 1528   score: 5.0   memory length: 336829   epsilon: 0.5310766000101799    steps: 273    lr: 1.6000000000000003e-05     evaluation reward: 5.65\n","episode: 1529   score: 5.0   memory length: 337151   epsilon: 0.5304390400101937    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 5.65\n","episode: 1530   score: 4.0   memory length: 337448   epsilon: 0.5298509800102065    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 5.64\n","episode: 1531   score: 4.0   memory length: 337723   epsilon: 0.5293064800102183    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 5.65\n","episode: 1532   score: 6.0   memory length: 338078   epsilon: 0.5286035800102336    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 5.65\n","episode: 1533   score: 4.0   memory length: 338353   epsilon: 0.5280590800102454    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 5.66\n","episode: 1534   score: 8.0   memory length: 338829   epsilon: 0.5271166000102658    steps: 476    lr: 1.6000000000000003e-05     evaluation reward: 5.63\n","episode: 1535   score: 2.0   memory length: 339010   epsilon: 0.5267582200102736    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 5.56\n","episode: 1536   score: 7.0   memory length: 339398   epsilon: 0.5259899800102903    steps: 388    lr: 1.6000000000000003e-05     evaluation reward: 5.59\n","episode: 1537   score: 5.0   memory length: 339710   epsilon: 0.5253722200103037    steps: 312    lr: 1.6000000000000003e-05     evaluation reward: 5.59\n","episode: 1538   score: 5.0   memory length: 339998   epsilon: 0.5248019800103161    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 5.59\n","episode: 1539   score: 1.0   memory length: 340149   epsilon: 0.5245030000103226    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 5.55\n","episode: 1540   score: 9.0   memory length: 340607   epsilon: 0.5235961600103423    steps: 458    lr: 1.6000000000000003e-05     evaluation reward: 5.61\n","episode: 1541   score: 1.0   memory length: 340757   epsilon: 0.5232991600103487    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 5.61\n","episode: 1542   score: 4.0   memory length: 341057   epsilon: 0.5227051600103616    steps: 300    lr: 1.6000000000000003e-05     evaluation reward: 5.57\n","episode: 1543   score: 4.0   memory length: 341330   epsilon: 0.5221646200103733    steps: 273    lr: 1.6000000000000003e-05     evaluation reward: 5.57\n","episode: 1544   score: 4.0   memory length: 341569   epsilon: 0.5216914000103836    steps: 239    lr: 1.6000000000000003e-05     evaluation reward: 5.57\n","episode: 1545   score: 10.0   memory length: 342111   epsilon: 0.5206182400104069    steps: 542    lr: 1.6000000000000003e-05     evaluation reward: 5.6\n","episode: 1546   score: 4.0   memory length: 342377   epsilon: 0.5200915600104183    steps: 266    lr: 1.6000000000000003e-05     evaluation reward: 5.61\n","episode: 1547   score: 4.0   memory length: 342678   epsilon: 0.5194955800104313    steps: 301    lr: 1.6000000000000003e-05     evaluation reward: 5.59\n","episode: 1548   score: 5.0   memory length: 343021   epsilon: 0.518816440010446    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 5.64\n","episode: 1549   score: 1.0   memory length: 343172   epsilon: 0.5185174600104525    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 5.61\n","episode: 1550   score: 9.0   memory length: 343620   epsilon: 0.5176304200104718    steps: 448    lr: 1.6000000000000003e-05     evaluation reward: 5.62\n","episode: 1551   score: 7.0   memory length: 344028   epsilon: 0.5168225800104893    steps: 408    lr: 1.6000000000000003e-05     evaluation reward: 5.66\n","episode: 1552   score: 7.0   memory length: 344385   epsilon: 0.5161157200105047    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 5.66\n","episode: 1553   score: 6.0   memory length: 344705   epsilon: 0.5154821200105184    steps: 320    lr: 1.6000000000000003e-05     evaluation reward: 5.65\n","episode: 1554   score: 7.0   memory length: 345088   epsilon: 0.5147237800105349    steps: 383    lr: 1.6000000000000003e-05     evaluation reward: 5.68\n","episode: 1555   score: 4.0   memory length: 345389   epsilon: 0.5141278000105478    steps: 301    lr: 1.6000000000000003e-05     evaluation reward: 5.65\n","episode: 1556   score: 5.0   memory length: 345718   epsilon: 0.513476380010562    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 5.61\n","episode: 1557   score: 6.0   memory length: 346105   epsilon: 0.5127101200105786    steps: 387    lr: 1.6000000000000003e-05     evaluation reward: 5.6\n","episode: 1558   score: 8.0   memory length: 346532   epsilon: 0.5118646600105969    steps: 427    lr: 1.6000000000000003e-05     evaluation reward: 5.63\n","episode: 1559   score: 10.0   memory length: 347053   epsilon: 0.5108330800106193    steps: 521    lr: 1.6000000000000003e-05     evaluation reward: 5.67\n","episode: 1560   score: 7.0   memory length: 347475   epsilon: 0.5099975200106375    steps: 422    lr: 1.6000000000000003e-05     evaluation reward: 5.64\n","episode: 1561   score: 4.0   memory length: 347748   epsilon: 0.5094569800106492    steps: 273    lr: 1.6000000000000003e-05     evaluation reward: 5.61\n","episode: 1562   score: 3.0   memory length: 347992   epsilon: 0.5089738600106597    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 5.57\n","episode: 1563   score: 8.0   memory length: 348405   epsilon: 0.5081561200106774    steps: 413    lr: 1.6000000000000003e-05     evaluation reward: 5.55\n","episode: 1564   score: 1.0   memory length: 348555   epsilon: 0.5078591200106839    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 5.52\n","episode: 1565   score: 7.0   memory length: 348960   epsilon: 0.5070572200107013    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 5.55\n","episode: 1566   score: 3.0   memory length: 349208   epsilon: 0.506566180010712    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 5.48\n","episode: 1567   score: 6.0   memory length: 349565   epsilon: 0.5058593200107273    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 5.48\n","episode: 1568   score: 3.0   memory length: 349778   epsilon: 0.5054375800107365    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 5.48\n","episode: 1569   score: 2.0   memory length: 349959   epsilon: 0.5050792000107442    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 5.43\n","episode: 1570   score: 5.0   memory length: 350267   epsilon: 0.5044693600107575    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 5.45\n","episode: 1571   score: 5.0   memory length: 350592   epsilon: 0.5038258600107715    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 5.43\n","episode: 1572   score: 3.0   memory length: 350805   epsilon: 0.5034041200107806    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 5.44\n","episode: 1573   score: 3.0   memory length: 351056   epsilon: 0.5029071400107914    steps: 251    lr: 1.6000000000000003e-05     evaluation reward: 5.43\n","episode: 1574   score: 3.0   memory length: 351302   epsilon: 0.502420060010802    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 5.41\n","episode: 1575   score: 8.0   memory length: 351724   epsilon: 0.5015845000108201    steps: 422    lr: 1.6000000000000003e-05     evaluation reward: 5.4\n","episode: 1576   score: 6.0   memory length: 352099   epsilon: 0.5008420000108362    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 5.43\n","episode: 1577   score: 6.0   memory length: 352474   epsilon: 0.5000995000108523    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 5.42\n","episode: 1578   score: 1.0   memory length: 352624   epsilon: 0.49980250001085325    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 5.39\n","episode: 1579   score: 2.0   memory length: 352824   epsilon: 0.49940650001085074    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 5.34\n","episode: 1580   score: 6.0   memory length: 353155   epsilon: 0.4987511200108466    steps: 331    lr: 1.6000000000000003e-05     evaluation reward: 5.38\n","episode: 1581   score: 13.0   memory length: 353641   epsilon: 0.4977888400108405    steps: 486    lr: 1.6000000000000003e-05     evaluation reward: 5.45\n","episode: 1582   score: 5.0   memory length: 353936   epsilon: 0.4972047400108368    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 5.43\n","episode: 1583   score: 3.0   memory length: 354182   epsilon: 0.49671766001083373    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 5.38\n","episode: 1584   score: 4.0   memory length: 354461   epsilon: 0.49616524001083023    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 5.33\n","episode: 1585   score: 9.0   memory length: 354938   epsilon: 0.49522078001082426    steps: 477    lr: 1.6000000000000003e-05     evaluation reward: 5.38\n","episode: 1586   score: 3.0   memory length: 355168   epsilon: 0.4947653800108214    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 5.34\n","episode: 1587   score: 6.0   memory length: 355524   epsilon: 0.4940605000108169    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 5.33\n","episode: 1588   score: 6.0   memory length: 355846   epsilon: 0.4934229400108129    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 5.35\n","episode: 1589   score: 5.0   memory length: 356137   epsilon: 0.49284676001080924    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 5.33\n","episode: 1590   score: 5.0   memory length: 356463   epsilon: 0.49220128001080515    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 5.32\n","episode: 1591   score: 5.0   memory length: 356790   epsilon: 0.49155382001080106    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 5.31\n","episode: 1592   score: 4.0   memory length: 357049   epsilon: 0.4910410000107978    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 5.3\n","episode: 1593   score: 2.0   memory length: 357267   epsilon: 0.4906093600107951    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 5.26\n","episode: 1594   score: 6.0   memory length: 357639   epsilon: 0.4898728000107904    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 5.29\n","episode: 1595   score: 5.0   memory length: 357948   epsilon: 0.48926098001078655    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 5.27\n","episode: 1596   score: 2.0   memory length: 358128   epsilon: 0.4889045800107843    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 5.24\n","episode: 1597   score: 3.0   memory length: 358357   epsilon: 0.4884511600107814    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 5.19\n","episode: 1598   score: 2.0   memory length: 358554   epsilon: 0.48806110001077896    steps: 197    lr: 1.6000000000000003e-05     evaluation reward: 5.14\n","episode: 1599   score: 4.0   memory length: 358847   epsilon: 0.4874809600107753    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 5.16\n","episode: 1600   score: 9.0   memory length: 359223   epsilon: 0.4867364800107706    steps: 376    lr: 1.6000000000000003e-05     evaluation reward: 5.16\n","episode: 1601   score: 3.0   memory length: 359452   epsilon: 0.4862830600107677    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 5.14\n","episode: 1602   score: 4.0   memory length: 359747   epsilon: 0.485698960010764    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 5.13\n","episode: 1603   score: 7.0   memory length: 360121   epsilon: 0.48495844001075933    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 5.17\n","episode: 1604   score: 6.0   memory length: 360467   epsilon: 0.484273360010755    steps: 346    lr: 1.6000000000000003e-05     evaluation reward: 5.22\n","episode: 1605   score: 11.0   memory length: 360985   epsilon: 0.4832477200107485    steps: 518    lr: 1.6000000000000003e-05     evaluation reward: 5.24\n","episode: 1606   score: 1.0   memory length: 361136   epsilon: 0.4829487400107466    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 5.14\n","episode: 1607   score: 4.0   memory length: 361380   epsilon: 0.48246562001074356    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 5.05\n","episode: 1608   score: 4.0   memory length: 361656   epsilon: 0.4819191400107401    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 5.03\n","episode: 1609   score: 5.0   memory length: 361982   epsilon: 0.481273660010736    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 5.03\n","episode: 1610   score: 4.0   memory length: 362262   epsilon: 0.4807192600107325    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 4.99\n","episode: 1611   score: 7.0   memory length: 362653   epsilon: 0.4799450800107276    steps: 391    lr: 1.6000000000000003e-05     evaluation reward: 5.0\n","episode: 1612   score: 3.0   memory length: 362866   epsilon: 0.47952334001072494    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 5.01\n","episode: 1613   score: 4.0   memory length: 363139   epsilon: 0.4789828000107215    steps: 273    lr: 1.6000000000000003e-05     evaluation reward: 5.0\n","episode: 1614   score: 6.0   memory length: 363496   epsilon: 0.47827594001071705    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 4.99\n","episode: 1615   score: 8.0   memory length: 363945   epsilon: 0.4773869200107114    steps: 449    lr: 1.6000000000000003e-05     evaluation reward: 4.98\n","episode: 1616   score: 2.0   memory length: 364126   epsilon: 0.47702854001070916    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 4.95\n","episode: 1617   score: 3.0   memory length: 364357   epsilon: 0.47657116001070626    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 4.96\n","episode: 1618   score: 4.0   memory length: 364656   epsilon: 0.4759791400107025    steps: 299    lr: 1.6000000000000003e-05     evaluation reward: 4.92\n","episode: 1619   score: 6.0   memory length: 365033   epsilon: 0.4752326800106978    steps: 377    lr: 1.6000000000000003e-05     evaluation reward: 4.91\n","episode: 1620   score: 6.0   memory length: 365367   epsilon: 0.4745713600106936    steps: 334    lr: 1.6000000000000003e-05     evaluation reward: 4.9\n","episode: 1621   score: 6.0   memory length: 365746   epsilon: 0.47382094001068886    steps: 379    lr: 1.6000000000000003e-05     evaluation reward: 4.9\n","episode: 1622   score: 3.0   memory length: 365956   epsilon: 0.47340514001068623    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.89\n","episode: 1623   score: 15.0   memory length: 366545   epsilon: 0.47223892001067885    steps: 589    lr: 1.6000000000000003e-05     evaluation reward: 5.0\n","episode: 1624   score: 5.0   memory length: 366852   epsilon: 0.471631060010675    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 5.04\n","episode: 1625   score: 6.0   memory length: 367229   epsilon: 0.4708846000106703    steps: 377    lr: 1.6000000000000003e-05     evaluation reward: 5.01\n","episode: 1626   score: 2.0   memory length: 367411   epsilon: 0.470524240010668    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 5.01\n","episode: 1627   score: 4.0   memory length: 367709   epsilon: 0.46993420001066427    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 5.03\n","episode: 1628   score: 8.0   memory length: 368103   epsilon: 0.46915408001065934    steps: 394    lr: 1.6000000000000003e-05     evaluation reward: 5.06\n","episode: 1629   score: 2.0   memory length: 368303   epsilon: 0.46875808001065683    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 5.03\n","episode: 1630   score: 6.0   memory length: 368662   epsilon: 0.46804726001065233    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 5.05\n","episode: 1631   score: 6.0   memory length: 369021   epsilon: 0.46733644001064784    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n","episode: 1632   score: 3.0   memory length: 369234   epsilon: 0.46691470001064517    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 5.04\n","episode: 1633   score: 5.0   memory length: 369542   epsilon: 0.4663048600106413    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 5.05\n","episode: 1634   score: 5.0   memory length: 369868   epsilon: 0.4656593800106372    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 5.02\n","episode: 1635   score: 9.0   memory length: 370300   epsilon: 0.4648040200106318    steps: 432    lr: 1.6000000000000003e-05     evaluation reward: 5.09\n","episode: 1636   score: 5.0   memory length: 370576   epsilon: 0.46425754001062836    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n","episode: 1637   score: 3.0   memory length: 370787   epsilon: 0.4638397600106257    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 5.05\n","episode: 1638   score: 10.0   memory length: 371327   epsilon: 0.46277056001061895    steps: 540    lr: 1.6000000000000003e-05     evaluation reward: 5.1\n","episode: 1639   score: 4.0   memory length: 371571   epsilon: 0.4622874400106159    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 5.13\n","episode: 1640   score: 6.0   memory length: 371964   epsilon: 0.46150930001061097    steps: 393    lr: 1.6000000000000003e-05     evaluation reward: 5.1\n","episode: 1641   score: 6.0   memory length: 372284   epsilon: 0.46087570001060696    steps: 320    lr: 1.6000000000000003e-05     evaluation reward: 5.15\n","episode: 1642   score: 5.0   memory length: 372628   epsilon: 0.46019458001060265    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 5.16\n","episode: 1643   score: 5.0   memory length: 372940   epsilon: 0.45957682001059874    steps: 312    lr: 1.6000000000000003e-05     evaluation reward: 5.17\n","episode: 1644   score: 3.0   memory length: 373186   epsilon: 0.45908974001059566    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 5.16\n","episode: 1645   score: 6.0   memory length: 373523   epsilon: 0.45842248001059144    steps: 337    lr: 1.6000000000000003e-05     evaluation reward: 5.12\n","episode: 1646   score: 4.0   memory length: 373819   epsilon: 0.45783640001058773    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 5.12\n","episode: 1647   score: 11.0   memory length: 374423   epsilon: 0.45664048001058016    steps: 604    lr: 1.6000000000000003e-05     evaluation reward: 5.19\n","episode: 1648   score: 2.0   memory length: 374604   epsilon: 0.4562821000105779    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 5.16\n","episode: 1649   score: 7.0   memory length: 374990   epsilon: 0.45551782001057306    steps: 386    lr: 1.6000000000000003e-05     evaluation reward: 5.22\n","episode: 1650   score: 4.0   memory length: 375252   epsilon: 0.4549990600105698    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 5.17\n","episode: 1651   score: 4.0   memory length: 375515   epsilon: 0.4544783200105665    steps: 263    lr: 1.6000000000000003e-05     evaluation reward: 5.14\n","episode: 1652   score: 9.0   memory length: 375946   epsilon: 0.4536249400105611    steps: 431    lr: 1.6000000000000003e-05     evaluation reward: 5.16\n","episode: 1653   score: 6.0   memory length: 376288   epsilon: 0.4529477800105568    steps: 342    lr: 1.6000000000000003e-05     evaluation reward: 5.16\n","episode: 1654   score: 5.0   memory length: 376638   epsilon: 0.4522547800105524    steps: 350    lr: 1.6000000000000003e-05     evaluation reward: 5.14\n","episode: 1655   score: 4.0   memory length: 376912   epsilon: 0.451712260010549    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 5.14\n","episode: 1656   score: 6.0   memory length: 377215   epsilon: 0.4511123200105452    steps: 303    lr: 1.6000000000000003e-05     evaluation reward: 5.15\n","episode: 1657   score: 4.0   memory length: 377490   epsilon: 0.45056782001054174    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 5.13\n","episode: 1658   score: 3.0   memory length: 377722   epsilon: 0.45010846001053884    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 5.08\n","episode: 1659   score: 5.0   memory length: 378047   epsilon: 0.44946496001053476    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 5.03\n","episode: 1660   score: 6.0   memory length: 378407   epsilon: 0.44875216001053025    steps: 360    lr: 1.6000000000000003e-05     evaluation reward: 5.02\n","episode: 1661   score: 4.0   memory length: 378682   epsilon: 0.4482076600105268    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 5.02\n","episode: 1662   score: 8.0   memory length: 379109   epsilon: 0.44736220001052146    steps: 427    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n","episode: 1663   score: 8.0   memory length: 379517   epsilon: 0.44655436001051635    steps: 408    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n","episode: 1664   score: 10.0   memory length: 379976   epsilon: 0.4456455400105106    steps: 459    lr: 1.6000000000000003e-05     evaluation reward: 5.16\n","episode: 1665   score: 3.0   memory length: 380186   epsilon: 0.44522974001050797    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 5.12\n","episode: 1666   score: 8.0   memory length: 380630   epsilon: 0.4443506200105024    steps: 444    lr: 1.6000000000000003e-05     evaluation reward: 5.17\n","episode: 1667   score: 7.0   memory length: 380983   epsilon: 0.443651680010498    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 5.18\n","episode: 1668   score: 8.0   memory length: 381370   epsilon: 0.44288542001049314    steps: 387    lr: 1.6000000000000003e-05     evaluation reward: 5.23\n","episode: 1669   score: 9.0   memory length: 381847   epsilon: 0.44194096001048716    steps: 477    lr: 1.6000000000000003e-05     evaluation reward: 5.3\n","episode: 1670   score: 9.0   memory length: 382324   epsilon: 0.4409965000104812    steps: 477    lr: 1.6000000000000003e-05     evaluation reward: 5.34\n","episode: 1671   score: 5.0   memory length: 382635   epsilon: 0.4403807200104773    steps: 311    lr: 1.6000000000000003e-05     evaluation reward: 5.34\n","episode: 1672   score: 8.0   memory length: 383114   epsilon: 0.4394323000104713    steps: 479    lr: 1.6000000000000003e-05     evaluation reward: 5.39\n","episode: 1673   score: 6.0   memory length: 383469   epsilon: 0.43872940001046684    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 5.42\n","episode: 1674   score: 10.0   memory length: 384015   epsilon: 0.43764832001046    steps: 546    lr: 1.6000000000000003e-05     evaluation reward: 5.49\n","episode: 1675   score: 6.0   memory length: 384340   epsilon: 0.43700482001045593    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 5.47\n","episode: 1676   score: 7.0   memory length: 384725   epsilon: 0.4362425200104511    steps: 385    lr: 1.6000000000000003e-05     evaluation reward: 5.48\n","episode: 1677   score: 6.0   memory length: 385047   epsilon: 0.4356049600104471    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 5.48\n","episode: 1678   score: 3.0   memory length: 385262   epsilon: 0.4351792600104444    steps: 215    lr: 1.6000000000000003e-05     evaluation reward: 5.5\n","episode: 1679   score: 9.0   memory length: 385750   epsilon: 0.43421302001043827    steps: 488    lr: 1.6000000000000003e-05     evaluation reward: 5.57\n","episode: 1680   score: 5.0   memory length: 386059   epsilon: 0.4336012000104344    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 5.56\n","episode: 1681   score: 8.0   memory length: 386550   epsilon: 0.43262902001042824    steps: 491    lr: 1.6000000000000003e-05     evaluation reward: 5.51\n","episode: 1682   score: 9.0   memory length: 386994   epsilon: 0.4317499000104227    steps: 444    lr: 1.6000000000000003e-05     evaluation reward: 5.55\n","episode: 1683   score: 6.0   memory length: 387357   epsilon: 0.43103116001041814    steps: 363    lr: 1.6000000000000003e-05     evaluation reward: 5.58\n","episode: 1684   score: 4.0   memory length: 387655   epsilon: 0.4304411200104144    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 5.58\n","episode: 1685   score: 11.0   memory length: 388151   epsilon: 0.4294590400104082    steps: 496    lr: 1.6000000000000003e-05     evaluation reward: 5.6\n","episode: 1686   score: 9.0   memory length: 388621   epsilon: 0.4285284400104023    steps: 470    lr: 1.6000000000000003e-05     evaluation reward: 5.66\n","episode: 1687   score: 6.0   memory length: 388971   epsilon: 0.4278354400103979    steps: 350    lr: 1.6000000000000003e-05     evaluation reward: 5.66\n","episode: 1688   score: 6.0   memory length: 389293   epsilon: 0.4271978800103939    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 5.66\n","episode: 1689   score: 10.0   memory length: 389845   epsilon: 0.42610492001038697    steps: 552    lr: 1.6000000000000003e-05     evaluation reward: 5.71\n","episode: 1690   score: 5.0   memory length: 390209   epsilon: 0.4253842000103824    steps: 364    lr: 1.6000000000000003e-05     evaluation reward: 5.71\n","episode: 1691   score: 5.0   memory length: 390542   epsilon: 0.42472486001037824    steps: 333    lr: 1.6000000000000003e-05     evaluation reward: 5.71\n","episode: 1692   score: 5.0   memory length: 390826   epsilon: 0.4241625400103747    steps: 284    lr: 1.6000000000000003e-05     evaluation reward: 5.72\n","episode: 1693   score: 5.0   memory length: 391132   epsilon: 0.42355666001037084    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 5.75\n","episode: 1694   score: 8.0   memory length: 391603   epsilon: 0.42262408001036494    steps: 471    lr: 1.6000000000000003e-05     evaluation reward: 5.77\n","episode: 1695   score: 8.0   memory length: 392008   epsilon: 0.42182218001035987    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 5.8\n","episode: 1696   score: 9.0   memory length: 392486   epsilon: 0.4208757400103539    steps: 478    lr: 1.6000000000000003e-05     evaluation reward: 5.87\n","episode: 1697   score: 3.0   memory length: 392717   epsilon: 0.420418360010351    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 5.87\n","episode: 1698   score: 5.0   memory length: 393029   epsilon: 0.4198006000103471    steps: 312    lr: 1.6000000000000003e-05     evaluation reward: 5.9\n","episode: 1699   score: 7.0   memory length: 393444   epsilon: 0.4189789000103419    steps: 415    lr: 1.6000000000000003e-05     evaluation reward: 5.93\n","episode: 1700   score: 4.0   memory length: 393683   epsilon: 0.4185056800103389    steps: 239    lr: 1.6000000000000003e-05     evaluation reward: 5.88\n","episode: 1701   score: 4.0   memory length: 393942   epsilon: 0.41799286001033564    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 5.89\n","episode: 1702   score: 10.0   memory length: 394471   epsilon: 0.416945440010329    steps: 529    lr: 1.6000000000000003e-05     evaluation reward: 5.95\n","episode: 1703   score: 3.0   memory length: 394681   epsilon: 0.4165296400103264    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 5.91\n","episode: 1704   score: 4.0   memory length: 394957   epsilon: 0.4159831600103229    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 5.89\n","episode: 1705   score: 8.0   memory length: 395407   epsilon: 0.4150921600103173    steps: 450    lr: 1.6000000000000003e-05     evaluation reward: 5.86\n","episode: 1706   score: 4.0   memory length: 395704   epsilon: 0.41450410001031357    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 5.89\n","episode: 1707   score: 5.0   memory length: 396013   epsilon: 0.4138922800103097    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 5.9\n","episode: 1708   score: 5.0   memory length: 396320   epsilon: 0.41328442001030585    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 5.91\n","episode: 1709   score: 6.0   memory length: 396695   epsilon: 0.41254192001030116    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 5.92\n","episode: 1710   score: 7.0   memory length: 397059   epsilon: 0.4118212000102966    steps: 364    lr: 1.6000000000000003e-05     evaluation reward: 5.95\n","episode: 1711   score: 4.0   memory length: 397323   epsilon: 0.4112984800102933    steps: 264    lr: 1.6000000000000003e-05     evaluation reward: 5.92\n","episode: 1712   score: 4.0   memory length: 397578   epsilon: 0.4107935800102901    steps: 255    lr: 1.6000000000000003e-05     evaluation reward: 5.93\n","episode: 1713   score: 3.0   memory length: 397824   epsilon: 0.410306500010287    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 5.92\n","episode: 1714   score: 10.0   memory length: 398322   epsilon: 0.4093204600102808    steps: 498    lr: 1.6000000000000003e-05     evaluation reward: 5.96\n","episode: 1715   score: 5.0   memory length: 398612   epsilon: 0.40874626001027714    steps: 290    lr: 1.6000000000000003e-05     evaluation reward: 5.93\n","episode: 1716   score: 14.0   memory length: 399136   epsilon: 0.4077087400102706    steps: 524    lr: 1.6000000000000003e-05     evaluation reward: 6.05\n","episode: 1717   score: 7.0   memory length: 399503   epsilon: 0.406982080010266    steps: 367    lr: 1.6000000000000003e-05     evaluation reward: 6.09\n","episode: 1718   score: 5.0   memory length: 399809   epsilon: 0.40637620001026215    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 6.1\n","episode: 1719   score: 2.0   memory length: 400026   epsilon: 0.4059465400102594    steps: 217    lr: 6.400000000000001e-06     evaluation reward: 6.06\n","episode: 1720   score: 6.0   memory length: 400339   epsilon: 0.4053268000102555    steps: 313    lr: 6.400000000000001e-06     evaluation reward: 6.06\n","episode: 1721   score: 9.0   memory length: 400800   epsilon: 0.40441402001024973    steps: 461    lr: 6.400000000000001e-06     evaluation reward: 6.09\n","episode: 1722   score: 7.0   memory length: 401170   epsilon: 0.4036814200102451    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 6.13\n","episode: 1723   score: 10.0   memory length: 401651   epsilon: 0.40272904001023907    steps: 481    lr: 6.400000000000001e-06     evaluation reward: 6.08\n","episode: 1724   score: 4.0   memory length: 401947   epsilon: 0.40214296001023536    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 6.07\n","episode: 1725   score: 13.0   memory length: 402424   epsilon: 0.4011985000102294    steps: 477    lr: 6.400000000000001e-06     evaluation reward: 6.14\n","episode: 1726   score: 6.0   memory length: 402753   epsilon: 0.40054708001022526    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 6.18\n","episode: 1727   score: 4.0   memory length: 402997   epsilon: 0.4000639600102222    steps: 244    lr: 6.400000000000001e-06     evaluation reward: 6.18\n","episode: 1728   score: 1.0   memory length: 403148   epsilon: 0.3997649800102203    steps: 151    lr: 6.400000000000001e-06     evaluation reward: 6.11\n","episode: 1729   score: 7.0   memory length: 403518   epsilon: 0.3990323800102157    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 6.16\n","episode: 1730   score: 5.0   memory length: 403849   epsilon: 0.39837700001021153    steps: 331    lr: 6.400000000000001e-06     evaluation reward: 6.15\n","episode: 1731   score: 7.0   memory length: 404274   epsilon: 0.3975355000102062    steps: 425    lr: 6.400000000000001e-06     evaluation reward: 6.16\n","episode: 1732   score: 6.0   memory length: 404607   epsilon: 0.39687616001020204    steps: 333    lr: 6.400000000000001e-06     evaluation reward: 6.19\n","episode: 1733   score: 8.0   memory length: 405057   epsilon: 0.3959851600101964    steps: 450    lr: 6.400000000000001e-06     evaluation reward: 6.22\n","episode: 1734   score: 6.0   memory length: 405434   epsilon: 0.3952387000101917    steps: 377    lr: 6.400000000000001e-06     evaluation reward: 6.23\n","episode: 1735   score: 7.0   memory length: 405825   epsilon: 0.3944645200101868    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 6.21\n","episode: 1736   score: 8.0   memory length: 406257   epsilon: 0.39360916001018137    steps: 432    lr: 6.400000000000001e-06     evaluation reward: 6.24\n","episode: 1737   score: 4.0   memory length: 406516   epsilon: 0.3930963400101781    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 6.25\n","episode: 1738   score: 7.0   memory length: 406902   epsilon: 0.3923320600101733    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 6.22\n","episode: 1739   score: 8.0   memory length: 407311   epsilon: 0.39152224001016817    steps: 409    lr: 6.400000000000001e-06     evaluation reward: 6.26\n","episode: 1740   score: 6.0   memory length: 407669   epsilon: 0.3908134000101637    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 6.26\n","episode: 1741   score: 7.0   memory length: 408033   epsilon: 0.3900926800101591    steps: 364    lr: 6.400000000000001e-06     evaluation reward: 6.27\n","episode: 1742   score: 9.0   memory length: 408512   epsilon: 0.3891442600101531    steps: 479    lr: 6.400000000000001e-06     evaluation reward: 6.31\n","episode: 1743   score: 6.0   memory length: 408870   epsilon: 0.38843542001014864    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 6.32\n","episode: 1744   score: 5.0   memory length: 409179   epsilon: 0.38782360001014476    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 6.34\n","episode: 1745   score: 7.0   memory length: 409601   epsilon: 0.3869880400101395    steps: 422    lr: 6.400000000000001e-06     evaluation reward: 6.35\n","episode: 1746   score: 8.0   memory length: 410027   epsilon: 0.38614456001013414    steps: 426    lr: 6.400000000000001e-06     evaluation reward: 6.39\n","episode: 1747   score: 9.0   memory length: 410503   epsilon: 0.3852020800101282    steps: 476    lr: 6.400000000000001e-06     evaluation reward: 6.37\n","episode: 1748   score: 4.0   memory length: 410747   epsilon: 0.3847189600101251    steps: 244    lr: 6.400000000000001e-06     evaluation reward: 6.39\n","episode: 1749   score: 10.0   memory length: 411210   epsilon: 0.3838022200101193    steps: 463    lr: 6.400000000000001e-06     evaluation reward: 6.42\n","episode: 1750   score: 6.0   memory length: 411532   epsilon: 0.3831646600101153    steps: 322    lr: 6.400000000000001e-06     evaluation reward: 6.44\n","episode: 1751   score: 6.0   memory length: 411889   epsilon: 0.3824578000101108    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 6.46\n","episode: 1752   score: 5.0   memory length: 412200   epsilon: 0.3818420200101069    steps: 311    lr: 6.400000000000001e-06     evaluation reward: 6.42\n","episode: 1753   score: 7.0   memory length: 412593   epsilon: 0.381063880010102    steps: 393    lr: 6.400000000000001e-06     evaluation reward: 6.43\n","episode: 1754   score: 7.0   memory length: 412944   epsilon: 0.3803689000100976    steps: 351    lr: 6.400000000000001e-06     evaluation reward: 6.45\n","episode: 1755   score: 5.0   memory length: 413216   epsilon: 0.3798303400100942    steps: 272    lr: 6.400000000000001e-06     evaluation reward: 6.46\n","episode: 1756   score: 7.0   memory length: 413636   epsilon: 0.37899874001008893    steps: 420    lr: 6.400000000000001e-06     evaluation reward: 6.47\n","episode: 1757   score: 7.0   memory length: 413984   epsilon: 0.37830970001008457    steps: 348    lr: 6.400000000000001e-06     evaluation reward: 6.5\n","episode: 1758   score: 7.0   memory length: 414362   epsilon: 0.37756126001007984    steps: 378    lr: 6.400000000000001e-06     evaluation reward: 6.54\n","episode: 1759   score: 11.0   memory length: 414851   epsilon: 0.3765930400100737    steps: 489    lr: 6.400000000000001e-06     evaluation reward: 6.6\n","episode: 1760   score: 8.0   memory length: 415251   epsilon: 0.3758010400100687    steps: 400    lr: 6.400000000000001e-06     evaluation reward: 6.62\n","episode: 1761   score: 11.0   memory length: 415740   epsilon: 0.3748328200100626    steps: 489    lr: 6.400000000000001e-06     evaluation reward: 6.69\n","episode: 1762   score: 6.0   memory length: 416095   epsilon: 0.3741299200100581    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 6.67\n","episode: 1763   score: 11.0   memory length: 416600   epsilon: 0.3731300200100518    steps: 505    lr: 6.400000000000001e-06     evaluation reward: 6.7\n","episode: 1764   score: 9.0   memory length: 417090   epsilon: 0.37215982001004566    steps: 490    lr: 6.400000000000001e-06     evaluation reward: 6.69\n","episode: 1765   score: 3.0   memory length: 417322   epsilon: 0.37170046001004275    steps: 232    lr: 6.400000000000001e-06     evaluation reward: 6.69\n","episode: 1766   score: 8.0   memory length: 417738   epsilon: 0.37087678001003754    steps: 416    lr: 6.400000000000001e-06     evaluation reward: 6.69\n","episode: 1767   score: 5.0   memory length: 418064   epsilon: 0.37023130001003346    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 6.67\n","episode: 1768   score: 9.0   memory length: 418542   epsilon: 0.36928486001002747    steps: 478    lr: 6.400000000000001e-06     evaluation reward: 6.68\n","episode: 1769   score: 9.0   memory length: 418971   epsilon: 0.3684354400100221    steps: 429    lr: 6.400000000000001e-06     evaluation reward: 6.68\n","episode: 1770   score: 7.0   memory length: 419381   epsilon: 0.36762364001001696    steps: 410    lr: 6.400000000000001e-06     evaluation reward: 6.66\n","episode: 1771   score: 6.0   memory length: 419760   epsilon: 0.3668732200100122    steps: 379    lr: 6.400000000000001e-06     evaluation reward: 6.67\n","episode: 1772   score: 7.0   memory length: 420130   epsilon: 0.3661406200100076    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 6.66\n","episode: 1773   score: 8.0   memory length: 420581   epsilon: 0.36524764001000193    steps: 451    lr: 6.400000000000001e-06     evaluation reward: 6.68\n","episode: 1774   score: 7.0   memory length: 421004   epsilon: 0.36441010000999663    steps: 423    lr: 6.400000000000001e-06     evaluation reward: 6.65\n","episode: 1775   score: 5.0   memory length: 421313   epsilon: 0.36379828000999276    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 6.64\n","episode: 1776   score: 8.0   memory length: 421776   epsilon: 0.36288154000998696    steps: 463    lr: 6.400000000000001e-06     evaluation reward: 6.65\n","episode: 1777   score: 9.0   memory length: 422283   epsilon: 0.3618776800099806    steps: 507    lr: 6.400000000000001e-06     evaluation reward: 6.68\n","episode: 1778   score: 4.0   memory length: 422543   epsilon: 0.36136288000997735    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 6.69\n","episode: 1779   score: 7.0   memory length: 422911   epsilon: 0.36063424000997274    steps: 368    lr: 6.400000000000001e-06     evaluation reward: 6.67\n","episode: 1780   score: 7.0   memory length: 423317   epsilon: 0.35983036000996765    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 6.69\n","episode: 1781   score: 4.0   memory length: 423596   epsilon: 0.35927794000996416    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 6.65\n","episode: 1782   score: 7.0   memory length: 424002   epsilon: 0.3584740600099591    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 6.63\n","episode: 1783   score: 10.0   memory length: 424580   epsilon: 0.35732962000995183    steps: 578    lr: 6.400000000000001e-06     evaluation reward: 6.67\n","episode: 1784   score: 10.0   memory length: 425060   epsilon: 0.3563792200099458    steps: 480    lr: 6.400000000000001e-06     evaluation reward: 6.73\n","episode: 1785   score: 3.0   memory length: 425270   epsilon: 0.3559634200099432    steps: 210    lr: 6.400000000000001e-06     evaluation reward: 6.65\n","episode: 1786   score: 4.0   memory length: 425550   epsilon: 0.3554090200099397    steps: 280    lr: 6.400000000000001e-06     evaluation reward: 6.6\n","episode: 1787   score: 10.0   memory length: 426036   epsilon: 0.3544467400099336    steps: 486    lr: 6.400000000000001e-06     evaluation reward: 6.64\n","episode: 1788   score: 11.0   memory length: 426585   epsilon: 0.3533597200099267    steps: 549    lr: 6.400000000000001e-06     evaluation reward: 6.69\n","episode: 1789   score: 2.0   memory length: 426784   epsilon: 0.3529657000099242    steps: 199    lr: 6.400000000000001e-06     evaluation reward: 6.61\n","episode: 1790   score: 7.0   memory length: 427189   epsilon: 0.35216380000991915    steps: 405    lr: 6.400000000000001e-06     evaluation reward: 6.63\n","episode: 1791   score: 7.0   memory length: 427560   epsilon: 0.3514292200099145    steps: 371    lr: 6.400000000000001e-06     evaluation reward: 6.65\n","episode: 1792   score: 7.0   memory length: 427946   epsilon: 0.35066494000990966    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 6.67\n","episode: 1793   score: 3.0   memory length: 428175   epsilon: 0.3502115200099068    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 6.65\n","episode: 1794   score: 8.0   memory length: 428624   epsilon: 0.34932250000990117    steps: 449    lr: 6.400000000000001e-06     evaluation reward: 6.65\n","episode: 1795   score: 9.0   memory length: 429102   epsilon: 0.3483760600098952    steps: 478    lr: 6.400000000000001e-06     evaluation reward: 6.66\n","episode: 1796   score: 9.0   memory length: 429541   epsilon: 0.3475068400098897    steps: 439    lr: 6.400000000000001e-06     evaluation reward: 6.66\n","episode: 1797   score: 5.0   memory length: 429829   epsilon: 0.3469366000098861    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 6.68\n","episode: 1798   score: 7.0   memory length: 430225   epsilon: 0.3461525200098811    steps: 396    lr: 6.400000000000001e-06     evaluation reward: 6.7\n","episode: 1799   score: 14.0   memory length: 430807   epsilon: 0.3450001600098738    steps: 582    lr: 6.400000000000001e-06     evaluation reward: 6.77\n","episode: 1800   score: 8.0   memory length: 431246   epsilon: 0.3441309400098683    steps: 439    lr: 6.400000000000001e-06     evaluation reward: 6.81\n","episode: 1801   score: 7.0   memory length: 431492   epsilon: 0.34364386000986524    steps: 246    lr: 6.400000000000001e-06     evaluation reward: 6.84\n","episode: 1802   score: 9.0   memory length: 431976   epsilon: 0.3426855400098592    steps: 484    lr: 6.400000000000001e-06     evaluation reward: 6.83\n","episode: 1803   score: 9.0   memory length: 432305   epsilon: 0.34203412000985506    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 6.89\n","episode: 1804   score: 10.0   memory length: 432760   epsilon: 0.34113322000984936    steps: 455    lr: 6.400000000000001e-06     evaluation reward: 6.95\n","episode: 1805   score: 12.0   memory length: 433348   epsilon: 0.339968980009842    steps: 588    lr: 6.400000000000001e-06     evaluation reward: 6.99\n","episode: 1806   score: 9.0   memory length: 433863   epsilon: 0.33894928000983554    steps: 515    lr: 6.400000000000001e-06     evaluation reward: 7.04\n","episode: 1807   score: 5.0   memory length: 434208   epsilon: 0.3382661800098312    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 7.04\n","episode: 1808   score: 8.0   memory length: 434660   epsilon: 0.33737122000982556    steps: 452    lr: 6.400000000000001e-06     evaluation reward: 7.07\n","episode: 1809   score: 7.0   memory length: 435008   epsilon: 0.3366821800098212    steps: 348    lr: 6.400000000000001e-06     evaluation reward: 7.08\n","episode: 1810   score: 5.0   memory length: 435337   epsilon: 0.3360307600098171    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 7.06\n","episode: 1811   score: 7.0   memory length: 435762   epsilon: 0.33518926000981175    steps: 425    lr: 6.400000000000001e-06     evaluation reward: 7.09\n","episode: 1812   score: 4.0   memory length: 436006   epsilon: 0.3347061400098087    steps: 244    lr: 6.400000000000001e-06     evaluation reward: 7.09\n","episode: 1813   score: 8.0   memory length: 436443   epsilon: 0.3338408800098032    steps: 437    lr: 6.400000000000001e-06     evaluation reward: 7.14\n","episode: 1814   score: 8.0   memory length: 436884   epsilon: 0.3329677000097977    steps: 441    lr: 6.400000000000001e-06     evaluation reward: 7.12\n","episode: 1815   score: 9.0   memory length: 437358   epsilon: 0.33202918000979176    steps: 474    lr: 6.400000000000001e-06     evaluation reward: 7.16\n","episode: 1816   score: 11.0   memory length: 437773   epsilon: 0.33120748000978656    steps: 415    lr: 6.400000000000001e-06     evaluation reward: 7.13\n","episode: 1817   score: 5.0   memory length: 438063   epsilon: 0.3306332800097829    steps: 290    lr: 6.400000000000001e-06     evaluation reward: 7.11\n","episode: 1818   score: 5.0   memory length: 438370   epsilon: 0.3300254200097791    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 7.11\n","episode: 1819   score: 4.0   memory length: 438648   epsilon: 0.3294749800097756    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 7.13\n","episode: 1820   score: 7.0   memory length: 439034   epsilon: 0.32871070000977076    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 7.14\n","episode: 1821   score: 8.0   memory length: 439478   epsilon: 0.3278315800097652    steps: 444    lr: 6.400000000000001e-06     evaluation reward: 7.13\n","episode: 1822   score: 6.0   memory length: 439830   epsilon: 0.3271346200097608    steps: 352    lr: 6.400000000000001e-06     evaluation reward: 7.12\n","episode: 1823   score: 3.0   memory length: 440041   epsilon: 0.32671684000975815    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 7.05\n","episode: 1824   score: 10.0   memory length: 440530   epsilon: 0.325748620009752    steps: 489    lr: 6.400000000000001e-06     evaluation reward: 7.11\n","episode: 1825   score: 13.0   memory length: 441126   epsilon: 0.32456854000974455    steps: 596    lr: 6.400000000000001e-06     evaluation reward: 7.11\n","episode: 1826   score: 6.0   memory length: 441467   epsilon: 0.3238933600097403    steps: 341    lr: 6.400000000000001e-06     evaluation reward: 7.11\n","episode: 1827   score: 7.0   memory length: 441891   epsilon: 0.32305384000973497    steps: 424    lr: 6.400000000000001e-06     evaluation reward: 7.14\n","episode: 1828   score: 6.0   memory length: 442248   epsilon: 0.3223469800097305    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 7.19\n","episode: 1829   score: 6.0   memory length: 442591   epsilon: 0.3216678400097262    steps: 343    lr: 6.400000000000001e-06     evaluation reward: 7.18\n","episode: 1830   score: 6.0   memory length: 442907   epsilon: 0.32104216000972224    steps: 316    lr: 6.400000000000001e-06     evaluation reward: 7.19\n","episode: 1831   score: 4.0   memory length: 443165   epsilon: 0.320531320009719    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 7.16\n","episode: 1832   score: 8.0   memory length: 443442   epsilon: 0.31998286000971554    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 7.18\n","episode: 1833   score: 7.0   memory length: 443844   epsilon: 0.3191869000097105    steps: 402    lr: 6.400000000000001e-06     evaluation reward: 7.17\n","episode: 1834   score: 11.0   memory length: 444420   epsilon: 0.3180464200097033    steps: 576    lr: 6.400000000000001e-06     evaluation reward: 7.22\n","episode: 1835   score: 16.0   memory length: 444987   epsilon: 0.3169237600096962    steps: 567    lr: 6.400000000000001e-06     evaluation reward: 7.31\n","episode: 1836   score: 14.0   memory length: 445593   epsilon: 0.3157238800096886    steps: 606    lr: 6.400000000000001e-06     evaluation reward: 7.37\n","episode: 1837   score: 11.0   memory length: 446117   epsilon: 0.31468636000968203    steps: 524    lr: 6.400000000000001e-06     evaluation reward: 7.44\n","episode: 1838   score: 10.0   memory length: 446610   epsilon: 0.31371022000967586    steps: 493    lr: 6.400000000000001e-06     evaluation reward: 7.47\n","episode: 1839   score: 7.0   memory length: 446995   epsilon: 0.31294792000967103    steps: 385    lr: 6.400000000000001e-06     evaluation reward: 7.46\n","episode: 1840   score: 11.0   memory length: 447621   epsilon: 0.3117084400096632    steps: 626    lr: 6.400000000000001e-06     evaluation reward: 7.51\n","episode: 1841   score: 12.0   memory length: 448101   epsilon: 0.3107580400096572    steps: 480    lr: 6.400000000000001e-06     evaluation reward: 7.56\n","episode: 1842   score: 9.0   memory length: 448579   epsilon: 0.3098116000096512    steps: 478    lr: 6.400000000000001e-06     evaluation reward: 7.56\n","episode: 1843   score: 10.0   memory length: 449079   epsilon: 0.3088216000096449    steps: 500    lr: 6.400000000000001e-06     evaluation reward: 7.6\n","episode: 1844   score: 8.0   memory length: 449554   epsilon: 0.307881100009639    steps: 475    lr: 6.400000000000001e-06     evaluation reward: 7.63\n","episode: 1845   score: 8.0   memory length: 449968   epsilon: 0.3070613800096338    steps: 414    lr: 6.400000000000001e-06     evaluation reward: 7.64\n","episode: 1846   score: 9.0   memory length: 450418   epsilon: 0.30617038000962815    steps: 450    lr: 6.400000000000001e-06     evaluation reward: 7.65\n","episode: 1847   score: 6.0   memory length: 450763   epsilon: 0.30548728000962383    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 7.62\n","episode: 1848   score: 7.0   memory length: 451127   epsilon: 0.30476656000961927    steps: 364    lr: 6.400000000000001e-06     evaluation reward: 7.65\n","episode: 1849   score: 8.0   memory length: 451552   epsilon: 0.30392506000961395    steps: 425    lr: 6.400000000000001e-06     evaluation reward: 7.63\n","episode: 1850   score: 13.0   memory length: 452176   epsilon: 0.30268954000960613    steps: 624    lr: 6.400000000000001e-06     evaluation reward: 7.7\n","episode: 1851   score: 10.0   memory length: 452696   epsilon: 0.3016599400095996    steps: 520    lr: 6.400000000000001e-06     evaluation reward: 7.74\n","episode: 1852   score: 11.0   memory length: 453173   epsilon: 0.30071548000959364    steps: 477    lr: 6.400000000000001e-06     evaluation reward: 7.8\n","episode: 1853   score: 10.0   memory length: 453674   epsilon: 0.29972350000958736    steps: 501    lr: 6.400000000000001e-06     evaluation reward: 7.83\n","episode: 1854   score: 6.0   memory length: 454036   epsilon: 0.2990067400095828    steps: 362    lr: 6.400000000000001e-06     evaluation reward: 7.82\n","episode: 1855   score: 7.0   memory length: 454407   epsilon: 0.2982721600095782    steps: 371    lr: 6.400000000000001e-06     evaluation reward: 7.84\n","episode: 1856   score: 7.0   memory length: 454794   epsilon: 0.29750590000957333    steps: 387    lr: 6.400000000000001e-06     evaluation reward: 7.84\n","episode: 1857   score: 12.0   memory length: 455327   epsilon: 0.29645056000956665    steps: 533    lr: 6.400000000000001e-06     evaluation reward: 7.89\n","episode: 1858   score: 5.0   memory length: 455624   epsilon: 0.29586250000956293    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 7.87\n","episode: 1859   score: 7.0   memory length: 456023   epsilon: 0.29507248000955794    steps: 399    lr: 6.400000000000001e-06     evaluation reward: 7.83\n","episode: 1860   score: 12.0   memory length: 456583   epsilon: 0.2939636800095509    steps: 560    lr: 6.400000000000001e-06     evaluation reward: 7.87\n","episode: 1861   score: 9.0   memory length: 457059   epsilon: 0.29302120000954496    steps: 476    lr: 6.400000000000001e-06     evaluation reward: 7.85\n","episode: 1862   score: 8.0   memory length: 457483   epsilon: 0.29218168000953965    steps: 424    lr: 6.400000000000001e-06     evaluation reward: 7.87\n","episode: 1863   score: 6.0   memory length: 457822   epsilon: 0.2915104600095354    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 7.82\n","episode: 1864   score: 11.0   memory length: 458227   epsilon: 0.2907085600095303    steps: 405    lr: 6.400000000000001e-06     evaluation reward: 7.84\n","episode: 1865   score: 9.0   memory length: 458668   epsilon: 0.2898353800095248    steps: 441    lr: 6.400000000000001e-06     evaluation reward: 7.9\n","episode: 1866   score: 7.0   memory length: 459041   epsilon: 0.28909684000952013    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 7.89\n","episode: 1867   score: 11.0   memory length: 459627   epsilon: 0.2879365600095128    steps: 586    lr: 6.400000000000001e-06     evaluation reward: 7.95\n","episode: 1868   score: 6.0   memory length: 459952   epsilon: 0.2872930600095087    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 7.92\n","episode: 1869   score: 4.0   memory length: 460235   epsilon: 0.28673272000950517    steps: 283    lr: 6.400000000000001e-06     evaluation reward: 7.87\n","episode: 1870   score: 6.0   memory length: 460612   epsilon: 0.28598626000950045    steps: 377    lr: 6.400000000000001e-06     evaluation reward: 7.86\n","episode: 1871   score: 7.0   memory length: 460979   epsilon: 0.28525960000949585    steps: 367    lr: 6.400000000000001e-06     evaluation reward: 7.87\n","episode: 1872   score: 11.0   memory length: 461513   epsilon: 0.28420228000948916    steps: 534    lr: 6.400000000000001e-06     evaluation reward: 7.91\n","episode: 1873   score: 11.0   memory length: 462047   epsilon: 0.28314496000948247    steps: 534    lr: 6.400000000000001e-06     evaluation reward: 7.94\n","episode: 1874   score: 4.0   memory length: 462322   epsilon: 0.282600460009479    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 7.91\n","episode: 1875   score: 12.0   memory length: 462804   epsilon: 0.281646100009473    steps: 482    lr: 6.400000000000001e-06     evaluation reward: 7.98\n","episode: 1876   score: 7.0   memory length: 463184   epsilon: 0.28089370000946823    steps: 380    lr: 6.400000000000001e-06     evaluation reward: 7.97\n","episode: 1877   score: 8.0   memory length: 463639   epsilon: 0.27999280000946253    steps: 455    lr: 6.400000000000001e-06     evaluation reward: 7.96\n","episode: 1878   score: 7.0   memory length: 464076   epsilon: 0.27912754000945705    steps: 437    lr: 6.400000000000001e-06     evaluation reward: 7.99\n","episode: 1879   score: 8.0   memory length: 464500   epsilon: 0.27828802000945174    steps: 424    lr: 6.400000000000001e-06     evaluation reward: 8.0\n","episode: 1880   score: 9.0   memory length: 464959   epsilon: 0.277379200009446    steps: 459    lr: 6.400000000000001e-06     evaluation reward: 8.02\n","episode: 1881   score: 5.0   memory length: 465266   epsilon: 0.27677134000944215    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 8.03\n","episode: 1882   score: 7.0   memory length: 465650   epsilon: 0.27601102000943734    steps: 384    lr: 6.400000000000001e-06     evaluation reward: 8.03\n","episode: 1883   score: 17.0   memory length: 466297   epsilon: 0.27472996000942923    steps: 647    lr: 6.400000000000001e-06     evaluation reward: 8.1\n","episode: 1884   score: 7.0   memory length: 466683   epsilon: 0.2739656800094244    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 8.07\n","episode: 1885   score: 9.0   memory length: 467164   epsilon: 0.27301330000941837    steps: 481    lr: 6.400000000000001e-06     evaluation reward: 8.13\n","episode: 1886   score: 11.0   memory length: 467585   epsilon: 0.2721797200094131    steps: 421    lr: 6.400000000000001e-06     evaluation reward: 8.2\n","episode: 1887   score: 17.0   memory length: 467985   epsilon: 0.2713877200094081    steps: 400    lr: 6.400000000000001e-06     evaluation reward: 8.27\n","episode: 1888   score: 6.0   memory length: 468330   epsilon: 0.27070462000940376    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 8.22\n","episode: 1889   score: 7.0   memory length: 468686   epsilon: 0.2699997400093993    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 8.27\n","episode: 1890   score: 5.0   memory length: 469001   epsilon: 0.26937604000939536    steps: 315    lr: 6.400000000000001e-06     evaluation reward: 8.25\n","episode: 1891   score: 6.0   memory length: 469379   epsilon: 0.2686276000093906    steps: 378    lr: 6.400000000000001e-06     evaluation reward: 8.24\n","episode: 1892   score: 12.0   memory length: 469824   epsilon: 0.26774650000938505    steps: 445    lr: 6.400000000000001e-06     evaluation reward: 8.29\n","episode: 1893   score: 10.0   memory length: 470164   epsilon: 0.2670733000093808    steps: 340    lr: 6.400000000000001e-06     evaluation reward: 8.36\n","episode: 1894   score: 11.0   memory length: 470746   epsilon: 0.2659209400093735    steps: 582    lr: 6.400000000000001e-06     evaluation reward: 8.39\n","episode: 1895   score: 4.0   memory length: 471029   epsilon: 0.26536060000936995    steps: 283    lr: 6.400000000000001e-06     evaluation reward: 8.34\n","episode: 1896   score: 8.0   memory length: 471472   epsilon: 0.2644834600093644    steps: 443    lr: 6.400000000000001e-06     evaluation reward: 8.33\n","episode: 1897   score: 7.0   memory length: 471863   epsilon: 0.2637092800093595    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 8.35\n","episode: 1898   score: 12.0   memory length: 472415   epsilon: 0.2626163200093526    steps: 552    lr: 6.400000000000001e-06     evaluation reward: 8.4\n","episode: 1899   score: 10.0   memory length: 472897   epsilon: 0.26166196000934655    steps: 482    lr: 6.400000000000001e-06     evaluation reward: 8.36\n","episode: 1900   score: 11.0   memory length: 473393   epsilon: 0.26067988000934034    steps: 496    lr: 6.400000000000001e-06     evaluation reward: 8.39\n","episode: 1901   score: 11.0   memory length: 473876   epsilon: 0.2597235400093343    steps: 483    lr: 6.400000000000001e-06     evaluation reward: 8.43\n","episode: 1902   score: 6.0   memory length: 474197   epsilon: 0.25908796000933026    steps: 321    lr: 6.400000000000001e-06     evaluation reward: 8.4\n","episode: 1903   score: 7.0   memory length: 474579   epsilon: 0.2583316000093255    steps: 382    lr: 6.400000000000001e-06     evaluation reward: 8.38\n","episode: 1904   score: 8.0   memory length: 475007   epsilon: 0.2574841600093201    steps: 428    lr: 6.400000000000001e-06     evaluation reward: 8.36\n","episode: 1905   score: 5.0   memory length: 475316   epsilon: 0.25687234000931625    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 8.29\n","episode: 1906   score: 6.0   memory length: 475673   epsilon: 0.2561654800093118    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 8.26\n","episode: 1907   score: 11.0   memory length: 476191   epsilon: 0.2551398400093053    steps: 518    lr: 6.400000000000001e-06     evaluation reward: 8.32\n","episode: 1908   score: 6.0   memory length: 476535   epsilon: 0.254458720009301    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 8.3\n","episode: 1909   score: 8.0   memory length: 476942   epsilon: 0.2536528600092959    steps: 407    lr: 6.400000000000001e-06     evaluation reward: 8.31\n","episode: 1910   score: 6.0   memory length: 477279   epsilon: 0.25298560000929166    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 8.32\n","episode: 1911   score: 6.0   memory length: 477621   epsilon: 0.25230844000928737    steps: 342    lr: 6.400000000000001e-06     evaluation reward: 8.31\n","episode: 1912   score: 5.0   memory length: 477930   epsilon: 0.2516966200092835    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 8.32\n","episode: 1913   score: 7.0   memory length: 478317   epsilon: 0.25093036000927865    steps: 387    lr: 6.400000000000001e-06     evaluation reward: 8.31\n","episode: 1914   score: 3.0   memory length: 478530   epsilon: 0.250508620009276    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 8.26\n","episode: 1915   score: 9.0   memory length: 479004   epsilon: 0.24957010000927005    steps: 474    lr: 6.400000000000001e-06     evaluation reward: 8.26\n","episode: 1916   score: 11.0   memory length: 479585   epsilon: 0.24841972000926277    steps: 581    lr: 6.400000000000001e-06     evaluation reward: 8.26\n","episode: 1917   score: 11.0   memory length: 479997   epsilon: 0.2476039600092576    steps: 412    lr: 6.400000000000001e-06     evaluation reward: 8.32\n","episode: 1918   score: 10.0   memory length: 480482   epsilon: 0.24664366000925153    steps: 485    lr: 6.400000000000001e-06     evaluation reward: 8.37\n","episode: 1919   score: 12.0   memory length: 481001   epsilon: 0.24561604000924503    steps: 519    lr: 6.400000000000001e-06     evaluation reward: 8.45\n","episode: 1920   score: 2.0   memory length: 481182   epsilon: 0.24525766000924276    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 8.4\n","episode: 1921   score: 8.0   memory length: 481630   epsilon: 0.24437062000923715    steps: 448    lr: 6.400000000000001e-06     evaluation reward: 8.4\n","episode: 1922   score: 5.0   memory length: 481955   epsilon: 0.24372712000923308    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 8.39\n","episode: 1923   score: 6.0   memory length: 482300   epsilon: 0.24304402000922876    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 8.42\n","episode: 1924   score: 6.0   memory length: 482640   epsilon: 0.2423708200092245    steps: 340    lr: 6.400000000000001e-06     evaluation reward: 8.38\n","episode: 1925   score: 10.0   memory length: 483112   epsilon: 0.24143626000921858    steps: 472    lr: 6.400000000000001e-06     evaluation reward: 8.35\n","episode: 1926   score: 10.0   memory length: 483647   epsilon: 0.24037696000921188    steps: 535    lr: 6.400000000000001e-06     evaluation reward: 8.39\n","episode: 1927   score: 7.0   memory length: 484009   epsilon: 0.23966020000920735    steps: 362    lr: 6.400000000000001e-06     evaluation reward: 8.39\n","episode: 1928   score: 8.0   memory length: 484412   epsilon: 0.2388622600092023    steps: 403    lr: 6.400000000000001e-06     evaluation reward: 8.41\n","episode: 1929   score: 12.0   memory length: 484994   epsilon: 0.237709900009195    steps: 582    lr: 6.400000000000001e-06     evaluation reward: 8.47\n","episode: 1930   score: 10.0   memory length: 485375   epsilon: 0.23695552000919023    steps: 381    lr: 6.400000000000001e-06     evaluation reward: 8.51\n","episode: 1931   score: 5.0   memory length: 485663   epsilon: 0.23638528000918663    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 8.52\n","episode: 1932   score: 10.0   memory length: 486197   epsilon: 0.23532796000917994    steps: 534    lr: 6.400000000000001e-06     evaluation reward: 8.54\n","episode: 1933   score: 15.0   memory length: 486759   epsilon: 0.2342152000091729    steps: 562    lr: 6.400000000000001e-06     evaluation reward: 8.62\n","episode: 1934   score: 6.0   memory length: 487112   epsilon: 0.23351626000916847    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 8.57\n","episode: 1935   score: 10.0   memory length: 487451   epsilon: 0.23284504000916423    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 8.51\n","episode: 1936   score: 8.0   memory length: 487898   epsilon: 0.23195998000915863    steps: 447    lr: 6.400000000000001e-06     evaluation reward: 8.45\n","episode: 1937   score: 9.0   memory length: 488391   epsilon: 0.23098384000915245    steps: 493    lr: 6.400000000000001e-06     evaluation reward: 8.43\n","episode: 1938   score: 11.0   memory length: 488772   epsilon: 0.23022946000914768    steps: 381    lr: 6.400000000000001e-06     evaluation reward: 8.44\n","episode: 1939   score: 7.0   memory length: 489144   epsilon: 0.22949290000914302    steps: 372    lr: 6.400000000000001e-06     evaluation reward: 8.44\n","episode: 1940   score: 8.0   memory length: 489618   epsilon: 0.22855438000913708    steps: 474    lr: 6.400000000000001e-06     evaluation reward: 8.41\n","episode: 1941   score: 10.0   memory length: 490155   epsilon: 0.22749112000913035    steps: 537    lr: 6.400000000000001e-06     evaluation reward: 8.39\n","episode: 1942   score: 6.0   memory length: 490529   epsilon: 0.22675060000912567    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 8.36\n","episode: 1943   score: 7.0   memory length: 490900   epsilon: 0.22601602000912102    steps: 371    lr: 6.400000000000001e-06     evaluation reward: 8.33\n","episode: 1944   score: 6.0   memory length: 491239   epsilon: 0.22534480000911677    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 8.31\n","episode: 1945   score: 16.0   memory length: 491837   epsilon: 0.22416076000910928    steps: 598    lr: 6.400000000000001e-06     evaluation reward: 8.39\n","episode: 1946   score: 9.0   memory length: 492325   epsilon: 0.22319452000910317    steps: 488    lr: 6.400000000000001e-06     evaluation reward: 8.39\n","episode: 1947   score: 8.0   memory length: 492736   epsilon: 0.22238074000909802    steps: 411    lr: 6.400000000000001e-06     evaluation reward: 8.41\n","episode: 1948   score: 7.0   memory length: 493121   epsilon: 0.2216184400090932    steps: 385    lr: 6.400000000000001e-06     evaluation reward: 8.41\n","episode: 1949   score: 8.0   memory length: 493551   epsilon: 0.2207670400090878    steps: 430    lr: 6.400000000000001e-06     evaluation reward: 8.41\n","episode: 1950   score: 3.0   memory length: 493766   epsilon: 0.22034134000908512    steps: 215    lr: 6.400000000000001e-06     evaluation reward: 8.31\n","episode: 1951   score: 11.0   memory length: 494348   epsilon: 0.21918898000907783    steps: 582    lr: 6.400000000000001e-06     evaluation reward: 8.32\n","episode: 1952   score: 6.0   memory length: 494685   epsilon: 0.2185217200090736    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 8.27\n","episode: 1953   score: 3.0   memory length: 494896   epsilon: 0.21810394000907096    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 8.2\n","episode: 1954   score: 8.0   memory length: 495319   epsilon: 0.21726640000906566    steps: 423    lr: 6.400000000000001e-06     evaluation reward: 8.22\n","episode: 1955   score: 8.0   memory length: 495708   epsilon: 0.2164961800090608    steps: 389    lr: 6.400000000000001e-06     evaluation reward: 8.23\n","episode: 1956   score: 11.0   memory length: 496228   epsilon: 0.21546658000905428    steps: 520    lr: 6.400000000000001e-06     evaluation reward: 8.27\n","episode: 1957   score: 7.0   memory length: 496613   epsilon: 0.21470428000904945    steps: 385    lr: 6.400000000000001e-06     evaluation reward: 8.22\n","episode: 1958   score: 6.0   memory length: 496987   epsilon: 0.21396376000904477    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 8.23\n","episode: 1959   score: 10.0   memory length: 497524   epsilon: 0.21290050000903804    steps: 537    lr: 6.400000000000001e-06     evaluation reward: 8.26\n","episode: 1960   score: 6.0   memory length: 497897   epsilon: 0.21216196000903337    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 8.2\n","episode: 1961   score: 7.0   memory length: 498268   epsilon: 0.21142738000902872    steps: 371    lr: 6.400000000000001e-06     evaluation reward: 8.18\n","episode: 1962   score: 9.0   memory length: 498694   epsilon: 0.21058390000902338    steps: 426    lr: 6.400000000000001e-06     evaluation reward: 8.19\n","episode: 1963   score: 9.0   memory length: 499164   epsilon: 0.2096533000090175    steps: 470    lr: 6.400000000000001e-06     evaluation reward: 8.22\n","episode: 1964   score: 5.0   memory length: 499461   epsilon: 0.20906524000901378    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 8.16\n","episode: 1965   score: 9.0   memory length: 499945   epsilon: 0.2081069200090077    steps: 484    lr: 6.400000000000001e-06     evaluation reward: 8.16\n","episode: 1966   score: 9.0   memory length: 500379   epsilon: 0.20724760000900228    steps: 434    lr: 2.560000000000001e-06     evaluation reward: 8.18\n","episode: 1967   score: 9.0   memory length: 500840   epsilon: 0.2063348200089965    steps: 461    lr: 2.560000000000001e-06     evaluation reward: 8.16\n","episode: 1968   score: 14.0   memory length: 501367   epsilon: 0.2052913600089899    steps: 527    lr: 2.560000000000001e-06     evaluation reward: 8.24\n","episode: 1969   score: 8.0   memory length: 501828   epsilon: 0.20437858000898412    steps: 461    lr: 2.560000000000001e-06     evaluation reward: 8.28\n","episode: 1970   score: 10.0   memory length: 502331   epsilon: 0.20338264000897782    steps: 503    lr: 2.560000000000001e-06     evaluation reward: 8.32\n","episode: 1971   score: 4.0   memory length: 502609   epsilon: 0.20283220000897434    steps: 278    lr: 2.560000000000001e-06     evaluation reward: 8.29\n","episode: 1972   score: 11.0   memory length: 503090   epsilon: 0.2018798200089683    steps: 481    lr: 2.560000000000001e-06     evaluation reward: 8.29\n","episode: 1973   score: 8.0   memory length: 503524   epsilon: 0.20102050000896288    steps: 434    lr: 2.560000000000001e-06     evaluation reward: 8.26\n","episode: 1974   score: 5.0   memory length: 503813   epsilon: 0.20044828000895926    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 8.27\n","episode: 1975   score: 10.0   memory length: 504300   epsilon: 0.19948402000895316    steps: 487    lr: 2.560000000000001e-06     evaluation reward: 8.25\n","episode: 1976   score: 9.0   memory length: 504785   epsilon: 0.19852372000894708    steps: 485    lr: 2.560000000000001e-06     evaluation reward: 8.27\n","episode: 1977   score: 12.0   memory length: 505331   epsilon: 0.19744264000894024    steps: 546    lr: 2.560000000000001e-06     evaluation reward: 8.31\n","episode: 1978   score: 13.0   memory length: 505921   epsilon: 0.19627444000893285    steps: 590    lr: 2.560000000000001e-06     evaluation reward: 8.37\n","episode: 1979   score: 6.0   memory length: 506253   epsilon: 0.1956170800089287    steps: 332    lr: 2.560000000000001e-06     evaluation reward: 8.35\n","episode: 1980   score: 9.0   memory length: 506740   epsilon: 0.1946528200089226    steps: 487    lr: 2.560000000000001e-06     evaluation reward: 8.35\n","episode: 1981   score: 9.0   memory length: 507210   epsilon: 0.1937222200089167    steps: 470    lr: 2.560000000000001e-06     evaluation reward: 8.39\n","episode: 1982   score: 13.0   memory length: 507790   epsilon: 0.19257382000890944    steps: 580    lr: 2.560000000000001e-06     evaluation reward: 8.45\n","episode: 1983   score: 14.0   memory length: 508293   epsilon: 0.19157788000890313    steps: 503    lr: 2.560000000000001e-06     evaluation reward: 8.42\n","episode: 1984   score: 9.0   memory length: 508788   epsilon: 0.19059778000889693    steps: 495    lr: 2.560000000000001e-06     evaluation reward: 8.44\n","episode: 1985   score: 7.0   memory length: 509134   epsilon: 0.1899127000088926    steps: 346    lr: 2.560000000000001e-06     evaluation reward: 8.42\n","episode: 1986   score: 9.0   memory length: 509512   epsilon: 0.18916426000888786    steps: 378    lr: 2.560000000000001e-06     evaluation reward: 8.4\n","episode: 1987   score: 14.0   memory length: 510050   epsilon: 0.18809902000888112    steps: 538    lr: 2.560000000000001e-06     evaluation reward: 8.37\n","episode: 1988   score: 11.0   memory length: 510586   epsilon: 0.1870377400088744    steps: 536    lr: 2.560000000000001e-06     evaluation reward: 8.42\n","episode: 1989   score: 8.0   memory length: 511061   epsilon: 0.18609724000886846    steps: 475    lr: 2.560000000000001e-06     evaluation reward: 8.43\n","episode: 1990   score: 8.0   memory length: 511458   epsilon: 0.18531118000886349    steps: 397    lr: 2.560000000000001e-06     evaluation reward: 8.46\n","episode: 1991   score: 8.0   memory length: 511895   epsilon: 0.184445920008858    steps: 437    lr: 2.560000000000001e-06     evaluation reward: 8.48\n","episode: 1992   score: 6.0   memory length: 512243   epsilon: 0.18375688000885365    steps: 348    lr: 2.560000000000001e-06     evaluation reward: 8.42\n","episode: 1993   score: 7.0   memory length: 512632   epsilon: 0.18298666000884878    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 8.39\n","episode: 1994   score: 5.0   memory length: 512945   epsilon: 0.18236692000884486    steps: 313    lr: 2.560000000000001e-06     evaluation reward: 8.33\n","episode: 1995   score: 7.0   memory length: 513332   epsilon: 0.18160066000884    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 8.36\n","episode: 1996   score: 13.0   memory length: 513850   epsilon: 0.18057502000883352    steps: 518    lr: 2.560000000000001e-06     evaluation reward: 8.41\n","episode: 1997   score: 5.0   memory length: 514179   epsilon: 0.1799236000088294    steps: 329    lr: 2.560000000000001e-06     evaluation reward: 8.39\n","episode: 1998   score: 10.0   memory length: 514637   epsilon: 0.17901676000882366    steps: 458    lr: 2.560000000000001e-06     evaluation reward: 8.37\n","episode: 1999   score: 7.0   memory length: 515008   epsilon: 0.178282180008819    steps: 371    lr: 2.560000000000001e-06     evaluation reward: 8.34\n","episode: 2000   score: 9.0   memory length: 515444   epsilon: 0.17741890000881355    steps: 436    lr: 2.560000000000001e-06     evaluation reward: 8.32\n","episode: 2001   score: 10.0   memory length: 515966   epsilon: 0.176385340008807    steps: 522    lr: 2.560000000000001e-06     evaluation reward: 8.31\n","episode: 2002   score: 9.0   memory length: 516388   epsilon: 0.17554978000880173    steps: 422    lr: 2.560000000000001e-06     evaluation reward: 8.34\n","episode: 2003   score: 13.0   memory length: 516974   epsilon: 0.17438950000879438    steps: 586    lr: 2.560000000000001e-06     evaluation reward: 8.4\n","episode: 2004   score: 7.0   memory length: 517347   epsilon: 0.1736509600087897    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 8.39\n","episode: 2005   score: 10.0   memory length: 517872   epsilon: 0.17261146000878314    steps: 525    lr: 2.560000000000001e-06     evaluation reward: 8.44\n","episode: 2006   score: 9.0   memory length: 518351   epsilon: 0.17166304000877713    steps: 479    lr: 2.560000000000001e-06     evaluation reward: 8.47\n","episode: 2007   score: 11.0   memory length: 518861   epsilon: 0.17065324000877075    steps: 510    lr: 2.560000000000001e-06     evaluation reward: 8.47\n","episode: 2008   score: 5.0   memory length: 519149   epsilon: 0.17008300000876714    steps: 288    lr: 2.560000000000001e-06     evaluation reward: 8.46\n","episode: 2009   score: 5.0   memory length: 519439   epsilon: 0.1695088000087635    steps: 290    lr: 2.560000000000001e-06     evaluation reward: 8.43\n","episode: 2010   score: 11.0   memory length: 520022   epsilon: 0.1683544600087562    steps: 583    lr: 2.560000000000001e-06     evaluation reward: 8.48\n","episode: 2011   score: 6.0   memory length: 520347   epsilon: 0.16771096000875213    steps: 325    lr: 2.560000000000001e-06     evaluation reward: 8.48\n","episode: 2012   score: 6.0   memory length: 520653   epsilon: 0.1671050800087483    steps: 306    lr: 2.560000000000001e-06     evaluation reward: 8.49\n","episode: 2013   score: 7.0   memory length: 521018   epsilon: 0.16638238000874372    steps: 365    lr: 2.560000000000001e-06     evaluation reward: 8.49\n","episode: 2014   score: 7.0   memory length: 521409   epsilon: 0.16560820000873883    steps: 391    lr: 2.560000000000001e-06     evaluation reward: 8.53\n","episode: 2015   score: 6.0   memory length: 521748   epsilon: 0.16493698000873458    steps: 339    lr: 2.560000000000001e-06     evaluation reward: 8.5\n","episode: 2016   score: 6.0   memory length: 522110   epsilon: 0.16422022000873004    steps: 362    lr: 2.560000000000001e-06     evaluation reward: 8.45\n","episode: 2017   score: 5.0   memory length: 522434   epsilon: 0.16357870000872599    steps: 324    lr: 2.560000000000001e-06     evaluation reward: 8.39\n","episode: 2018   score: 9.0   memory length: 522846   epsilon: 0.16276294000872082    steps: 412    lr: 2.560000000000001e-06     evaluation reward: 8.38\n","episode: 2019   score: 6.0   memory length: 523208   epsilon: 0.1620461800087163    steps: 362    lr: 2.560000000000001e-06     evaluation reward: 8.32\n","episode: 2020   score: 9.0   memory length: 523606   epsilon: 0.1612581400087113    steps: 398    lr: 2.560000000000001e-06     evaluation reward: 8.39\n","episode: 2021   score: 4.0   memory length: 523850   epsilon: 0.16077502000870825    steps: 244    lr: 2.560000000000001e-06     evaluation reward: 8.35\n","episode: 2022   score: 8.0   memory length: 524232   epsilon: 0.16001866000870346    steps: 382    lr: 2.560000000000001e-06     evaluation reward: 8.38\n","episode: 2023   score: 4.0   memory length: 524512   epsilon: 0.15946426000869995    steps: 280    lr: 2.560000000000001e-06     evaluation reward: 8.36\n","episode: 2024   score: 8.0   memory length: 524946   epsilon: 0.15860494000869452    steps: 434    lr: 2.560000000000001e-06     evaluation reward: 8.38\n","episode: 2025   score: 9.0   memory length: 525397   epsilon: 0.15771196000868887    steps: 451    lr: 2.560000000000001e-06     evaluation reward: 8.37\n","episode: 2026   score: 9.0   memory length: 525863   epsilon: 0.15678928000868303    steps: 466    lr: 2.560000000000001e-06     evaluation reward: 8.36\n","episode: 2027   score: 6.0   memory length: 526217   epsilon: 0.1560883600086786    steps: 354    lr: 2.560000000000001e-06     evaluation reward: 8.35\n","episode: 2028   score: 8.0   memory length: 526634   epsilon: 0.15526270000867337    steps: 417    lr: 2.560000000000001e-06     evaluation reward: 8.35\n","episode: 2029   score: 15.0   memory length: 527291   epsilon: 0.15396184000866514    steps: 657    lr: 2.560000000000001e-06     evaluation reward: 8.38\n","episode: 2030   score: 6.0   memory length: 527668   epsilon: 0.15321538000866042    steps: 377    lr: 2.560000000000001e-06     evaluation reward: 8.34\n","episode: 2031   score: 11.0   memory length: 528166   epsilon: 0.15222934000865418    steps: 498    lr: 2.560000000000001e-06     evaluation reward: 8.4\n","episode: 2032   score: 10.0   memory length: 528677   epsilon: 0.15121756000864778    steps: 511    lr: 2.560000000000001e-06     evaluation reward: 8.4\n","episode: 2033   score: 7.0   memory length: 529050   epsilon: 0.1504790200086431    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 8.32\n","episode: 2034   score: 9.0   memory length: 529514   epsilon: 0.1495603000086373    steps: 464    lr: 2.560000000000001e-06     evaluation reward: 8.35\n","episode: 2035   score: 25.0   memory length: 530340   epsilon: 0.14792482000862694    steps: 826    lr: 2.560000000000001e-06     evaluation reward: 8.5\n","episode: 2036   score: 9.0   memory length: 530831   epsilon: 0.1469526400086208    steps: 491    lr: 2.560000000000001e-06     evaluation reward: 8.51\n","episode: 2037   score: 14.0   memory length: 531356   epsilon: 0.14591314000861422    steps: 525    lr: 2.560000000000001e-06     evaluation reward: 8.56\n","episode: 2038   score: 6.0   memory length: 531713   epsilon: 0.14520628000860974    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 8.51\n","episode: 2039   score: 8.0   memory length: 532136   epsilon: 0.14436874000860445    steps: 423    lr: 2.560000000000001e-06     evaluation reward: 8.52\n","episode: 2040   score: 5.0   memory length: 532445   epsilon: 0.14375692000860057    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 8.49\n","episode: 2041   score: 12.0   memory length: 533047   epsilon: 0.14256496000859303    steps: 602    lr: 2.560000000000001e-06     evaluation reward: 8.51\n","episode: 2042   score: 14.0   memory length: 533516   epsilon: 0.14163634000858716    steps: 469    lr: 2.560000000000001e-06     evaluation reward: 8.59\n","episode: 2043   score: 9.0   memory length: 533961   epsilon: 0.14075524000858158    steps: 445    lr: 2.560000000000001e-06     evaluation reward: 8.61\n","episode: 2044   score: 8.0   memory length: 534421   epsilon: 0.13984444000857582    steps: 460    lr: 2.560000000000001e-06     evaluation reward: 8.63\n","episode: 2045   score: 11.0   memory length: 534922   epsilon: 0.13885246000856954    steps: 501    lr: 2.560000000000001e-06     evaluation reward: 8.58\n","episode: 2046   score: 7.0   memory length: 535332   epsilon: 0.1380406600085644    steps: 410    lr: 2.560000000000001e-06     evaluation reward: 8.56\n","episode: 2047   score: 13.0   memory length: 535808   epsilon: 0.13709818000855845    steps: 476    lr: 2.560000000000001e-06     evaluation reward: 8.61\n","episode: 2048   score: 11.0   memory length: 536308   epsilon: 0.13610818000855218    steps: 500    lr: 2.560000000000001e-06     evaluation reward: 8.65\n","episode: 2049   score: 11.0   memory length: 536828   epsilon: 0.13507858000854567    steps: 520    lr: 2.560000000000001e-06     evaluation reward: 8.68\n","episode: 2050   score: 12.0   memory length: 537391   epsilon: 0.13396384000853861    steps: 563    lr: 2.560000000000001e-06     evaluation reward: 8.77\n","episode: 2051   score: 14.0   memory length: 538050   epsilon: 0.13265902000853036    steps: 659    lr: 2.560000000000001e-06     evaluation reward: 8.8\n","episode: 2052   score: 9.0   memory length: 538524   epsilon: 0.13172050000852442    steps: 474    lr: 2.560000000000001e-06     evaluation reward: 8.83\n","episode: 2053   score: 12.0   memory length: 538982   epsilon: 0.13081366000851868    steps: 458    lr: 2.560000000000001e-06     evaluation reward: 8.92\n","episode: 2054   score: 10.0   memory length: 539486   epsilon: 0.12981574000851237    steps: 504    lr: 2.560000000000001e-06     evaluation reward: 8.94\n","episode: 2055   score: 14.0   memory length: 540136   epsilon: 0.12852874000850423    steps: 650    lr: 2.560000000000001e-06     evaluation reward: 9.0\n","episode: 2056   score: 7.0   memory length: 540528   epsilon: 0.12775258000849932    steps: 392    lr: 2.560000000000001e-06     evaluation reward: 8.96\n","episode: 2057   score: 7.0   memory length: 540916   epsilon: 0.12698434000849446    steps: 388    lr: 2.560000000000001e-06     evaluation reward: 8.96\n","episode: 2058   score: 8.0   memory length: 541387   epsilon: 0.12605176000848856    steps: 471    lr: 2.560000000000001e-06     evaluation reward: 8.98\n","episode: 2059   score: 9.0   memory length: 541712   epsilon: 0.12540826000848448    steps: 325    lr: 2.560000000000001e-06     evaluation reward: 8.97\n","episode: 2060   score: 9.0   memory length: 542202   epsilon: 0.12443806000848229    steps: 490    lr: 2.560000000000001e-06     evaluation reward: 9.0\n","episode: 2061   score: 6.0   memory length: 542558   epsilon: 0.12373318000848277    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 8.99\n","episode: 2062   score: 8.0   memory length: 543013   epsilon: 0.12283228000848338    steps: 455    lr: 2.560000000000001e-06     evaluation reward: 8.98\n","episode: 2063   score: 16.0   memory length: 543731   epsilon: 0.12141064000848435    steps: 718    lr: 2.560000000000001e-06     evaluation reward: 9.05\n","episode: 2064   score: 10.0   memory length: 544233   epsilon: 0.12041668000848503    steps: 502    lr: 2.560000000000001e-06     evaluation reward: 9.1\n","episode: 2065   score: 11.0   memory length: 544769   epsilon: 0.11935540000848575    steps: 536    lr: 2.560000000000001e-06     evaluation reward: 9.12\n","episode: 2066   score: 10.0   memory length: 545245   epsilon: 0.1184129200084864    steps: 476    lr: 2.560000000000001e-06     evaluation reward: 9.13\n","episode: 2067   score: 12.0   memory length: 545761   epsilon: 0.1173912400084871    steps: 516    lr: 2.560000000000001e-06     evaluation reward: 9.16\n","episode: 2068   score: 5.0   memory length: 546051   epsilon: 0.11681704000848749    steps: 290    lr: 2.560000000000001e-06     evaluation reward: 9.07\n","episode: 2069   score: 9.0   memory length: 546475   epsilon: 0.11597752000848806    steps: 424    lr: 2.560000000000001e-06     evaluation reward: 9.08\n","episode: 2070   score: 10.0   memory length: 546951   epsilon: 0.1150350400084887    steps: 476    lr: 2.560000000000001e-06     evaluation reward: 9.08\n","episode: 2071   score: 15.0   memory length: 547616   epsilon: 0.1137183400084896    steps: 665    lr: 2.560000000000001e-06     evaluation reward: 9.19\n","episode: 2072   score: 9.0   memory length: 548074   epsilon: 0.11281150000849022    steps: 458    lr: 2.560000000000001e-06     evaluation reward: 9.17\n","episode: 2073   score: 2.0   memory length: 548255   epsilon: 0.11245312000849046    steps: 181    lr: 2.560000000000001e-06     evaluation reward: 9.11\n","episode: 2074   score: 10.0   memory length: 548757   epsilon: 0.11145916000849114    steps: 502    lr: 2.560000000000001e-06     evaluation reward: 9.16\n","episode: 2075   score: 21.0   memory length: 549528   epsilon: 0.10993258000849218    steps: 771    lr: 2.560000000000001e-06     evaluation reward: 9.27\n","episode: 2076   score: 7.0   memory length: 549916   epsilon: 0.1091643400084927    steps: 388    lr: 2.560000000000001e-06     evaluation reward: 9.25\n","episode: 2077   score: 5.0   memory length: 550226   epsilon: 0.10855054000849312    steps: 310    lr: 2.560000000000001e-06     evaluation reward: 9.18\n","episode: 2078   score: 9.0   memory length: 550729   epsilon: 0.1075546000084938    steps: 503    lr: 2.560000000000001e-06     evaluation reward: 9.14\n","episode: 2079   score: 8.0   memory length: 551152   epsilon: 0.10671706000849437    steps: 423    lr: 2.560000000000001e-06     evaluation reward: 9.16\n","episode: 2080   score: 9.0   memory length: 551676   epsilon: 0.10567954000849508    steps: 524    lr: 2.560000000000001e-06     evaluation reward: 9.16\n","episode: 2081   score: 20.0   memory length: 552277   epsilon: 0.1044895600084959    steps: 601    lr: 2.560000000000001e-06     evaluation reward: 9.27\n","episode: 2082   score: 10.0   memory length: 552804   epsilon: 0.1034461000084966    steps: 527    lr: 2.560000000000001e-06     evaluation reward: 9.24\n","episode: 2083   score: 13.0   memory length: 553410   epsilon: 0.10224622000849742    steps: 606    lr: 2.560000000000001e-06     evaluation reward: 9.23\n","episode: 2084   score: 7.0   memory length: 553836   epsilon: 0.101402740008498    steps: 426    lr: 2.560000000000001e-06     evaluation reward: 9.21\n","episode: 2085   score: 10.0   memory length: 554259   epsilon: 0.10056520000849857    steps: 423    lr: 2.560000000000001e-06     evaluation reward: 9.24\n","episode: 2086   score: 10.0   memory length: 554774   epsilon: 0.09954550000849927    steps: 515    lr: 2.560000000000001e-06     evaluation reward: 9.25\n","episode: 2087   score: 6.0   memory length: 555130   epsilon: 0.09884062000849975    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 9.17\n","episode: 2088   score: 16.0   memory length: 555717   epsilon: 0.09767836000850054    steps: 587    lr: 2.560000000000001e-06     evaluation reward: 9.22\n","episode: 2089   score: 11.0   memory length: 556242   epsilon: 0.09663886000850125    steps: 525    lr: 2.560000000000001e-06     evaluation reward: 9.25\n","episode: 2090   score: 6.0   memory length: 556581   epsilon: 0.0959676400085017    steps: 339    lr: 2.560000000000001e-06     evaluation reward: 9.23\n","episode: 2091   score: 11.0   memory length: 557066   epsilon: 0.09500734000850236    steps: 485    lr: 2.560000000000001e-06     evaluation reward: 9.26\n","episode: 2092   score: 7.0   memory length: 557440   epsilon: 0.09426682000850287    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 9.27\n","episode: 2093   score: 7.0   memory length: 557832   epsilon: 0.0934906600085034    steps: 392    lr: 2.560000000000001e-06     evaluation reward: 9.27\n","episode: 2094   score: 12.0   memory length: 558462   epsilon: 0.09224326000850425    steps: 630    lr: 2.560000000000001e-06     evaluation reward: 9.34\n","episode: 2095   score: 16.0   memory length: 558958   epsilon: 0.09126118000850492    steps: 496    lr: 2.560000000000001e-06     evaluation reward: 9.43\n","episode: 2096   score: 10.0   memory length: 559452   epsilon: 0.09028306000850558    steps: 494    lr: 2.560000000000001e-06     evaluation reward: 9.4\n","episode: 2097   score: 13.0   memory length: 560112   epsilon: 0.08897626000850647    steps: 660    lr: 2.560000000000001e-06     evaluation reward: 9.48\n","episode: 2098   score: 12.0   memory length: 560572   epsilon: 0.0880654600085071    steps: 460    lr: 2.560000000000001e-06     evaluation reward: 9.5\n","episode: 2099   score: 10.0   memory length: 561090   epsilon: 0.0870398200085078    steps: 518    lr: 2.560000000000001e-06     evaluation reward: 9.53\n","episode: 2100   score: 3.0   memory length: 561303   epsilon: 0.08661808000850808    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 9.47\n","episode: 2101   score: 10.0   memory length: 561826   epsilon: 0.08558254000850879    steps: 523    lr: 2.560000000000001e-06     evaluation reward: 9.47\n","episode: 2102   score: 15.0   memory length: 562489   epsilon: 0.08426980000850968    steps: 663    lr: 2.560000000000001e-06     evaluation reward: 9.53\n","episode: 2103   score: 8.0   memory length: 562897   epsilon: 0.08346196000851024    steps: 408    lr: 2.560000000000001e-06     evaluation reward: 9.48\n","episode: 2104   score: 8.0   memory length: 563364   epsilon: 0.08253730000851087    steps: 467    lr: 2.560000000000001e-06     evaluation reward: 9.49\n","episode: 2105   score: 6.0   memory length: 563686   epsilon: 0.0818997400085113    steps: 322    lr: 2.560000000000001e-06     evaluation reward: 9.45\n","episode: 2106   score: 8.0   memory length: 564123   epsilon: 0.08103448000851189    steps: 437    lr: 2.560000000000001e-06     evaluation reward: 9.44\n","episode: 2107   score: 10.0   memory length: 564661   epsilon: 0.07996924000851262    steps: 538    lr: 2.560000000000001e-06     evaluation reward: 9.43\n","episode: 2108   score: 10.0   memory length: 565187   epsilon: 0.07892776000851333    steps: 526    lr: 2.560000000000001e-06     evaluation reward: 9.48\n","episode: 2109   score: 9.0   memory length: 565672   epsilon: 0.07796746000851398    steps: 485    lr: 2.560000000000001e-06     evaluation reward: 9.52\n","episode: 2110   score: 17.0   memory length: 566402   epsilon: 0.07652206000851497    steps: 730    lr: 2.560000000000001e-06     evaluation reward: 9.58\n","episode: 2111   score: 11.0   memory length: 566985   epsilon: 0.07536772000851576    steps: 583    lr: 2.560000000000001e-06     evaluation reward: 9.63\n","episode: 2112   score: 4.0   memory length: 567229   epsilon: 0.07488460000851609    steps: 244    lr: 2.560000000000001e-06     evaluation reward: 9.61\n","episode: 2113   score: 6.0   memory length: 567586   epsilon: 0.07417774000851657    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 9.6\n","episode: 2114   score: 9.0   memory length: 568091   epsilon: 0.07317784000851725    steps: 505    lr: 2.560000000000001e-06     evaluation reward: 9.62\n","episode: 2115   score: 12.0   memory length: 568646   epsilon: 0.072078940008518    steps: 555    lr: 2.560000000000001e-06     evaluation reward: 9.68\n","episode: 2116   score: 12.0   memory length: 569164   epsilon: 0.0710533000085187    steps: 518    lr: 2.560000000000001e-06     evaluation reward: 9.74\n","episode: 2117   score: 7.0   memory length: 569535   epsilon: 0.0703187200085192    steps: 371    lr: 2.560000000000001e-06     evaluation reward: 9.76\n","episode: 2118   score: 9.0   memory length: 569983   epsilon: 0.0694316800085198    steps: 448    lr: 2.560000000000001e-06     evaluation reward: 9.76\n","episode: 2119   score: 10.0   memory length: 570470   epsilon: 0.06846742000852046    steps: 487    lr: 2.560000000000001e-06     evaluation reward: 9.8\n","episode: 2120   score: 14.0   memory length: 571100   epsilon: 0.06722002000852131    steps: 630    lr: 2.560000000000001e-06     evaluation reward: 9.85\n","episode: 2121   score: 11.0   memory length: 571507   epsilon: 0.06641416000852186    steps: 407    lr: 2.560000000000001e-06     evaluation reward: 9.92\n","episode: 2122   score: 13.0   memory length: 571975   epsilon: 0.0654875200085225    steps: 468    lr: 2.560000000000001e-06     evaluation reward: 9.97\n","episode: 2123   score: 14.0   memory length: 572610   epsilon: 0.06423022000852335    steps: 635    lr: 2.560000000000001e-06     evaluation reward: 10.07\n","episode: 2124   score: 7.0   memory length: 572963   epsilon: 0.06353128000852383    steps: 353    lr: 2.560000000000001e-06     evaluation reward: 10.06\n","episode: 2125   score: 12.0   memory length: 573492   epsilon: 0.062483860008524544    steps: 529    lr: 2.560000000000001e-06     evaluation reward: 10.09\n","episode: 2126   score: 11.0   memory length: 573889   epsilon: 0.06169780000852508    steps: 397    lr: 2.560000000000001e-06     evaluation reward: 10.11\n","episode: 2127   score: 8.0   memory length: 574345   epsilon: 0.060794920008525696    steps: 456    lr: 2.560000000000001e-06     evaluation reward: 10.13\n","episode: 2128   score: 10.0   memory length: 574817   epsilon: 0.059860360008526334    steps: 472    lr: 2.560000000000001e-06     evaluation reward: 10.15\n","episode: 2129   score: 11.0   memory length: 575364   epsilon: 0.05877730000852707    steps: 547    lr: 2.560000000000001e-06     evaluation reward: 10.11\n","episode: 2130   score: 11.0   memory length: 575938   epsilon: 0.05764078000852785    steps: 574    lr: 2.560000000000001e-06     evaluation reward: 10.16\n","episode: 2131   score: 8.0   memory length: 576363   epsilon: 0.05679928000852842    steps: 425    lr: 2.560000000000001e-06     evaluation reward: 10.13\n","episode: 2132   score: 12.0   memory length: 576884   epsilon: 0.055767700008529125    steps: 521    lr: 2.560000000000001e-06     evaluation reward: 10.15\n","episode: 2133   score: 10.0   memory length: 577381   epsilon: 0.054783640008529796    steps: 497    lr: 2.560000000000001e-06     evaluation reward: 10.18\n","episode: 2134   score: 6.0   memory length: 577724   epsilon: 0.05410450000853026    steps: 343    lr: 2.560000000000001e-06     evaluation reward: 10.15\n","episode: 2135   score: 7.0   memory length: 578111   epsilon: 0.05333824000853078    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 9.97\n","episode: 2136   score: 9.0   memory length: 578560   epsilon: 0.05244922000853139    steps: 449    lr: 2.560000000000001e-06     evaluation reward: 9.97\n","episode: 2137   score: 10.0   memory length: 579023   epsilon: 0.051532480008532014    steps: 463    lr: 2.560000000000001e-06     evaluation reward: 9.93\n","episode: 2138   score: 11.0   memory length: 579599   epsilon: 0.05039200000853279    steps: 576    lr: 2.560000000000001e-06     evaluation reward: 9.98\n","episode: 2139   score: 12.0   memory length: 580171   epsilon: 0.049259440008533564    steps: 572    lr: 2.560000000000001e-06     evaluation reward: 10.02\n","episode: 2140   score: 13.0   memory length: 580635   epsilon: 0.04834072000853419    steps: 464    lr: 2.560000000000001e-06     evaluation reward: 10.1\n","episode: 2141   score: 10.0   memory length: 581119   epsilon: 0.047382400008534845    steps: 484    lr: 2.560000000000001e-06     evaluation reward: 10.08\n","episode: 2142   score: 11.0   memory length: 581695   epsilon: 0.04624192000853562    steps: 576    lr: 2.560000000000001e-06     evaluation reward: 10.05\n","episode: 2143   score: 4.0   memory length: 581991   epsilon: 0.04565584000853602    steps: 296    lr: 2.560000000000001e-06     evaluation reward: 10.0\n","episode: 2144   score: 10.0   memory length: 582462   epsilon: 0.04472326000853666    steps: 471    lr: 2.560000000000001e-06     evaluation reward: 10.02\n","episode: 2145   score: 13.0   memory length: 583053   epsilon: 0.043553080008537456    steps: 591    lr: 2.560000000000001e-06     evaluation reward: 10.04\n","episode: 2146   score: 6.0   memory length: 583410   epsilon: 0.04284622000853794    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 10.03\n","episode: 2147   score: 7.0   memory length: 583800   epsilon: 0.042074020008538465    steps: 390    lr: 2.560000000000001e-06     evaluation reward: 9.97\n","episode: 2148   score: 7.0   memory length: 584179   epsilon: 0.04132360000853898    steps: 379    lr: 2.560000000000001e-06     evaluation reward: 9.93\n","episode: 2149   score: 13.0   memory length: 584786   epsilon: 0.0401217400085398    steps: 607    lr: 2.560000000000001e-06     evaluation reward: 9.95\n","episode: 2150   score: 6.0   memory length: 585094   epsilon: 0.03951190000854021    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 9.89\n","episode: 2151   score: 12.0   memory length: 585667   epsilon: 0.03837736000854099    steps: 573    lr: 2.560000000000001e-06     evaluation reward: 9.87\n","episode: 2152   score: 10.0   memory length: 586200   epsilon: 0.037322020008541706    steps: 533    lr: 2.560000000000001e-06     evaluation reward: 9.88\n","episode: 2153   score: 7.0   memory length: 586622   epsilon: 0.036486460008542276    steps: 422    lr: 2.560000000000001e-06     evaluation reward: 9.83\n","episode: 2154   score: 13.0   memory length: 587183   epsilon: 0.035375680008543034    steps: 561    lr: 2.560000000000001e-06     evaluation reward: 9.86\n","episode: 2155   score: 11.0   memory length: 587590   epsilon: 0.034569820008543584    steps: 407    lr: 2.560000000000001e-06     evaluation reward: 9.83\n","episode: 2156   score: 9.0   memory length: 588058   epsilon: 0.033643180008544216    steps: 468    lr: 2.560000000000001e-06     evaluation reward: 9.85\n","episode: 2157   score: 13.0   memory length: 588604   epsilon: 0.03256210000854495    steps: 546    lr: 2.560000000000001e-06     evaluation reward: 9.91\n","episode: 2158   score: 3.0   memory length: 588835   epsilon: 0.032104720008545265    steps: 231    lr: 2.560000000000001e-06     evaluation reward: 9.86\n","episode: 2159   score: 16.0   memory length: 589388   epsilon: 0.031009780008546012    steps: 553    lr: 2.560000000000001e-06     evaluation reward: 9.93\n","episode: 2160   score: 9.0   memory length: 589851   epsilon: 0.030093040008546637    steps: 463    lr: 2.560000000000001e-06     evaluation reward: 9.93\n","episode: 2161   score: 12.0   memory length: 590399   epsilon: 0.029008000008547377    steps: 548    lr: 2.560000000000001e-06     evaluation reward: 9.99\n","episode: 2162   score: 5.0   memory length: 590691   epsilon: 0.02842984000854777    steps: 292    lr: 2.560000000000001e-06     evaluation reward: 9.96\n","episode: 2163   score: 6.0   memory length: 590999   epsilon: 0.027820000008548187    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 9.86\n","episode: 2164   score: 3.0   memory length: 591214   epsilon: 0.027394300008548478    steps: 215    lr: 2.560000000000001e-06     evaluation reward: 9.79\n","episode: 2165   score: 7.0   memory length: 591607   epsilon: 0.02661616000854901    steps: 393    lr: 2.560000000000001e-06     evaluation reward: 9.75\n","episode: 2166   score: 11.0   memory length: 592131   epsilon: 0.025578640008549716    steps: 524    lr: 2.560000000000001e-06     evaluation reward: 9.76\n","episode: 2167   score: 9.0   memory length: 592632   epsilon: 0.024586660008550393    steps: 501    lr: 2.560000000000001e-06     evaluation reward: 9.73\n","episode: 2168   score: 8.0   memory length: 593018   epsilon: 0.023822380008550914    steps: 386    lr: 2.560000000000001e-06     evaluation reward: 9.76\n","episode: 2169   score: 9.0   memory length: 593474   epsilon: 0.02291950000855153    steps: 456    lr: 2.560000000000001e-06     evaluation reward: 9.76\n","episode: 2170   score: 13.0   memory length: 594033   epsilon: 0.021812680008552285    steps: 559    lr: 2.560000000000001e-06     evaluation reward: 9.79\n","episode: 2171   score: 7.0   memory length: 594460   epsilon: 0.02096722000855286    steps: 427    lr: 2.560000000000001e-06     evaluation reward: 9.71\n","episode: 2172   score: 10.0   memory length: 594930   epsilon: 0.020036620008553496    steps: 470    lr: 2.560000000000001e-06     evaluation reward: 9.72\n","episode: 2173   score: 12.0   memory length: 595464   epsilon: 0.018979300008554217    steps: 534    lr: 2.560000000000001e-06     evaluation reward: 9.82\n","episode: 2174   score: 6.0   memory length: 595804   epsilon: 0.018306100008554677    steps: 340    lr: 2.560000000000001e-06     evaluation reward: 9.78\n","episode: 2175   score: 7.0   memory length: 596237   epsilon: 0.01744876000855526    steps: 433    lr: 2.560000000000001e-06     evaluation reward: 9.64\n","episode: 2176   score: 15.0   memory length: 596822   epsilon: 0.01629046000855605    steps: 585    lr: 2.560000000000001e-06     evaluation reward: 9.72\n","episode: 2177   score: 10.0   memory length: 597294   epsilon: 0.015355900008556453    steps: 472    lr: 2.560000000000001e-06     evaluation reward: 9.77\n","episode: 2178   score: 9.0   memory length: 597729   epsilon: 0.014494600008556286    steps: 435    lr: 2.560000000000001e-06     evaluation reward: 9.77\n","episode: 2179   score: 15.0   memory length: 598329   epsilon: 0.013306600008556055    steps: 600    lr: 2.560000000000001e-06     evaluation reward: 9.84\n","episode: 2180   score: 7.0   memory length: 598740   epsilon: 0.012492820008555897    steps: 411    lr: 2.560000000000001e-06     evaluation reward: 9.82\n","episode: 2181   score: 7.0   memory length: 599129   epsilon: 0.011722600008555748    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 9.69\n","episode: 2182   score: 14.0   memory length: 599503   epsilon: 0.010982080008555604    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 9.73\n","episode: 2183   score: 10.0   memory length: 599854   epsilon: 0.01028710000855547    steps: 351    lr: 2.560000000000001e-06     evaluation reward: 9.7\n","episode: 2184   score: 11.0   memory length: 600388   epsilon: 0.009998020008555413    steps: 534    lr: 1.0240000000000005e-06     evaluation reward: 9.74\n","episode: 2185   score: 11.0   memory length: 600903   epsilon: 0.009998020008555413    steps: 515    lr: 1.0240000000000005e-06     evaluation reward: 9.75\n","episode: 2186   score: 10.0   memory length: 601386   epsilon: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     evaluation reward: 9.75\n","episode: 2187   score: 15.0   memory length: 601936   epsilon: 0.009998020008555413    steps: 550    lr: 1.0240000000000005e-06     evaluation reward: 9.84\n","episode: 2188   score: 11.0   memory length: 602450   epsilon: 0.009998020008555413    steps: 514    lr: 1.0240000000000005e-06     evaluation reward: 9.79\n","episode: 2189   score: 14.0   memory length: 603053   epsilon: 0.009998020008555413    steps: 603    lr: 1.0240000000000005e-06     evaluation reward: 9.82\n","episode: 2190   score: 8.0   memory length: 603458   epsilon: 0.009998020008555413    steps: 405    lr: 1.0240000000000005e-06     evaluation reward: 9.84\n","episode: 2191   score: 9.0   memory length: 603943   epsilon: 0.009998020008555413    steps: 485    lr: 1.0240000000000005e-06     evaluation reward: 9.82\n","episode: 2192   score: 9.0   memory length: 604424   epsilon: 0.009998020008555413    steps: 481    lr: 1.0240000000000005e-06     evaluation reward: 9.84\n","episode: 2193   score: 12.0   memory length: 604878   epsilon: 0.009998020008555413    steps: 454    lr: 1.0240000000000005e-06     evaluation reward: 9.89\n","episode: 2194   score: 7.0   memory length: 605239   epsilon: 0.009998020008555413    steps: 361    lr: 1.0240000000000005e-06     evaluation reward: 9.84\n","episode: 2195   score: 11.0   memory length: 605679   epsilon: 0.009998020008555413    steps: 440    lr: 1.0240000000000005e-06     evaluation reward: 9.79\n","episode: 2196   score: 26.0   memory length: 606271   epsilon: 0.009998020008555413    steps: 592    lr: 1.0240000000000005e-06     evaluation reward: 9.95\n","episode: 2197   score: 15.0   memory length: 606863   epsilon: 0.009998020008555413    steps: 592    lr: 1.0240000000000005e-06     evaluation reward: 9.97\n","episode: 2198   score: 13.0   memory length: 607440   epsilon: 0.009998020008555413    steps: 577    lr: 1.0240000000000005e-06     evaluation reward: 9.98\n","episode: 2199   score: 9.0   memory length: 607909   epsilon: 0.009998020008555413    steps: 469    lr: 1.0240000000000005e-06     evaluation reward: 9.97\n","episode: 2200   score: 10.0   memory length: 608408   epsilon: 0.009998020008555413    steps: 499    lr: 1.0240000000000005e-06     evaluation reward: 10.04\n","episode: 2201   score: 6.0   memory length: 608769   epsilon: 0.009998020008555413    steps: 361    lr: 1.0240000000000005e-06     evaluation reward: 10.0\n","episode: 2202   score: 10.0   memory length: 609236   epsilon: 0.009998020008555413    steps: 467    lr: 1.0240000000000005e-06     evaluation reward: 9.95\n","episode: 2203   score: 17.0   memory length: 609882   epsilon: 0.009998020008555413    steps: 646    lr: 1.0240000000000005e-06     evaluation reward: 10.04\n","episode: 2204   score: 3.0   memory length: 610097   epsilon: 0.009998020008555413    steps: 215    lr: 1.0240000000000005e-06     evaluation reward: 9.99\n","episode: 2205   score: 14.0   memory length: 610669   epsilon: 0.009998020008555413    steps: 572    lr: 1.0240000000000005e-06     evaluation reward: 10.07\n","episode: 2206   score: 12.0   memory length: 611221   epsilon: 0.009998020008555413    steps: 552    lr: 1.0240000000000005e-06     evaluation reward: 10.11\n","episode: 2207   score: 9.0   memory length: 611725   epsilon: 0.009998020008555413    steps: 504    lr: 1.0240000000000005e-06     evaluation reward: 10.1\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14856\\3520826364.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# Start training after random sample generation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mtrain_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# You can set train_frame to a lower value while testing your starts training earlier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_policy_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m             \u001b[1;31m# Update the target network only for Double DQN only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdouble_dqn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mupdate_target_network_frequency\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32me:\\Personal_Stuff\\UIUC\\Sem_2\\DL for CV (CS_444)\\Assignments\\assignment5\\agent_double.py\u001b[0m in \u001b[0;36mtrain_policy_net\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon_decay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mmini_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_mini_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[0mmini_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32me:\\Personal_Stuff\\UIUC\\Sem_2\\DL for CV (CS_444)\\Assignments\\assignment5\\memory.py\u001b[0m in \u001b[0;36msample_mini_batch\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;31m# sample = torch.from_numpy(sample)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mmini_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n","\u001b[1;32mc:\\Users\\vaibh\\anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[0msl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[0mexpanded_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["rewards, episodes = [], []\n","best_eval_reward = 0\n","for e in range(EPISODES):\n","    done = False\n","    score = 0\n","\n","    history = np.zeros([5, 84, 84], dtype=np.uint8)\n","    step = 0\n","    state, _ = env.reset()\n","    next_state = state\n","    life = number_lives\n","\n","    get_init_state(history, state, HISTORY_SIZE)\n","\n","    while not done:\n","        step += 1\n","        frame += 1\n","\n","        # Perform a fire action if ball is no longer on screen to continue onto next life\n","        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n","            action = torch.tensor([[0]]).cuda()\n","        else:\n","            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n","        state = next_state\n","\n","        next_state, reward, terminated, truncated, info = env.step(action + 1)\n","\n","        done = terminated or truncated\n","\n","        frame_next_state = get_frame(next_state)\n","        history[4, :, :] = frame_next_state\n","        terminal_state = check_live(life, info['lives'])\n","\n","        life = info['lives']\n","        r = reward\n","\n","        # Store the transition in memory\n","        agent.memory.push(deepcopy(frame_next_state), action.cpu(), r, terminal_state)\n","        # Start training after random sample generation\n","        if(frame >= train_frame): # You can set train_frame to a lower value while testing your starts training earlier\n","            agent.train_policy_net(frame)\n","            # Update the target network only for Double DQN only\n","            if double_dqn and (frame % update_target_network_frequency)== 0:\n","                agent.update_target_net()\n","        score += reward\n","        history[:4, :, :] = history[1:, :, :]\n","\n","        if done:\n","            evaluation_reward.append(score)\n","            rewards.append(np.mean(evaluation_reward))\n","            episodes.append(e)\n","            pylab.plot(episodes, rewards, 'b')\n","            pylab.xlabel('Episodes')\n","            pylab.ylabel('Rewards')\n","            pylab.title('Episodes vs Reward')\n","            pylab.savefig(\"./save_graph/breakout_double_dqn.png\") # save graph for training visualization\n","\n","            # every episode, plot the play time\n","            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n","                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n","                  \"   lr:\", agent.optimizer.param_groups[0]['lr'],\"    evaluation reward:\", np.mean(evaluation_reward))\n","\n","            # if the mean of scores of last 100 episode is bigger than 5 save model\n","            ### Change this save condition to whatever you prefer ###\n","            if np.mean(evaluation_reward) > 8 and np.mean(evaluation_reward) > best_eval_reward:\n","                torch.save(agent.policy_net, \"./save_model/breakout_double_dqn.pth\")\n","                best_eval_reward = np.mean(evaluation_reward)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 200 episodes: 1.5\n","# 400 episodes: 1.5\n","# 600 episodes: 1.5\n","# 1000 episodes: 1.8\n","# 1200 episodes: 2.9\n","# 1400 episodes: 4.2\n","# 1600 episodes: 5.0\n","# 1800 episodes: 6.6 \n","# 2000 episodes: 9.1\n","# 2200 episodes: 10.1"]},{"cell_type":"markdown","metadata":{"id":"seFgJUcRurdO"},"source":["# Visualize Agent Performance"]},{"cell_type":"markdown","metadata":{"id":"FxPeh0-IurdP"},"source":["BE AWARE THIS CODE BELOW MAY CRASH THE KERNEL IF YOU RUN THE SAME CELL TWICE.\n","\n","Please save your model before running this portion of the code."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"PcuUhlv1urdP"},"outputs":[],"source":["torch.save(agent.policy_net, \"./save_model/breakout_double_dqn_latest.pth\")"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"B-Zhl6hVurdP"},"outputs":[{"name":"stdout","output_type":"stream","text":["Moviepy - Building video e:\\Personal_Stuff\\UIUC\\Sem_2\\DL for CV (CS_444)\\Assignments\\assignment5\\video_double\\rl-video-episode-0.mp4.\n","Moviepy - Writing video e:\\Personal_Stuff\\UIUC\\Sem_2\\DL for CV (CS_444)\\Assignments\\assignment5\\video_double\\rl-video-episode-0.mp4\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                "]},{"name":"stdout","output_type":"stream","text":["Moviepy - Done !\n","Moviepy - video ready e:\\Personal_Stuff\\UIUC\\Sem_2\\DL for CV (CS_444)\\Assignments\\assignment5\\video_double\\rl-video-episode-0.mp4\n"]},{"name":"stderr","output_type":"stream","text":["\r"]},{"data":{"text/html":["<video style=\"height: 400px;\" controls=\"\" loop=\"\" autoplay=\"\" alt=\"test\">\n","                <source type=\"video/mp4\" src=\"data:video/mp4;base64,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\">\n","             </video>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# from gym.wrappers import Monitor # If importing monitor raises issues, try using `from gym.wrappers import RecordVideo`\n","# import glob\n","# import io\n","# import base64\n","\n","# from IPython.display import HTML\n","# from IPython import display as ipythondisplay\n","\n","# from pyvirtualdisplay import Display\n","\n","# # Displaying the game live\n","# def show_state(env, step=0, info=\"\"):\n","#     plt.figure(3)\n","#     plt.clf()\n","#     plt.imshow(env.render(mode='rgb_array'))\n","#     plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n","#     plt.axis('off')\n","\n","#     ipythondisplay.clear_output(wait=True)\n","#     ipythondisplay.display(plt.gcf())\n","\n","# # Recording the game and replaying the game afterwards\n","# def show_video():\n","#     mp4list = glob.glob('video/*.mp4')\n","#     if len(mp4list) > 0:\n","#         mp4 = mp4list[0]\n","#         video = io.open(mp4, 'r+b').read()\n","#         encoded = base64.b64encode(video)\n","#         ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n","#                 loop controls style=\"height: 400px;\">\n","#                 <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","#              </video>'''.format(encoded.decode('ascii'))))\n","#     else:\n","#         print(\"Could not find video\")\n","\n","\n","# def wrap_env(env):\n","#     env = Monitor(env, './video', force=True)\n","#     return env\n","\n","\n","\n","\n","\n","import sys\n","import gym\n","import torch\n","import pylab\n","import random\n","import numpy as np\n","from collections import deque\n","from datetime import datetime\n","from copy import deepcopy\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.utils.tensorboard import SummaryWriter\n","from utils import find_max_lives, check_live, get_frame, get_init_state\n","from model import DQN, DQN_LSTM\n","from config import *\n","\n","import matplotlib.pyplot as plt\n","# %load_ext autoreload\n","# %autoreload 2\n","\n","from gym.wrappers import RecordVideo # If importing monitor raises issues, try using `from gym.wrappers import RecordVideo`\n","import glob\n","import io\n","import base64\n","\n","from IPython.display import HTML\n","from IPython import display as ipythondisplay\n","\n","from pyvirtualdisplay import Display\n","\n","env = gym.make('BreakoutDeterministic-v4', render_mode='rgb_array')\n","state = env.reset()\n","number_lives = find_max_lives(env)\n","state_size = env.observation_space.shape\n","action_size = 3 #fire, left, and right\n","\n","# Displaying the game live\n","def show_state(env, step=0, info=\"\"):\n","    plt.figure(3)\n","    plt.clf()\n","    plt.imshow(env.render(mode='rgb_array'))\n","    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n","    plt.axis('off')\n","\n","    ipythondisplay.clear_output(wait=True)\n","    ipythondisplay.display(plt.gcf())\n","\n","# Recording the game and replaying the game afterwards\n","def show_video():\n","    mp4list = glob.glob('video_double/*.mp4')\n","    if len(mp4list) > 0:\n","        mp4 = mp4list[0]\n","        video = io.open(mp4, 'r+b').read()\n","        encoded = base64.b64encode(video)\n","        ipythondisplay.display(HTML(data='''<video style=\"height: 400px;\" controls=\"\" loop=\"\" autoplay=\"\" alt=\"test\">\n","                <source type=\"video/mp4\" src=\"data:video/mp4;base64,{0}\">\n","             </video>'''.format(encoded.decode('ascii'))))\n","    else:\n","        print(\"Could not find video\")\n","\n","\n","def wrap_env(env):\n","    env = RecordVideo(env, './video_double')\n","    return env\n","\n","from agent import Agent\n","action_size = 3\n","\n","\n","# Load agent\n","agent = Agent(action_size)\n","agent.load_policy_net(\"./save_model/breakout_double_dqn.pth\")\n","agent.epsilon = 0.0 # Set agent to only exploit the best action\n","\n","env = wrap_env(env)\n","\n","done = False\n","score = 0\n","step = 0\n","state, _ = env.reset()\n","next_state = state\n","life = number_lives\n","history = np.zeros([5, 84, 84], dtype=np.uint8)\n","get_init_state(history, state, HISTORY_SIZE)\n","frame = 0\n","while not done:\n","#     show_state(env,step) # uncommenting this provides another way to visualize the game\n","    step += 1\n","    frame += 1\n","\n","    # Perform a fire action if ball is no longer on screen\n","    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n","        action = 0\n","    else:\n","        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n","    state = next_state\n","\n","    next_state, reward, done, _, info = env.step(action + 1)\n","\n","    frame_next_state = get_frame(next_state)\n","    history[4, :, :] = frame_next_state\n","    terminal_state = check_live(life, info['lives'])\n","\n","    life = info['lives']\n","    r = np.clip(reward, -1, 1)\n","    r = reward\n","\n","    # Store the transition in memory\n","    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n","    # Start training after random sample generation\n","    score += reward\n","\n","    history[:4, :, :] = history[1:, :, :]\n","env.close()\n","show_video()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"54B9IN0_urdP"},"outputs":[],"source":["# display = Display(visible=0, size=(300, 200))\n","# display.start()\n","\n","# # Load agent\n","# # agent.load_policy_net(\"./save_model/breakout_dqn.pth\")\n","# agent.epsilon = 0.0 # Set agent to only exploit the best action\n","\n","# env = gym.make('BreakoutDeterministic-v4')\n","# env = wrap_env(env)\n","\n","# done = False\n","# score = 0\n","# step = 0\n","# state = env.reset()\n","# next_state = state\n","# life = number_lives\n","# history = np.zeros([5, 84, 84], dtype=np.uint8)\n","# get_init_state(history, state)\n","\n","# while not done:\n","\n","#     # Render breakout\n","#     env.render()\n","# #     show_state(env,step) # uncommenting this provides another way to visualize the game\n","\n","#     step += 1\n","#     frame += 1\n","\n","#     # Perform a fire action if ball is no longer on screen\n","#     if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n","#         action = 0\n","#     else:\n","#         action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n","#     state = next_state\n","\n","#     next_state, reward, done, info = env.step(action + 1)\n","\n","#     frame_next_state = get_frame(next_state)\n","#     history[4, :, :] = frame_next_state\n","#     terminal_state = check_live(life, info['ale.lives'])\n","\n","#     life = info['ale.lives']\n","#     r = np.clip(reward, -1, 1)\n","#     r = reward\n","\n","#     # Store the transition in memory\n","#     agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n","#     # Start training after random sample generation\n","#     score += reward\n","\n","#     history[:4, :, :] = history[1:, :, :]\n","# env.close()\n","# show_video()\n","# display.stop()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pq3-zcf4urdP"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3C_aNaXxurdQ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
